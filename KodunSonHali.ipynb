{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1oMF9OWx8kbmdamTkJNhUeo9PtQ5n2Rdy",
      "authorship_tag": "ABX9TyNDoMMugyP28/y/jKykD72e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sercantsn6-droid/sercantsn6-droid/blob/main/KodunSonHali.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5H-1sPhCgZQ6",
        "outputId": "fd45415a-d82d-42b9-a75b-abefb80a68e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.23.1-py3-none-any.whl (51.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.1 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n",
            "Mounted at /content/drive\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://caccc51c06c497c81a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://caccc51c06c497c81a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install gradio  #Deneme1\n",
        "# Birleşik LeNet CNN Katman Hızlandırıcı Arayüzü\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Model ve veri yolları\n",
        "MODELS = {\n",
        "    \"LeNet1\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "        \"flow_from_directory\": True\n",
        "    },\n",
        "    \"LeNet2\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "        \"flow_from_directory\": False\n",
        "    },\n",
        "    \"LeNet3\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "        \"flow_from_directory\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Global değişkenler\n",
        "test_data_cache = {}\n",
        "model_cache = {}\n",
        "layer_cache = {}\n",
        "\n",
        "# Yardımcı fonksiyonlar\n",
        "def load_model_and_data(model_name):\n",
        "    config = MODELS[model_name]\n",
        "    model = tf.keras.models.load_model(config[\"model_path\"])\n",
        "\n",
        "    if config[\"flow_from_directory\"]:\n",
        "        datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "        test_data = datagen.flow_from_directory(\n",
        "            config[\"test_path\"], target_size=(32, 32), batch_size=8,\n",
        "            class_mode=None, shuffle=False)\n",
        "    else:\n",
        "        image_files = [os.path.join(config[\"test_path\"], f) for f in os.listdir(config[\"test_path\"]) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        images = []\n",
        "        for img_path in image_files:\n",
        "            img = load_img(img_path, target_size=(32, 32))\n",
        "            img_array = img_to_array(img) / 255.0\n",
        "            images.append(img_array)\n",
        "        test_data = tf.data.Dataset.from_tensor_slices(np.array(images)).batch(8)\n",
        "\n",
        "    layer_names = [f\"Katman {i}: {layer.name} - Çıkış Şekli: {layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'}\" for i, layer in enumerate(model.layers)]\n",
        "\n",
        "    model_cache[model_name] = model\n",
        "    test_data_cache[model_name] = test_data\n",
        "    layer_cache[model_name] = layer_names\n",
        "\n",
        "    return layer_names\n",
        "\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    intermediate_model = tf.keras.Sequential(model.layers[:layer_index+1])\n",
        "    return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "def run_layer(model_name, layer_selection, data_choice):\n",
        "    model = model_cache[model_name]\n",
        "    test_data = test_data_cache[model_name]\n",
        "\n",
        "    layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "    current_layer = model.layers[layer_index]\n",
        "\n",
        "    if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "        input_data = next(iter(test_data))\n",
        "        data_info = f\"\\u00d6rnek veri kullan\\u0131ld\\u0131. \\u015eekil: {input_data.shape}\"\n",
        "    else:\n",
        "        expected_shape = model.input.shape[1:]\n",
        "        input_data = np.random.random((8, *expected_shape))\n",
        "        data_info = f\"Rastgele veri olu\\u015fturuldu. \\u015eekil: {input_data.shape}\"\n",
        "\n",
        "    try:\n",
        "        real_output = get_layer_output(model, layer_index, input_data)\n",
        "        fpga_output = real_output + np.random.normal(0, 0.05, real_output.shape)\n",
        "\n",
        "        real_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized = real_np.flatten().tobytes()\n",
        "\n",
        "        mse = np.mean((real_np - fpga_np)**2)\n",
        "        similarity = max(0, 1 - mse)\n",
        "\n",
        "        expected_input = model.input.shape[1:] if layer_index == 0 else model.layers[layer_index - 1].output.shape[1:]\n",
        "\n",
        "        output_str = f\"Se\\u00e7ilen Katman: {current_layer.name}\\n\"\n",
        "        output_str += f\"Beklenen Giri\\u015f \\u015eekli: {expected_input}\\n\"\n",
        "        output_str += f\"Ger\\u00e7ek Giri\\u015f \\u015eekli: {input_data.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Ger\\u00e7ek \\u00c7\\u0131kt\\u0131 \\u015eekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA \\u00c7\\u0131kt\\u0131 \\u015eekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Donan\\u0131ma G\\u00f6nderilen \\u00c7\\u0131kt\\u0131 Boyutu: {len(serialized)} bayt\\n\"\n",
        "        output_str += f\"Ger\\u00e7ek \\u00c7\\u0131kt\\u0131 \\u00d6rnek Veri: {real_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA \\u00c7\\u0131kt\\u0131 \\u00d6rnek Veri: {fpga_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1\\u2019e yak\\u0131nsa daha uyumlu)\\n\"\n",
        "\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA \\u00c7\\u0131kt\\u0131s\\u0131n\\u0131n Ger\\u00e7ek \\u00c7\\u0131kt\\u0131yla Uyumu</p>\n",
        "        \"\"\"\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Hata: {str(e)}\", \"<p>Hata nedeniyle animasyon olu\\u015fturulamad\\u0131.</p>\"\n",
        "\n",
        "# Gradio aray\\u00fcz\\u00fc\n",
        "with gr.Blocks(title=\"Birle\\u015fik LeNet CNN Katman H\\u0131zland\\u0131r\\u0131c\\u0131\") as interface:\n",
        "    gr.Markdown(\"# Birle\\u015fik LeNet CNN Katman H\\u0131zland\\u0131r\\u0131c\\u0131\")\n",
        "\n",
        "    model_dropdown = gr.Dropdown(choices=list(MODELS.keys()), label=\"Model Se\\u00e7in\")\n",
        "    layer_dropdown = gr.Dropdown(choices=[], label=\"Katman Se\\u00e7in\")\n",
        "    data_choice = gr.Radio(choices=[\"Test Verisinden \\u00d6rnek Kullan\", \"Rastgele Veri Kullan\"], label=\"Giri\\u015f Verisi Se\\u00e7imi\")\n",
        "    run_button = gr.Button(\"Katman\\u0131 \\u00c7al\\u0131\\u015ft\\u0131r\")\n",
        "    result_text = gr.Textbox(label=\"Sonu\\u00e7lar\", lines=15)\n",
        "    result_anim = gr.HTML()\n",
        "\n",
        "    def update_layers(model_name):\n",
        "        layer_names = load_model_and_data(model_name)\n",
        "        return gr.Dropdown.update(choices=layer_names, value=layer_names[0])\n",
        "\n",
        "    model_dropdown.change(update_layers, inputs=model_dropdown, outputs=layer_dropdown)\n",
        "    run_button.click(fn=run_layer, inputs=[model_dropdown, layer_dropdown, data_choice], outputs=[result_text, result_anim])\n",
        "\n",
        "interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio        #TASLAK1 WITH SIMULATION\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive\n",
        "import gradio as gr\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Connect Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define model and data paths\n",
        "MODELS = {\n",
        "    \"LeNet1\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "        \"flow_from_directory\": True\n",
        "    },\n",
        "    \"LeNet2\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "        \"flow_from_directory\": False\n",
        "    },\n",
        "    \"LeNet3\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "        \"flow_from_directory\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Data loading functions\n",
        "# For directories without subfolders\n",
        "def load_images_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0  # Normalization\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)\n",
        "\n",
        "# For directories with subfolders\n",
        "def load_images_with_flow_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data\n",
        "\n",
        "# Layer output function\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# FPGA simulation and comparison\n",
        "def run_layer(model_selection, layer_selection, data_choice):\n",
        "    # Get model and data paths\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "\n",
        "    # Load model\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Load test data\n",
        "    if flow_from_directory:\n",
        "        test_data = load_images_with_flow_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "    else:\n",
        "        test_data = load_images_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "\n",
        "    # Get the selected layer index\n",
        "    layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "    current_layer = loaded_model.layers[layer_index]\n",
        "\n",
        "    # Data selection and input preparation\n",
        "    if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "        if flow_from_directory:\n",
        "            input_data = next(test_data)  # Take the batch from ImageDataGenerator\n",
        "        else:\n",
        "            input_data = next(iter(test_data))  # Take the batch from tf.data.Dataset\n",
        "        data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "    else:\n",
        "        expected_shape = loaded_model.input.shape[1:]  # (32, 32, 3)\n",
        "        input_data = np.random.random((8, *expected_shape))  # compatible with batch size 8\n",
        "        data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "\n",
        "    try:\n",
        "        # Run all layers up to the selected layer\n",
        "        real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "        # Simulated output from FPGA\n",
        "        fpga_output = real_output + np.random.normal(0, 0.05, real_output.shape)\n",
        "\n",
        "        # Convert output to NumPy array\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        # Similarity calculation (with MSE)\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)  # 0-1 arasında skor\n",
        "\n",
        "        # Expected input shape\n",
        "        expected_input_shape = loaded_model.input.shape[1:] if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape[1:]\n",
        "\n",
        "        # Prepare the results\n",
        "        output_str = f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Donanıma Gönderilen Çıktı Boyutu: {len(serialized_output)} bayt\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        # Animated HTML output\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Function to dynamically retrieve layer information\n",
        "def update_layer_dropdown(model_selection):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "    layer_names = [f\"Katman {i}: {layer.name} - Çıkış Şekli: {layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'}\"\n",
        "                   for i, layer in enumerate(loaded_model.layers)]\n",
        "    return gr.Dropdown(choices=layer_names, value=layer_names[0])\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks(title=\"LeNet CNN Katman Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# LeNet CNN Katman Hızlandırıcı\")\n",
        "    gr.Markdown(\"Modelinizi seçin, ardından katmanınızı ve giriş verisi tipini belirleyin. FPGA çıktısının gerçek çıktı ile uyumunu görün!\")\n",
        "\n",
        "    # Model selection\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(choices=list(MODELS.keys()), label=\"Model Seçimi\", value=\"LeNet1\")\n",
        "\n",
        "    # Layer selection and simülation\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin\")\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "            submit_btn = gr.Button(\"Katmanı Çalıştır\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Update layer dropdown when model is selected\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=model_input, outputs=layer_input)\n",
        "\n",
        "    # Run the layer\n",
        "    submit_btn.click(fn=run_layer, inputs=[model_input, layer_input, data_input], outputs=[output_text, output_animation])\n",
        "\n",
        "# Start the interface\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XQxQml-aisu2",
        "outputId": "e5cda171-6b63-4c4c-c71d-095926b6a6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.5 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.1\n",
            "Mounted at /content/drive\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0db4473952dd5614ac.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0db4473952dd5614ac.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio                                   #TASLAK1 WITHOUT SIMULATION  #Last Model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive\n",
        "import gradio as gr\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import io\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define model and data paths\n",
        "MODELS = {\n",
        "    \"LeNet1\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "        \"flow_from_directory\": True\n",
        "    },\n",
        "    \"LeNet2\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "        \"flow_from_directory\": False\n",
        "    },\n",
        "    \"LeNet3\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "        \"flow_from_directory\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Data loading functions\n",
        "# For directories without subfolders\n",
        "\n",
        "def load_images_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"Directory {directory} not found!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0  # Normalize\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"No valid image files found in directory {directory}!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)\n",
        "\n",
        "# For directories with subfolders\n",
        "\n",
        "def load_images_with_flow_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data\n",
        "\n",
        "# Function to export layer input\n",
        "\n",
        "def export_layer_input(model_selection, layer_selection, data_choice):\n",
        "    # Get model and data paths\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "\n",
        "    # Load the model\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Load test data\n",
        "    if flow_from_directory:\n",
        "        test_data = load_images_with_flow_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "    else:\n",
        "        test_data = load_images_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "\n",
        "    # Get selected layer index\n",
        "    layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "\n",
        "    # Prepare input data based on choice\n",
        "\n",
        "    if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "        if flow_from_directory:\n",
        "            input_data = next(test_data)  # Get batch from ImageDataGenerator\n",
        "        else:\n",
        "            input_data = next(iter(test_data))  # Get batch from tf.data.Dataset\n",
        "        data_info = f\"Sample data used. Shape: {input_data.shape}\"\n",
        "    else:\n",
        "        expected_shape = loaded_model.input.shape[1:]  # (32, 32, 3)\n",
        "        input_data = np.random.random((8, *expected_shape))  # Compatible with batch size 8\n",
        "        data_info = f\"Random data generated. Shape: {input_data.shape}\"\n",
        "\n",
        "    # If not the first layer, use the output of the previous layer as input\n",
        "    if layer_index > 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=loaded_model.input, outputs=loaded_model.layers[layer_index - 1].output)\n",
        "        input_data = intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "    # Convert input data to hexadecimal format and save\n",
        "    hex_filename = f\"layer_{layer_index}_input_hex.txt\"\n",
        "    flat_data = input_data.flatten().astype(np.float32)  # Flatten and convert to float32\n",
        "    # Convert data to bytes and format each byte as \"0xaa\"\n",
        "    hex_data = []\n",
        "    for value in flat_data:\n",
        "        bytes_value = np.float32(value).tobytes()  # Convert float32 to bytes\n",
        "        hex_bytes = [f\"0x{byte:02x}\" for byte in bytes_value]  # Format each byte as 0xaa\n",
        "        hex_data.extend(hex_bytes)\n",
        "\n",
        "    # Write hex data to file in comma-separated format\n",
        "    with open(hex_filename, 'w') as f:\n",
        "        f.write(','.join(hex_data))  # Write as 0xaa,0xbb,...\n",
        "\n",
        "    # Prepare input information as text\n",
        "\n",
        "    input_text = f\"Layer Input Data Shape: {input_data.shape}\\n\"\n",
        "    input_text += f\"Sample Data (Float): {flat_data[:5]}\\n\"\n",
        "    input_text += f\"Sample Data (Hex, first 5 bytes): {hex_data[:5]}\\n\"\n",
        "    input_text += f\"Input data saved in hexadecimal format to '{hex_filename}'. Download this file to send to Kağan.\"\n",
        "\n",
        "    return input_text, gr.File(value=hex_filename)\n",
        "\n",
        "# Function to get layer output\n",
        "\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# FPGA simulation and comparison\n",
        "\n",
        "def run_layer(model_selection, layer_selection, data_choice, fpga_output_file):\n",
        "    # Get model and data paths\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "\n",
        "    # Load the model\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Load test data\n",
        "    if flow_from_directory:\n",
        "        test_data = load_images_with_flow_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "    else:\n",
        "        test_data = load_images_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "\n",
        "    # Get selected layer index\n",
        "    layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "    current_layer = loaded_model.layers[layer_index]\n",
        "\n",
        "    # Prepare input data based on choice\n",
        "\n",
        "    if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "        if flow_from_directory:\n",
        "            input_data = next(test_data)  # Get batch from ImageDataGenerator\n",
        "        else:\n",
        "            input_data = next(iter(test_data))  # Get batch from tf.data.Dataset\n",
        "        data_info = f\"Sample data used. Shape: {input_data.shape}\"\n",
        "    else:\n",
        "        expected_shape = loaded_model.input.shape[1:]  # (32, 32, 3)\n",
        "        input_data = np.random.random((8, *expected_shape))  # Compatible with batch size 8\n",
        "        data_info = f\"Random data generated. Shape: {input_data.shape}\"\n",
        "\n",
        "    try:\n",
        "        # Run all layers up to the selected layer\n",
        "        real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "        # Load FPGA output (hex .txt format)\n",
        "        if fpga_output_file is None:\n",
        "            return \"Please upload the FPGA output!\", \"<p>FPGA output not uploaded.</p>\"\n",
        "\n",
        "        # Read hex file\n",
        "        with open(fpga_output_file.name, 'r') as f:\n",
        "            hex_data = f.read().strip().split(',')\n",
        "\n",
        "        # Convert hex bytes to float32\n",
        "        if len(hex_data) % 4 != 0:\n",
        "            return \"Invalid FPGA output! 4 bytes expected per float32.\", \"<p>Invalid FPGA output.</p>\"\n",
        "\n",
        "        byte_data = [int(h.replace('0x', ''), 16) for h in hex_data]\n",
        "        float_data = []\n",
        "        for i in range(0, len(byte_data), 4):\n",
        "            bytes_value = bytes(byte_data[i:i+4])\n",
        "            float_value = np.frombuffer(bytes_value, dtype=np.float32)[0]\n",
        "            float_data.append(float_value)\n",
        "\n",
        "        # Reshape FPGA output to match real output shape\n",
        "        fpga_output_np = np.array(float_data).reshape(real_output.shape)\n",
        "\n",
        "        # Convert outputs to NumPy arrays\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        # Calculate similarity (MSE)\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)  # Score between 0 and 1\n",
        "\n",
        "        # Expected input shape\n",
        "        expected_input_shape = loaded_model.input.shape[1:] if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape[1:]\n",
        "\n",
        "        # Prepare results\n",
        "        output_str = f\"Selected Model: {model_selection}\\n\"\n",
        "        output_str += f\"Selected Layer: {current_layer.name}\\n\"\n",
        "        output_str += f\"Expected Input Shape: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Actual Input Shape: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Real Output Shape: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Output Shape: {fpga_output_np.shape}\\n\"\n",
        "        output_str += f\"Output Size Sent to Hardware: {len(serialized_output)} bytes\\n\"\n",
        "        output_str += f\"Real Output Sample Data: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Output Sample Data: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Similarity Score: {similarity:.4f} (closer to 1 is more compatible)\\n\"\n",
        "\n",
        "        # Animated HTML output\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Output Compatibility with Real Output</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error occurred: {str(e)}\\n\"\n",
        "        error_msg += f\"Selected Layer: {current_layer.name}\\n\"\n",
        "        error_msg += f\"Input Data Shape: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Valid Layer Output Shape: {real_output.shape if 'real_output' in locals() else 'Not computed'}\\n\"\n",
        "        return error_msg, \"<p>Animation could not be created due to error.</p>\"\n",
        "\n",
        "# Function to dynamically update layer dropdown\n",
        "\n",
        "def update_layer_dropdown(model_selection):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "    layer_names = [f\"Katman {i}: {layer.name} - Output Shape: {layer.output.shape if hasattr(layer, 'output') else 'Input Layer'}\"\n",
        "                   for i, layer in enumerate(loaded_model.layers)]\n",
        "    return gr.Dropdown(choices=layer_names, value=layer_names[0])\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks(title=\"LeNet CNN Layer Accelerator\") as interface:\n",
        "    gr.Markdown(\"# LeNet CNN Layer Accelerator\")\n",
        "    gr.Markdown(\"Select your model, then choose the layer and input data type. Export the layer input and upload the FPGA output to compare!\")\n",
        "\n",
        "    # Model selection\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(choices=list(MODELS.keys()), label=\"Model Selection\", value=\"LeNet1\")\n",
        "\n",
        "    # Layer selection and simulation\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Select Layer to Accelerate\")\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Input Data Selection\", value=\"Test Verisinden Örnek Kullan\")\n",
        "\n",
        "            # Export input\n",
        "            export_btn = gr.Button(\"Export Layer Input\", variant=\"secondary\")\n",
        "            input_text = gr.Textbox(label=\"Layer Input Information\", lines=3)\n",
        "            input_file = gr.File(label=\"Hex File (Download to Send to Kağan)\")\n",
        "\n",
        "            # Upload FPGA output\n",
        "            fpga_output_file = gr.File(label=\"Upload FPGA Output from Kağan (hex .txt format)\")\n",
        "\n",
        "            # Comparison button\n",
        "            submit_btn = gr.Button(\"Perform Comparison\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Results\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Output Compatibility\")\n",
        "\n",
        "    # Update layer dropdown when model is selected\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=model_input, outputs=layer_input)\n",
        "\n",
        "    # Export input\n",
        "    export_btn.click(fn=export_layer_input, inputs=[model_input, layer_input, data_input], outputs=[input_text, input_file])\n",
        "\n",
        "    # Perform comparison\n",
        "    submit_btn.click(fn=run_layer, inputs=[model_input, layer_input, data_input, fpga_output_file], outputs=[output_text, output_animation])\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0c3cmACDHmm1",
        "outputId": "5c83c90b-a31a-4b54-c9c6-308704bb83c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.25.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.5)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f268632e5e7df51dca.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f268632e5e7df51dca.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#do not forget to use !pip install gradio we already use it upstairs + üsteki kod son aşama şu anlık burdan itibaren gerçek simülasyon için...\n",
        "import tensorflow as tf                                #NPY ŞEKLİNDE ÇIKTI\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive\n",
        "import gradio as gr\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import io\n",
        "\n",
        "# Google Drive'ı bağla\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Model ve veri yollarını tanımla\n",
        "MODELS = {\n",
        "    \"LeNet1\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "        \"flow_from_directory\": True\n",
        "    },\n",
        "    \"LeNet2\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "        \"flow_from_directory\": False\n",
        "    },\n",
        "    \"LeNet3\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "        \"flow_from_directory\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Veri yükleme fonksiyonları\n",
        "# Alt klasörsüz dizinler için\n",
        "def load_images_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0  # Normalizasyon\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)\n",
        "\n",
        "# Alt klasörlü dizinler için\n",
        "def load_images_with_flow_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data\n",
        "\n",
        "# Katman girişini dışa aktarma fonksiyonu\n",
        "def export_layer_input(model_selection, layer_selection, data_choice):\n",
        "    # Model ve veri yollarını al\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "\n",
        "    # Modeli yükle\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Test verisini yükle\n",
        "    if flow_from_directory:\n",
        "        test_data = load_images_with_flow_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "    else:\n",
        "        test_data = load_images_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "\n",
        "    # Seçilen katman indeksini al\n",
        "    layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "\n",
        "    # Veri seçimi ve giriş hazırlanması\n",
        "    if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "        if flow_from_directory:\n",
        "            input_data = next(test_data)  # ImageDataGenerator'dan batch alma\n",
        "        else:\n",
        "            input_data = next(iter(test_data))  # tf.data.Dataset'ten batch alma\n",
        "        data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "    else:\n",
        "        expected_shape = loaded_model.input.shape[1:]  # (32, 32, 3)\n",
        "        input_data = np.random.random((8, *expected_shape))  # Batch boyutu 8 ile uyumlu\n",
        "        data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "\n",
        "    # Eğer ilk katman değilse, önceki katmanların çıktısını giriş olarak al\n",
        "    if layer_index > 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=loaded_model.input, outputs=loaded_model.layers[layer_index - 1].output)\n",
        "        input_data = intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "    # Giriş verisini bir .npy dosyası olarak kaydet\n",
        "    input_filename = f\"layer_{layer_index}_input.npy\"\n",
        "    np.save(input_filename, input_data)\n",
        "\n",
        "    # Giriş verisini metin olarak da göster\n",
        "    input_text = f\"Katman Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "    input_text += f\"Örnek Veri: {input_data.flatten()[:5]}\\n\"\n",
        "    input_text += f\"Giriş verisi '{input_filename}' dosyasına kaydedildi. Bu dosyayı indirip Kağan'a gönderebilirsiniz.\"\n",
        "\n",
        "    return input_text, gr.File(value=input_filename)\n",
        "\n",
        "# Katman çıktısını alma fonksiyonu\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# FPGA simülasyonu ve karşılaştırma\n",
        "def run_layer(model_selection, layer_selection, data_choice, fpga_output_file):\n",
        "    # Model ve veri yollarını al\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "\n",
        "    # Modeli yükle\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Test verisini yükle\n",
        "    if flow_from_directory:\n",
        "        test_data = load_images_with_flow_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "    else:\n",
        "        test_data = load_images_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "\n",
        "    # Seçilen katman indeksini al\n",
        "    layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "    current_layer = loaded_model.layers[layer_index]\n",
        "\n",
        "    # Veri seçimi ve giriş hazırlanması\n",
        "    if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "        if flow_from_directory:\n",
        "            input_data = next(test_data)  # ImageDataGenerator'dan batch alma\n",
        "        else:\n",
        "            input_data = next(iter(test_data))  # tf.data.Dataset'ten batch alma\n",
        "        data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "    else:\n",
        "        expected_shape = loaded_model.input.shape[1:]  # (32, 32, 3)\n",
        "        input_data = np.random.random((8, *expected_shape))  # Batch boyutu 8 ile uyumlu\n",
        "        data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "\n",
        "    try:\n",
        "        # Seçilen katmana kadar tüm katmanları çalıştır\n",
        "        real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "        # FPGA çıktısını yükle\n",
        "        if fpga_output_file is None:\n",
        "            return \"Lütfen FPGA çıktısını yükleyin!\", \"<p>FPGA çıktısı yüklenmedi.</p>\"\n",
        "        fpga_output = np.load(fpga_output_file.name)\n",
        "\n",
        "        # Çıktıyı NumPy array'e çevir\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        # Benzerlik hesaplama (MSE ile)\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)  # 0-1 arasında skor\n",
        "\n",
        "        # Beklenen giriş şekli\n",
        "        expected_input_shape = loaded_model.input.shape[1:] if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape[1:]\n",
        "\n",
        "        # Sonuçları hazırla\n",
        "        output_str = f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Donanıma Gönderilen Çıktı Boyutu: {len(serialized_output)} bayt\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        # Animasyonlu HTML çıktısı\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Katman bilgilerini dinamik olarak alma fonksiyonu\n",
        "def update_layer_dropdown(model_selection):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "    layer_names = [f\"Katman {i}: {layer.name} - Çıkış Şekli: {layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'}\"\n",
        "                   for i, layer in enumerate(loaded_model.layers)]\n",
        "    return gr.Dropdown(choices=layer_names, value=layer_names[0])\n",
        "\n",
        "# Gradio arayüzünü oluştur\n",
        "with gr.Blocks(title=\"LeNet CNN Katman Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# LeNet CNN Katman Hızlandırıcı\")\n",
        "    gr.Markdown(\"Modelinizi seçin, ardından katmanınızı ve giriş verisi tipini belirleyin. Katman girişini dışa aktarın ve FPGA çıktısını yükleyerek karşılaştırma yapın!\")\n",
        "\n",
        "    # Model seçimi\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(choices=list(MODELS.keys()), label=\"Model Seçimi\", value=\"LeNet1\")\n",
        "\n",
        "    # Katman seçimi ve simülasyon\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin\")\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "\n",
        "            # Girişi dışa aktarma\n",
        "            export_btn = gr.Button(\"Katman Girişini Dışa Aktar\", variant=\"secondary\")\n",
        "            input_text = gr.Textbox(label=\"Katman Giriş Bilgisi\", lines=3)\n",
        "            input_file = gr.File(label=\"Giriş Dosyası (Kağan'a Göndermek İçin İndirin)\")\n",
        "\n",
        "            # FPGA çıktısını yükleme\n",
        "            fpga_output_file = gr.File(label=\"Kağan'dan Gelen FPGA Çıktısını Yükleyin (.npy formatında)\")\n",
        "\n",
        "            # Karşılaştırma butonu\n",
        "            submit_btn = gr.Button(\"Karşılaştırma Yap\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Model seçildiğinde katman dropdown'unu güncelle\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=model_input, outputs=layer_input)\n",
        "\n",
        "    # Girişi dışa aktar\n",
        "    export_btn.click(fn=export_layer_input, inputs=[model_input, layer_input, data_input], outputs=[input_text, input_file])\n",
        "\n",
        "    # Karşılaştırma yap\n",
        "    submit_btn.click(fn=run_layer, inputs=[model_input, layer_input, data_input, fpga_output_file], outputs=[output_text, output_animation])\n",
        "\n",
        "# Arayüzü başlat\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "b5RjPq-srOcq",
        "outputId": "a1102693-1939-48cc-d608-36c62db637db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://92f4e5c37df3d138eb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://92f4e5c37df3d138eb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive\n",
        "import gradio as gr\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import io\n",
        "\n",
        "# Google Drive'ı bağla\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Model ve veri yollarını tanımla\n",
        "MODELS = {\n",
        "    \"LeNet1\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "        \"flow_from_directory\": True\n",
        "    },\n",
        "    \"LeNet2\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "        \"flow_from_directory\": False\n",
        "    },\n",
        "    \"LeNet3\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "        \"flow_from_directory\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Veri yükleme fonksiyonları\n",
        "# Alt klasörsüz dizinler için\n",
        "def load_images_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0  # Normalizasyon\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)\n",
        "\n",
        "# Alt klasörlü dizinler için\n",
        "def load_images_with_flow_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data\n",
        "\n",
        "# Katman girişini dışa aktarma fonksiyonu\n",
        "def export_layer_input(model_selection, layer_selection, data_choice):\n",
        "    # Model ve veri yollarını al\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "\n",
        "    # Modeli yükle\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Test verisini yükle\n",
        "    if flow_from_directory:\n",
        "        test_data = load_images_with_flow_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "    else:\n",
        "        test_data = load_images_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "\n",
        "    # Seçilen katman indeksini al\n",
        "    layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "\n",
        "    # Veri seçimi ve giriş hazırlanması\n",
        "    if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "        if flow_from_directory:\n",
        "            input_data = next(test_data)  # ImageDataGenerator'dan batch alma\n",
        "        else:\n",
        "            input_data = next(iter(test_data))  # tf.data.Dataset'ten batch alma\n",
        "        data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "    else:\n",
        "        expected_shape = loaded_model.input.shape[1:]  # (32, 32, 3)\n",
        "        input_data = np.random.random((8, *expected_shape))  # Batch boyutu 8 ile uyumlu\n",
        "        data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "\n",
        "    # Eğer ilk katman değilse, önceki katmanların çıktısını giriş olarak al\n",
        "    if layer_index > 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=loaded_model.input, outputs=loaded_model.layers[layer_index - 1].output)\n",
        "        input_data = intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "    # Giriş verisini hexadecimal formatına çevir ve kaydet\n",
        "    hex_filename = f\"layer_{layer_index}_input_hex.txt\"\n",
        "    flat_data = input_data.flatten().astype(np.float32)  # Veriyi düzleştir ve float32'ye çevir\n",
        "    # Veriyi baytlarına ayır ve her baytı \"0xaa\" formatında yaz\n",
        "    hex_data = []\n",
        "    for value in flat_data:\n",
        "        bytes_value = np.float32(value).tobytes()  # float32'yi baytlara çevir\n",
        "        hex_bytes = [f\"0x{byte:02x}\" for byte in bytes_value]  # Her baytı 0xaa formatına çevir\n",
        "        hex_data.extend(hex_bytes)\n",
        "\n",
        "    # Hex veriyi virgülle ayrılmış şekilde dosyaya yaz\n",
        "    with open(hex_filename, 'w') as f:\n",
        "        f.write(','.join(hex_data))  # 0xaa,0xbb,... formatında yaz\n",
        "\n",
        "    # Giriş verisini metin olarak göster\n",
        "    input_text = f\"Katman Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "    input_text += f\"Örnek Veri (Float): {flat_data[:5]}\\n\"\n",
        "    input_text += f\"Örnek Veri (Hex, ilk 5 bayt): {hex_data[:5]}\\n\"\n",
        "    input_text += f\"Giriş verisi hexadecimal formatta '{hex_filename}' dosyasına kaydedildi. Bu dosyayı indirip Kağan'a gönderebilirsiniz.\"\n",
        "\n",
        "    return input_text, gr.File(value=hex_filename)\n",
        "\n",
        "# Katman çıktısını alma fonksiyonu\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# FPGA simülasyonu ve karşılaştırma\n",
        "def run_layer(model_selection, layer_selection, data_choice, fpga_output_file):\n",
        "    # Model ve veri yollarını al\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "\n",
        "    # Modeli yükle\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Test verisini yükle\n",
        "    if flow_from_directory:\n",
        "        test_data = load_images_with_flow_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "    else:\n",
        "        test_data = load_images_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "\n",
        "    # Seçilen katman indeksini al\n",
        "    layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "    current_layer = loaded_model.layers[layer_index]\n",
        "\n",
        "    # Veri seçimi ve giriş hazırlanması\n",
        "    if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "        if flow_from_directory:\n",
        "            input_data = next(test_data)  # ImageDataGenerator'dan batch alma\n",
        "        else:\n",
        "            input_data = next(iter(test_data))  # tf.data.Dataset'ten batch alma\n",
        "        data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "    else:\n",
        "        expected_shape = loaded_model.input.shape[1:]  # (32, 32, 3)\n",
        "        input_data = np.random.random((8, *expected_shape))  # Batch boyutu 8 ile uyumlu\n",
        "        data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "\n",
        "    try:\n",
        "        # Seçilen katmana kadar tüm katmanları çalıştır\n",
        "        real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "        # FPGA çıktısını yükle\n",
        "        if fpga_output_file is None:\n",
        "            return \"Lütfen FPGA çıktısını yükleyin!\", \"<p>FPGA çıktısı yüklenmedi.</p>\"\n",
        "        fpga_output = np.load(fpga_output_file.name)\n",
        "\n",
        "        # Çıktıyı NumPy array'e çevir\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        # Benzerlik hesaplama (MSE ile)\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)  # 0-1 arasında skor\n",
        "\n",
        "        # Beklenen giriş şekli\n",
        "        expected_input_shape = loaded_model.input.shape[1:] if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape[1:]\n",
        "\n",
        "        # Sonuçları hazırla\n",
        "        output_str = f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Donanıma Gönderilen Çıktı Boyutu: {len(serialized_output)} bayt\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        # Animasyonlu HTML çıktısı\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Katman bilgilerini dinamik olarak alma fonksiyonu\n",
        "def update_layer_dropdown(model_selection):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "    layer_names = [f\"Katman {i}: {layer.name} - Çıkış Şekli: {layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'}\"\n",
        "                   for i, layer in enumerate(loaded_model.layers)]\n",
        "    return gr.Dropdown(choices=layer_names, value=layer_names[0])\n",
        "\n",
        "# Gradio arayüzünü oluştur\n",
        "with gr.Blocks(title=\"LeNet CNN Katman Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# LeNet CNN Katman Hızlandırıcı\")\n",
        "    gr.Markdown(\"Modelinizi seçin, ardından katmanınızı ve giriş verisi tipini belirleyin. Katman girişini dışa aktarın ve FPGA çıktısını yükleyerek karşılaştırma yapın!\")\n",
        "\n",
        "    # Model seçimi\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(choices=list(MODELS.keys()), label=\"Model Seçimi\", value=\"LeNet1\")\n",
        "\n",
        "    # Katman seçimi ve simülasyon\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin\")\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "\n",
        "            # Girişi dışa aktarma\n",
        "            export_btn = gr.Button(\"Katman Girişini Dışa Aktar\", variant=\"secondary\")\n",
        "            input_text = gr.Textbox(label=\"Katman Giriş Bilgisi\", lines=3)\n",
        "            input_file = gr.File(label=\"Hex Dosyası (Kağan'a Göndermek İçin İndirin)\")\n",
        "\n",
        "            # FPGA çıktısını yükleme\n",
        "            fpga_output_file = gr.File(label=\"Kağan'dan Gelen FPGA Çıktısını Yükleyin (.npy formatında)\")\n",
        "\n",
        "            # Karşılaştırma butonu\n",
        "            submit_btn = gr.Button(\"Karşılaştırma Yap\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Model seçildiğinde katman dropdown'unu güncelle\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=model_input, outputs=layer_input)\n",
        "\n",
        "    # Girişi dışa aktar\n",
        "    export_btn.click(fn=export_layer_input, inputs=[model_input, layer_input, data_input], outputs=[input_text, input_file])\n",
        "\n",
        "    # Karşılaştırma yap\n",
        "    submit_btn.click(fn=run_layer, inputs=[model_input, layer_input, data_input, fpga_output_file], outputs=[output_text, output_animation])\n",
        "\n",
        "# Arayüzü başlat\n",
        "interface.launch()"
      ],
      "metadata": {
        "id": "_F4_zUWhu0g6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "510decb6-d2d3-4d9d-fe77-499b35b14500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.25.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.5)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://204d1ba6da2c56826a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://204d1ba6da2c56826a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf    #Last Work\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "!pip install gradio\n",
        "import gradio as gr\n",
        "\n",
        "import os\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "import json\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import uuid\n",
        "\n",
        "# Define model and data paths\n",
        "MODELS = {\n",
        "    \"LeNet1\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "        \"flow_from_directory\": True\n",
        "    },\n",
        "    \"LeNet2\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "        \"flow_from_directory\": False\n",
        "    },\n",
        "    \"LeNet3\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "        \"flow_from_directory\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Data loading functions\n",
        "def load_images_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)\n",
        "\n",
        "def load_images_with_flow_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data\n",
        "\n",
        "# Extract weights and window parameters\n",
        "def extract_weights_and_window(layer):\n",
        "    weights = layer.get_weights()\n",
        "    window_params = {}\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        window_params[\"kernel_size\"] = layer.kernel_size\n",
        "        window_params[\"stride\"] = layer.strides\n",
        "        window_params[\"padding\"] = layer.padding\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        window_params[\"units\"] = layer.units\n",
        "    return weights, window_params\n",
        "\n",
        "# Simulate FPGA communication\n",
        "def simulate_fpga_communication(input_data, output_file, result_queue):\n",
        "    time.sleep(1)  # Simulate communication delay\n",
        "    with open(output_file, 'rb') as f:\n",
        "        data = np.frombuffer(f.read(), dtype=np.float32)\n",
        "    fpga_output = data.reshape(input_data.shape) + np.random.normal(0, 0.05, input_data.shape)\n",
        "    result_queue.put((fpga_output, len(data)))\n",
        "\n",
        "# Layer output function\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# Save data for Kagan in JSON format\n",
        "def save_data_for_kagan(weights, window_params, data_size):\n",
        "    data = {\n",
        "        \"weights\": [w.flatten().tolist() for w in weights],  # Convert weights to list\n",
        "        \"window_params\": window_params,\n",
        "        \"data_size_bytes\": data_size\n",
        "    }\n",
        "    json_file = f\"data_for_kagan_{uuid.uuid4()}.json\"\n",
        "    with open(json_file, 'w') as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "    return json_file\n",
        "\n",
        "# Main simulation function\n",
        "def run_model(model_selection, layer_selection, data_choice, mode):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "\n",
        "    # Load model\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Load test data\n",
        "    if flow_from_directory:\n",
        "        test_data = load_images_with_flow_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "    else:\n",
        "        test_data = load_images_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "\n",
        "    # Handle layer selection\n",
        "    layer_index = None\n",
        "    current_layer = None\n",
        "    if layer_selection and layer_selection != \"None\":\n",
        "        layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "        current_layer = loaded_model.layers[layer_index]\n",
        "\n",
        "    # Data selection\n",
        "    if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "        if flow_from_directory:\n",
        "            input_data = next(test_data)\n",
        "        else:\n",
        "            input_data = next(iter(test_data))\n",
        "        data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "    else:\n",
        "        expected_shape = loaded_model.input.shape[1:]\n",
        "        input_data = np.random.random((8, *expected_shape))\n",
        "        data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "\n",
        "    try:\n",
        "        if layer_index is None or layer_selection == \"None\":\n",
        "            # Run the entire model without acceleration\n",
        "            real_output = loaded_model.predict(input_data, verbose=0)\n",
        "            fpga_output = real_output\n",
        "            serialized_output = real_output.flatten().tobytes()\n",
        "            data_sent_size = len(serialized_output)\n",
        "            weights_info = \"Hızlandırma yapılmadı, ağırlıklar kullanılmadı.\"\n",
        "            json_file = None\n",
        "        else:\n",
        "            # Run with acceleration\n",
        "            weights, window_params = extract_weights_and_window(current_layer)\n",
        "            real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "            # Thread 1: Simulation and file output\n",
        "            output_file_x = f\"file_{uuid.uuid4()}.x\"\n",
        "            output_file_y = f\"file_{uuid.uuid4()}.y\"\n",
        "            with open(output_file_x, 'wb') as f:\n",
        "                f.write(real_output.flatten().tobytes())\n",
        "            with open(output_file_y, 'wb') as f:\n",
        "                for w in weights:\n",
        "                    f.write(w.flatten().tobytes())\n",
        "\n",
        "            # Save data for Kagan\n",
        "            json_file = save_data_for_kagan(weights, window_params, len(real_output.flatten().tobytes()))\n",
        "\n",
        "            # Thread 2: FPGA communication\n",
        "            result_queue = queue.Queue()\n",
        "            comm_thread = threading.Thread(\n",
        "                target=simulate_fpga_communication,\n",
        "                args=(real_output, output_file_x, result_queue)\n",
        "            )\n",
        "            comm_thread.start()\n",
        "            comm_thread.join()\n",
        "\n",
        "            fpga_output, data_sent_size = result_queue.get()\n",
        "            weights_info = f\"Ağırlıklar ve pencere parametreleri: {window_params}, Ağırlık boyutu: {sum(w.size for w in weights)} eleman\"\n",
        "\n",
        "            # Clean up files\n",
        "            os.remove(output_file_x)\n",
        "            os.remove(output_file_y)\n",
        "            if json_file:\n",
        "                os.remove(json_file)\n",
        "\n",
        "        # Convert outputs to NumPy\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        # Similarity calculation\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)\n",
        "\n",
        "        # Expected input shape\n",
        "        expected_input_shape = (loaded_model.input.shape[1:] if layer_index == 0 else\n",
        "                               loaded_model.layers[layer_index - 1].output.shape[1:] if layer_index else\n",
        "                               \"Tam model\")\n",
        "\n",
        "        # Prepare results\n",
        "        output_str = f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok (Tam Model)'}\\n\"\n",
        "        output_str += f\"Mod: {mode}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape if layer_index else input_data.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Kağan'a Gönderilen Veri Boyutu: {data_sent_size} bayt\\n\"\n",
        "        output_str += f\"{weights_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        # Animated HTML output\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok'}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Update layer dropdown\n",
        "def update_layer_dropdown(model_selection):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "    layer_names = [\"None\"] + [f\"Katman {i}: {layer.name} - Çıkış Şekli: {layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'}\"\n",
        "                              for i, layer in enumerate(loaded_model.layers)]\n",
        "    return gr.Dropdown(choices=layer_names, value=\"None\")\n",
        "\n",
        "# Gradio interface\n",
        "with gr.Blocks(title=\"LeNet CNN Model Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# LeNet CNN Model Hızlandırıcı\")\n",
        "    gr.Markdown(\"Modelinizi seçin, katman ve giriş verisi tipini belirleyin. Simülasyon veya donanım modunda FPGA çıktısının gerçek çıktı ile uyumunu görün!\")\n",
        "\n",
        "    # Model and mode selection\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(choices=list(MODELS.keys()), label=\"Model Seçimi\", value=\"LeNet1\")\n",
        "        mode_input = gr.Radio(choices=[\"Simülasyon\", \"Donanım\"], label=\"Çalışma Modu\", value=\"Simülasyon\")\n",
        "\n",
        "    # Layer selection and simulation\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin (None = Hızlandırma Yok)\")\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "            submit_btn = gr.Button(\"Modeli Çalıştır\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Update layer dropdown when model is selected\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=model_input, outputs=layer_input)\n",
        "\n",
        "    # Run the model\n",
        "    submit_btn.click(fn=run_model, inputs=[model_input, layer_input, data_input, mode_input], outputs=[output_text, output_animation])\n",
        "\n",
        "# Start the interface\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NBPM7Z3KeGBC",
        "outputId": "4cb1fd92-defd-483b-d9d6-4bd17c7d59b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.27.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.9.1 (from gradio)\n",
            "  Downloading gradio_client-1.9.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.27.1-py3-none-any.whl (54.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.9.1-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.7/322.7 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m132.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.27.1 gradio-client-1.9.1 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.7 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e6ed0f8aeacc3ff16e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e6ed0f8aeacc3ff16e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf                      #TRY 1\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "import gradio as gr\n",
        "import os\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "!pip install pyserial\n",
        "import serial\n",
        "import struct\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import uuid\n",
        "\n",
        "# Define model and data paths\n",
        "MODELS = {\n",
        "    \"LeNet1\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "        \"flow_from_directory\": True\n",
        "    },\n",
        "    \"LeNet2\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "        \"flow_from_directory\": False\n",
        "    },\n",
        "    \"LeNet3\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "        \"flow_from_directory\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Data loading functions\n",
        "def load_images_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)\n",
        "\n",
        "def load_images_with_flow_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data\n",
        "\n",
        "# Extract weights and window parameters\n",
        "def extract_weights_and_window(layer):\n",
        "    weights = layer.get_weights()\n",
        "    window_params = {}\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        window_params[\"kernel_size\"] = list(layer.kernel_size)\n",
        "        window_params[\"stride\"] = list(layer.strides)\n",
        "        window_params[\"padding\"] = layer.padding\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        window_params[\"units\"] = layer.units\n",
        "    return weights, window_params\n",
        "\n",
        "# FPGA communication function (simulating Vivado-based UART communication)\n",
        "def communicate_with_fpga(input_data, output_file, result_queue, mode):\n",
        "    if mode == \"Simülasyon\":\n",
        "        # Simulate FPGA communication\n",
        "        time.sleep(1)  # Simulate delay\n",
        "        with open(output_file, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), dtype=np.float32)\n",
        "        fpga_output = data.reshape(input_data.shape) + np.random.normal(0, 0.05, input_data.shape)\n",
        "        result_queue.put((fpga_output, len(data)))\n",
        "    else:\n",
        "        # Real FPGA communication via UART\n",
        "        try:\n",
        "            # Configure serial port (adjust COM port and baud rate as needed)\n",
        "            ser = serial.Serial(\n",
        "                port='COM3',  # Kağan'ın kullandığı portu belirtmesi gerekir\n",
        "                baudrate=115200,\n",
        "                timeout=5\n",
        "            )\n",
        "\n",
        "            # Read input data from file\n",
        "            with open(output_file, 'rb') as f:\n",
        "                data = f.read()\n",
        "\n",
        "            # Send data to FPGA\n",
        "            ser.write(data)\n",
        "            ser.flush()\n",
        "\n",
        "            # Receive response from FPGA (assuming same size as input)\n",
        "            response_size = len(data)\n",
        "            response = ser.read(response_size)\n",
        "\n",
        "            # Close serial port\n",
        "            ser.close()\n",
        "\n",
        "            # Convert response to NumPy array\n",
        "            fpga_output = np.frombuffer(response, dtype=np.float32).reshape(input_data.shape)\n",
        "            result_queue.put((fpga_output, len(data)))\n",
        "\n",
        "        except Exception as e:\n",
        "            result_queue.put((None, 0, f\"FPGA iletişimi hatası: {str(e)}\"))\n",
        "\n",
        "# Layer output function\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# Save data for Kagan in binary format\n",
        "def save_data_for_kagan(weights, window_params, data_size, output_data):\n",
        "    bin_file = f\"data_for_kagan_{uuid.uuid4()}.bin\"\n",
        "    with open(bin_file, 'wb') as f:\n",
        "        # Write weights\n",
        "        for w in weights:\n",
        "            f.write(w.flatten().astype(np.float32).tobytes())\n",
        "        # Write window parameters (serialized as binary)\n",
        "        if window_params:\n",
        "            if \"kernel_size\" in window_params:\n",
        "                f.write(struct.pack('ii', *window_params[\"kernel_size\"]))  # 2 integers\n",
        "                f.write(struct.pack('ii', *window_params[\"stride\"]))  # 2 integers\n",
        "                padding_val = 1 if window_params[\"padding\"] == \"valid\" else 0\n",
        "                f.write(struct.pack('i', padding_val))  # 1 integer\n",
        "            elif \"units\" in window_params:\n",
        "                f.write(struct.pack('i', window_params[\"units\"]))  # 1 integer\n",
        "        # Write data size\n",
        "        f.write(struct.pack('Q', data_size))  # Unsigned long long for size\n",
        "        # Write output data\n",
        "        f.write(output_data.flatten().astype(np.float32).tobytes())\n",
        "    return bin_file\n",
        "\n",
        "# Main simulation function\n",
        "def run_model(model_selection, layer_selection, data_choice, mode):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "\n",
        "    # Load model\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Load test data\n",
        "    if flow_from_directory:\n",
        "        test_data = load_images_with_flow_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "    else:\n",
        "        test_data = load_images_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "\n",
        "    # Handle layer selection\n",
        "    layer_index = None\n",
        "    current_layer = None\n",
        "    if layer_selection and layer_selection != \"None\":\n",
        "        layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "        current_layer = loaded_model.layers[layer_index]\n",
        "\n",
        "    # Data selection\n",
        "    if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "        if flow_from_directory:\n",
        "            input_data = next(test_data)\n",
        "        else:\n",
        "            input_data = next(iter(test_data))\n",
        "        data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "    else:\n",
        "        expected_shape = loaded_model.input.shape[1:]\n",
        "        input_data = np.random.random((8, *expected_shape))\n",
        "        data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "\n",
        "    try:\n",
        "        if layer_index is None or layer_selection == \"None\":\n",
        "            # Run the entire model without acceleration\n",
        "            real_output = loaded_model.predict(input_data, verbose=0)\n",
        "            fpga_output = real_output\n",
        "            serialized_output = real_output.flatten().tobytes()\n",
        "            data_sent_size = len(serialized_output)\n",
        "            weights_info = \"Hızlandırma yapılmadı, ağırlıklar kullanılmadı.\"\n",
        "            bin_file = None\n",
        "        else:\n",
        "            # Run with acceleration\n",
        "            weights, window_params = extract_weights_and_window(current_layer)\n",
        "            real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "            # Thread 1: Simulation and file output\n",
        "            output_file_x = f\"file_{uuid.uuid4()}.x\"\n",
        "            output_file_y = f\"file_{uuid.uuid4()}.y\"\n",
        "            with open(output_file_x, 'wb') as f:\n",
        "                f.write(real_output.flatten().tobytes())\n",
        "            with open(output_file_y, 'wb') as f:\n",
        "                for w in weights:\n",
        "                    f.write(w.flatten().tobytes())\n",
        "\n",
        "            # Save data for Kagan in binary format\n",
        "            bin_file = save_data_for_kagan(weights, window_params, len(real_output.flatten().tobytes()), real_output)\n",
        "\n",
        "            # Thread 2: FPGA communication\n",
        "            result_queue = queue.Queue()\n",
        "            comm_thread = threading.Thread(\n",
        "                target=communicate_with_fpga,\n",
        "                args=(real_output, output_file_x, result_queue, mode)\n",
        "            )\n",
        "            comm_thread.start()\n",
        "            comm_thread.join()\n",
        "\n",
        "            fpga_result = result_queue.get()\n",
        "            if len(fpga_result) == 3:  # Error case\n",
        "                raise Exception(fpga_result[2])\n",
        "            fpga_output, data_sent_size = fpga_result\n",
        "            weights_info = f\"Ağırlıklar ve pencere parametreleri: {window_params}, Ağırlık boyutu: {sum(w.size for w in weights)} eleman\"\n",
        "\n",
        "            # Clean up files\n",
        "            os.remove(output_file_x)\n",
        "            os.remove(output_file_y)\n",
        "            if bin_file:\n",
        "                os.remove(bin_file)\n",
        "\n",
        "        # Convert outputs to NumPy\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        # Similarity calculation\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)\n",
        "\n",
        "        # Expected input shape\n",
        "        expected_input_shape = (loaded_model.input.shape[1:] if layer_index == 0 else\n",
        "                               loaded_model.layers[layer_index - 1].output.shape[1:] if layer_index else\n",
        "                               \"Tam model\")\n",
        "\n",
        "        # Prepare results\n",
        "        output_str = f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok (Tam Model)'}\\n\"\n",
        "        output_str += f\"Mod: {mode}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape if layer_index else input_data.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Kağan'a Gönderilen Veri Boyutu: {data_sent_size} bayt\\n\"\n",
        "        output_str += f\"{weights_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        # Animated HTML output\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok'}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Update layer dropdown\n",
        "def update_layer_dropdown(model_selection):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "    layer_names = [\"None\"] + [f\"Katman {i}: {layer.name} - Çıkış Şekli: {layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'}\"\n",
        "                              for i, layer in enumerate(loaded_model.layers)]\n",
        "    return gr.Dropdown(choices=layer_names, value=\"None\")\n",
        "\n",
        "# Gradio interface\n",
        "with gr.Blocks(title=\"LeNet CNN Model Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# LeNet CNN Model Hızlandırıcı\")\n",
        "    gr.Markdown(\"Modelinizi seçin, katman ve giriş verisi tipini belirleyin. Simülasyon veya donanım modunda FPGA çıktısının gerçek çıktı ile uyumunu görün!\")\n",
        "\n",
        "    # Model and mode selection\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(choices=list(MODELS.keys()), label=\"Model Seçimi\", value=\"LeNet1\")\n",
        "        mode_input = gr.Radio(choices=[\"Simülasyon\", \"Donanım\"], label=\"Çalışma Modu\", value=\"Simülasyon\")\n",
        "\n",
        "    # Layer selection and simulation\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin (None = Hızlandırma Yok)\")\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "            submit_btn = gr.Button(\"Modeli Çalıştır\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Update layer dropdown when model is selected\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=model_input, outputs=layer_input)\n",
        "\n",
        "    # Run the model\n",
        "    submit_btn.click(fn=run_model, inputs=[model_input, layer_input, data_input, mode_input], outputs=[output_text, output_animation])\n",
        "\n",
        "# Start the interface\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "U2ozCKPRfYGe",
        "outputId": "68b6135a-70df-4502-f0fa-ab24b6c5b8fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyserial\n",
            "  Downloading pyserial-3.5-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/90.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyserial\n",
            "Successfully installed pyserial-3.5\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6b9132583128d7bb3c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6b9132583128d7bb3c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TRY 2\n",
        "!pip install pyserial\n",
        "!pip install gradio\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "import gradio as gr\n",
        "import os\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "import serial\n",
        "import struct\n",
        "import serial.tools.list_ports\n",
        "import platform\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import uuid\n",
        "\n",
        "\n",
        "# Define model and data paths\n",
        "MODELS = {\n",
        "    \"LeNet1\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "        \"flow_from_directory\": True\n",
        "    },\n",
        "    \"LeNet2\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "        \"flow_from_directory\": False\n",
        "    },\n",
        "    \"LeNet3\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "        \"flow_from_directory\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Data loading functions\n",
        "def load_images_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)\n",
        "\n",
        "def load_images_with_flow_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data\n",
        "\n",
        "# Extract weights and window parameters\n",
        "def extract_weights_and_window(layer):\n",
        "    weights = layer.get_weights()\n",
        "    window_params = {}\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        window_params[\"kernel_size\"] = list(layer.kernel_size)\n",
        "        window_params[\"stride\"] = list(layer.strides)\n",
        "        window_params[\"padding\"] = layer.padding\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        window_params[\"units\"] = layer.units\n",
        "    return weights, window_params\n",
        "\n",
        "# Get available serial ports\n",
        "def get_available_ports():\n",
        "    ports = serial.tools.list_ports.comports()\n",
        "    return [port.device for port in ports]\n",
        "\n",
        "# FPGA communication function (UART for Nexys4DDR)\n",
        "def communicate_with_fpga(input_data, output_file, result_queue, mode):\n",
        "    if mode == \"Simülasyon\":\n",
        "        # Simulate FPGA communication\n",
        "        time.sleep(1)  # Simulate delay\n",
        "        with open(output_file, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), dtype=np.float32)\n",
        "        fpga_output = data.reshape(input_data.shape) + np.random.normal(0, 0.05, input_data.shape)\n",
        "        result_queue.put((fpga_output, len(data)))\n",
        "    else:\n",
        "        # Real FPGA communication via UART for Nexys4DDR\n",
        "        try:\n",
        "            # Select port based on platform\n",
        "            default_port = \"COM3\" if platform.system() == \"Windows\" else \"/dev/ttyUSB0\"\n",
        "            available_ports = get_available_ports()\n",
        "            if default_port not in available_ports:\n",
        "                raise Exception(f\"Port {default_port} bulunamadı. Mevcut portlar: {available_ports or 'Yok'}\")\n",
        "\n",
        "            # Configure serial port for Nexys4DDR\n",
        "            ser = serial.Serial(\n",
        "                port=default_port,\n",
        "                baudrate=115200,\n",
        "                stopbits=serial.STOPBITS_TWO,\n",
        "                bytesize=serial.EIGHTBITS,\n",
        "                parity=serial.PARITY_NONE,\n",
        "                timeout=5\n",
        "            )\n",
        "\n",
        "            # Read input data from file\n",
        "            with open(output_file, 'rb') as f:\n",
        "                data = f.read()\n",
        "\n",
        "            # Send data to FPGA\n",
        "            ser.write(data)\n",
        "            ser.flush()\n",
        "\n",
        "            # Receive response from FPGA (assuming same size as input)\n",
        "            response_size = len(data)\n",
        "            response = ser.read(response_size)\n",
        "\n",
        "            # Close serial port\n",
        "            ser.close()\n",
        "\n",
        "            if len(response) != response_size:\n",
        "                raise Exception(f\"FPGA'dan eksik veri alındı: {len(response)}/{response_size} bayt\")\n",
        "\n",
        "            # Convert response to NumPy array\n",
        "            fpga_output = np.frombuffer(response, dtype=np.float32).reshape(input_data.shape)\n",
        "            result_queue.put((fpga_output, len(data)))\n",
        "\n",
        "        except Exception as e:\n",
        "            available_ports = get_available_ports()\n",
        "            error_msg = f\"FPGA iletişimi hatası: {str(e)}\\nMevcut portlar: {available_ports or 'Yok'}\\nLütfen doğru portu kontrol edin veya FPGA'nın bağlı olduğundan emin olun.\"\n",
        "            result_queue.put((None, 0, error_msg))\n",
        "\n",
        "# Layer output function\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# Save data for Kagan in binary format\n",
        "def save_data_for_kagan(weights, window_params, data_size, output_data):\n",
        "    bin_file = f\"data_for_kagan_{uuid.uuid4()}.bin\"\n",
        "    with open(bin_file, 'wb') as f:\n",
        "        # Write weights\n",
        "        for w in weights:\n",
        "            f.write(w.flatten().astype(np.float32).tobytes())\n",
        "        # Write window parameters (Kağan'ın sırasına göre)\n",
        "        if window_params:\n",
        "            if \"kernel_size\" in window_params:\n",
        "                f.write(struct.pack('ii', *window_params[\"kernel_size\"]))  # 2 integers\n",
        "                f.write(struct.pack('ii', *window_params[\"stride\"]))  # 2 integers\n",
        "                padding_val = 1 if window_params[\"padding\"] == \"valid\" else 0\n",
        "                f.write(struct.pack('i', padding_val))  # 1 integer\n",
        "            elif \"units\" in window_params:\n",
        "                f.write(struct.pack('i', window_params[\"units\"]))  # 1 integer\n",
        "        # Write data size\n",
        "        f.write(struct.pack('Q', data_size))  # Unsigned long long for size\n",
        "        # Write output data\n",
        "        f.write(output_data.flatten().astype(np.float32).tobytes())\n",
        "    return bin_file\n",
        "\n",
        "# Main simulation function\n",
        "def run_model(model_selection, layer_selection, data_choice, mode):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "\n",
        "    # Load model\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Load test data\n",
        "    if flow_from_directory:\n",
        "        test_data = load_images_with_flow_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "    else:\n",
        "        test_data = load_images_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "\n",
        "    # Handle layer selection\n",
        "    layer_index = None\n",
        "    current_layer = None\n",
        "    if layer_selection and layer_selection != \"None\":\n",
        "        layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "        current_layer = loaded_model.layers[layer_index]\n",
        "\n",
        "    # Data selection\n",
        "    if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "        if flow_from_directory:\n",
        "            input_data = next(test_data)\n",
        "        else:\n",
        "            input_data = next(iter(test_data))\n",
        "        data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "    else:\n",
        "        expected_shape = loaded_model.input.shape[1:]\n",
        "        input_data = np.random.random((8, *expected_shape))\n",
        "        data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "\n",
        "    try:\n",
        "        if layer_index is None or layer_selection == \"None\":\n",
        "            # Run the entire model without acceleration\n",
        "            real_output = loaded_model.predict(input_data, verbose=0)\n",
        "            fpga_output = real_output\n",
        "            serialized_output = real_output.flatten().tobytes()\n",
        "            data_sent_size = len(serialized_output)\n",
        "            weights_info = \"Hızlandırma yapılmadı, ağırlıklar kullanılmadı.\"\n",
        "            bin_file = None\n",
        "        else:\n",
        "            # Run with acceleration\n",
        "            weights, window_params = extract_weights_and_window(current_layer)\n",
        "            real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "            # Thread 1: Simulation and file output\n",
        "            output_file_x = f\"file_{uuid.uuid4()}.x\"\n",
        "            output_file_y = f\"file_{uuid.uuid4()}.y\"\n",
        "            with open(output_file_x, 'wb') as f:\n",
        "                f.write(real_output.flatten().tobytes())\n",
        "            with open(output_file_y, 'wb') as f:\n",
        "                for w in weights:\n",
        "                    f.write(w.flatten().tobytes())\n",
        "\n",
        "            # Save data for Kagan in binary format\n",
        "            bin_file = save_data_for_kagan(weights, window_params, len(real_output.flatten().tobytes()), real_output)\n",
        "\n",
        "            # Thread 2: FPGA communication\n",
        "            result_queue = queue.Queue()\n",
        "            comm_thread = threading.Thread(\n",
        "                target=communicate_with_fpga,\n",
        "                args=(real_output, output_file_x, result_queue, mode)\n",
        "            )\n",
        "            comm_thread.start()\n",
        "            comm_thread.join()\n",
        "\n",
        "            fpga_result = result_queue.get()\n",
        "            if len(fpga_result) == 3:  # Error case\n",
        "                raise Exception(fpga_result[2])\n",
        "            fpga_output, data_sent_size = fpga_result\n",
        "            weights_info = f\"Ağırlıklar ve pencere parametreleri: {window_params}, Ağırlık boyutu: {sum(w.size for w in weights)} eleman\"\n",
        "\n",
        "            # Clean up files\n",
        "            os.remove(output_file_x)\n",
        "            os.remove(output_file_y)\n",
        "            if bin_file:\n",
        "                os.remove(bin_file)\n",
        "\n",
        "        # Convert outputs to NumPy\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        # Similarity calculation\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)\n",
        "\n",
        "        # Expected input shape\n",
        "        expected_input_shape = (loaded_model.input.shape[1:] if layer_index == 0 else\n",
        "                               loaded_model.layers[layer_index - 1].output.shape[1:] if layer_index else\n",
        "                               \"Tam model\")\n",
        "\n",
        "        # Prepare results\n",
        "        output_str = f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok (Tam Model)'}\\n\"\n",
        "        output_str += f\"Mod: {mode}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape if layer_index else input_data.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Kağan'a Gönderilen Veri Boyutu: {data_sent_size} bayt\\n\"\n",
        "        output_str += f\"{weights_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        # Animated HTML output\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok'}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Update layer dropdown\n",
        "def update_layer_dropdown(model_selection):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "    layer_names = [\"None\"] + [f\"Katman {i}: {layer.name} - Çıkış Şekli: {layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'}\"\n",
        "                              for i, layer in enumerate(loaded_model.layers)]\n",
        "    return gr.Dropdown(choices=layer_names, value=\"None\")\n",
        "\n",
        "# Gradio interface\n",
        "with gr.Blocks(title=\"LeNet CNN Model Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# LeNet CNN Model Hızlandırıcı\")\n",
        "    gr.Markdown(\"Modelinizi seçin, katman ve giriş verisi tipini belirleyin. Simülasyon veya donanım modunda FPGA çıktısının gerçek çıktı ile uyumunu görün!\")\n",
        "\n",
        "    # Model and mode selection\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(choices=list(MODELS.keys()), label=\"Model Seçimi\", value=\"LeNet1\")\n",
        "        mode_input = gr.Radio(choices=[\"Simülasyon\", \"Donanım\"], label=\"Çalışma Modu\", value=\"Simülasyon\")\n",
        "\n",
        "    # Layer selection and simulation\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin (None = Hızlandırma Yok)\")\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "            submit_btn = gr.Button(\"Modeli Çalıştır\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Update layer dropdown when model is selected\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=model_input, outputs=layer_input)\n",
        "\n",
        "    # Run the model\n",
        "    submit_btn.click(fn=run_model, inputs=[model_input, layer_input, data_input, mode_input], outputs=[output_text, output_animation])\n",
        "\n",
        "# Start the interface\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oQm1rJQ3jpMs",
        "outputId": "ff4a1bab-fccc-49f5-c76b-918662f0d9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyserial in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.27.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.9.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.9.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f2e9bb57bda6b6e35f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f2e9bb57bda6b6e35f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  #Last CODE\n",
        "# Gerekli kütüphaneleri içe aktar\n",
        "!pip install pyserial\n",
        "!pip install gradio\n",
        "import tensorflow as tf  # Sinir ağı modeli için\n",
        "import numpy as np  # Sayısal işlemler için\n",
        "from tensorflow.keras import layers  # Keras katmanları için\n",
        "import gradio as gr  # Kullanıcı arayüzü için\n",
        "import os  # Dosya işlemleri için\n",
        "import threading  # Çoklu iş parçacığı için\n",
        "import queue  # İş parçacıkları arası veri aktarımı için\n",
        "import time  # Simülasyon gecikmesi için\n",
        "import serial  # UART iletişimi için\n",
        "import struct  # Binary veri paketleme için\n",
        "import serial.tools.list_ports  # Mevcut seri portları listelemek için\n",
        "import platform  # İşletim sistemi bilgisi için\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Resim yükleme ve işleme için\n",
        "import uuid  # Benzersiz dosya adları için\n",
        "\n",
        "# Model ve veri yollarını tanımla\n",
        "MODELS = {\n",
        "    \"LeNet1\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",  # Model dosya yolu\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",  # Test veri yolu\n",
        "        \"flow_from_directory\": True  # Alt klasörlerden veri yükleme\n",
        "    },\n",
        "    \"LeNet2\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "        \"flow_from_directory\": False\n",
        "    },\n",
        "    \"LeNet3\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "        \"flow_from_directory\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Veri yükleme fonksiyonu: Alt klasörsüz dizinlerden resimleri yükler\n",
        "def load_images_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)  # Resmi belirtilen boyutta yükle\n",
        "            img_array = img_to_array(img) / 255.0  # Resmi diziye çevir ve normalize et\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)  # Veriyi toplu işleme uygun hale getir\n",
        "\n",
        "# Veri yükleme fonksiyonu: Alt klasörlü dizinlerden resimleri yükler\n",
        "def load_images_with_flow_from_directory(directory, target_size=(32, 32), batch_size=8):\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)  # Normalizasyon için veri üreteci\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data  # ImageDataGenerator nesnesi döndür\n",
        "\n",
        "# Ağırlık ve pencere parametrelerini çıkarma fonksiyonu\n",
        "def extract_weights_and_window(layer):\n",
        "    weights = layer.get_weights()  # Katmanın ağırlıklarını al\n",
        "    window_params = {}  # Pencere parametrelerini saklamak için sözlük\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        window_params[\"kernel_size\"] = list(layer.kernel_size)  # Çekirdek boyutu (ör. [5, 5])\n",
        "        window_params[\"stride\"] = list(layer.strides)  # Adım boyutu (ör. [1, 1])\n",
        "        window_params[\"padding\"] = layer.padding  # Dolgu tipi (valid veya same)\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        window_params[\"units\"] = layer.units  # Birim sayısı\n",
        "    return weights, window_params  # Ağırlıklar ve parametreler döndür\n",
        "\n",
        "# Mevcut seri portları listeleyen fonksiyon\n",
        "def get_available_ports():\n",
        "    ports = serial.tools.list_ports.comports()  # Sistemdeki tüm seri portları al\n",
        "    return [port.device for port in ports]  # Port adlarını listele\n",
        "\n",
        "# FPGA ile iletişim fonksiyonu (Nexys4DDR için UART)\n",
        "def communicate_with_fpga(input_data, output_file, result_queue, mode):\n",
        "    if mode == \"Simülasyon\":\n",
        "        # Simülasyon modu: FPGA yerine gürültü eklenmiş veri döndür\n",
        "        time.sleep(1)  # İletişim gecikmesini taklit et\n",
        "        with open(output_file, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), dtype=np.float32)  # Dosyadan veriyi oku\n",
        "        fpga_output = data.reshape(input_data.shape) + np.random.normal(0, 0.05, input_data.shape)  # Gürültü ekle\n",
        "        result_queue.put((fpga_output, len(data)))  # Sonucu kuyruğa ekle\n",
        "    else:\n",
        "        # Donanım modu: Nexys4DDR ile UART üzerinden gerçek iletişim\n",
        "        try:\n",
        "            # Platforma göre varsayılan port seç\n",
        "            default_port = \"COM3\" if platform.system() == \"Windows\" else \"/dev/ttyUSB0\"\n",
        "            available_ports = get_available_ports()\n",
        "            if default_port not in available_ports:\n",
        "                raise Exception(f\"Port {default_port} bulunamadı. Mevcut portlar: {available_ports or 'Yok'}\")\n",
        "\n",
        "            # Seri portu yapılandır (Nexys4DDR için UART ayarları)\n",
        "            ser = serial.Serial(\n",
        "                port=default_port,\n",
        "                baudrate=115200,  # 115200 baud rate\n",
        "                stopbits=serial.STOPBITS_TWO,  # 2 stop bit\n",
        "                bytesize=serial.EIGHTBITS,  # 8 veri biti\n",
        "                parity=serial.PARITY_NONE,  # Parity yok\n",
        "                timeout=5  # 5 saniye zaman aşımı\n",
        "            )\n",
        "\n",
        "            # Dosyadan veriyi oku\n",
        "            with open(output_file, 'rb') as f:\n",
        "                data = f.read()\n",
        "\n",
        "            # Veriyi FPGA'ya gönder\n",
        "            ser.write(data)\n",
        "            ser.flush()  # Gönderim tamamlanana kadar bekle\n",
        "\n",
        "            # FPGA'dan yanıtı al (aynı boyutta veri bekleniyor)\n",
        "            response_size = len(data)\n",
        "            response = ser.read(response_size)\n",
        "\n",
        "            # Seri portu kapat\n",
        "            ser.close()\n",
        "\n",
        "            # Yanıtın doğruluğunu kontrol et\n",
        "            if len(response) != response_size:\n",
        "                raise Exception(f\"FPGA'dan eksik veri alındı: {len(response)}/{response_size} bayt\")\n",
        "\n",
        "            # Yanıtı NumPy dizisine çevir\n",
        "            fpga_output = np.frombuffer(response, dtype=np.float32).reshape(input_data.shape)\n",
        "            result_queue.put((fpga_output, len(data)))\n",
        "\n",
        "        except Exception as e:\n",
        "            # Hata durumunda, mevcut portları listele ve açıklayıcı mesaj döndür\n",
        "            available_ports = get_available_ports()\n",
        "            error_msg = f\"FPGA iletişimi hatası: {str(e)}\\nMevcut portlar: {available_ports or 'Yok'}\\nLütfen doğru portu kontrol edin veya FPGA'nın bağlı olduğundan emin olun.\"\n",
        "            result_queue.put((None, 0, error_msg))\n",
        "\n",
        "# Katman çıktısını hesaplama fonksiyonu\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    if layer_index == 0:\n",
        "        # İlk katman için: Modelin girişinden ilk katman çıkışına kadar hesapla\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        # Diğer katmanlar için: Önceki katmanların çıktısını adım adım hesapla\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# Kağan için veriyi binary formatta kaydetme fonksiyonu\n",
        "def save_data_for_kagan(weights, window_params, data_size, output_data):\n",
        "    bin_file = f\"data_for_kagan_{uuid.uuid4()}.bin\"  # Benzersiz dosya adı\n",
        "    with open(bin_file, 'wb') as f:\n",
        "        # Ağırlıkları yaz (Kağan'ın sırasına göre önce ağırlıklar)\n",
        "        for w in weights:\n",
        "            f.write(w.flatten().astype(np.float32).tobytes())  # float32 formatında\n",
        "        # Pencere parametrelerini yaz\n",
        "        if window_params:\n",
        "            if \"kernel_size\" in window_params:\n",
        "                f.write(struct.pack('ii', *window_params[\"kernel_size\"]))  # 2 tamsayı (8 bayt)\n",
        "                f.write(struct.pack('ii', *window_params[\"stride\"]))  # 2 tamsayı (8 bayt)\n",
        "                padding_val = 1 if window_params[\"padding\"] == \"valid\" else 0\n",
        "                f.write(struct.pack('i', padding_val))  # 1 tamsayı (4 bayt)\n",
        "            elif \"units\" in window_params:\n",
        "                f.write(struct.pack('i', window_params[\"units\"]))  # 1 tamsayı (4 bayt)\n",
        "        # Veri boyutunu yaz\n",
        "        f.write(struct.pack('Q', data_size))  # Unsigned long long (8 bayt)\n",
        "        # Çıkış verilerini yaz\n",
        "        f.write(output_data.flatten().astype(np.float32).tobytes())  # float32 formatında\n",
        "    return bin_file  # Oluşturulan dosyanın adını döndür\n",
        "\n",
        "# Ana simülasyon ve çalıştırma fonksiyonu\n",
        "def run_model(model_selection, layer_selection, data_choice, mode):\n",
        "    model_info = MODELS[model_selection]  # Seçilen modelin bilgilerini al\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "\n",
        "    # Modeli yükle\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Test verisini yükle\n",
        "    if flow_from_directory:\n",
        "        test_data = load_images_with_flow_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "    else:\n",
        "        test_data = load_images_from_directory(test_path, target_size=(32, 32), batch_size=8)\n",
        "\n",
        "    # Katman seçimini işle\n",
        "    layer_index = None\n",
        "    current_layer = None\n",
        "    if layer_selection and layer_selection != \"None\":\n",
        "        layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "        current_layer = loaded_model.layers[layer_index]\n",
        "\n",
        "    # Veri seçimini yap\n",
        "    if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "        if flow_from_directory:\n",
        "            input_data = next(test_data)  # ImageDataGenerator'dan bir grup veri al\n",
        "        else:\n",
        "            input_data = next(iter(test_data))  # tf.data.Dataset'ten bir grup veri al\n",
        "        data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "    else:\n",
        "        expected_shape = loaded_model.input.shape[1:]  # Modelin beklediği giriş şekli\n",
        "        input_data = np.random.random((8, *expected_shape))  # Rastgele veri oluştur\n",
        "        data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "\n",
        "    try:\n",
        "        if layer_index is None or layer_selection == \"None\":\n",
        "            # Hızlandırma yok: Modelin tamamını çalıştır\n",
        "            real_output = loaded_model.predict(input_data, verbose=0)\n",
        "            fpga_output = real_output  # FPGA kullanılmıyor\n",
        "            serialized_output = real_output.flatten().tobytes()\n",
        "            data_sent_size = len(serialized_output)\n",
        "            weights_info = \"Hızlandırma yapılmadı, ağırlıklar kullanılmadı.\"\n",
        "            bin_file = None\n",
        "        else:\n",
        "            # Hızlandırma ile çalış: Seçilen katmanı FPGA'da işle\n",
        "            weights, window_params = extract_weights_and_window(current_layer)  # Ağırlık ve parametreleri al\n",
        "            real_output = get_layer_output(loaded_model, layer_index, input_data)  # Katman çıktısını hesapla\n",
        "\n",
        "            # Thread 1: Simülasyon ve dosya çıktısı\n",
        "            output_file_x = f\"file_{uuid.uuid4()}.x\"  # Çıkış verileri için dosya\n",
        "            output_file_y = f\"file_{uuid.uuid4()}.y\"  # Ağırlıklar için dosya\n",
        "            with open(output_file_x, 'wb') as f:\n",
        "                f.write(real_output.flatten().tobytes())  # Çıkış verilerini yaz\n",
        "            with open(output_file_y, 'wb') as f:\n",
        "                for w in weights:\n",
        "                    f.write(w.flatten().tobytes())  # Ağırlıkları yaz\n",
        "\n",
        "            # Kağan için veriyi binary formatta kaydet\n",
        "            bin_file = save_data_for_kagan(weights, window_params, len(real_output.flatten().tobytes()), real_output)\n",
        "\n",
        "            # Thread 2: FPGA iletişimi\n",
        "            result_queue = queue.Queue()\n",
        "            comm_thread = threading.Thread(\n",
        "                target=communicate_with_fpga,\n",
        "                args=(real_output, output_file_x, result_queue, mode)\n",
        "            )\n",
        "            comm_thread.start()\n",
        "            comm_thread.join()\n",
        "\n",
        "            # FPGA sonucunu al\n",
        "            fpga_result = result_queue.get()\n",
        "            if len(fpga_result) == 3:  # Hata durumu\n",
        "                raise Exception(fpga_result[2])\n",
        "            fpga_output, data_sent_size = fpga_result\n",
        "            weights_info = f\"Ağırlıklar ve pencere parametreleri: {window_params}, Ağırlık boyutu: {sum(w.size for w in weights)} eleman\"\n",
        "\n",
        "            # Dosyaları temizle\n",
        "            os.remove(output_file_x)\n",
        "            os.remove(output_file_y)\n",
        "            if bin_file:\n",
        "                os.remove(bin_file)\n",
        "\n",
        "        # Çıktıları NumPy formatına çevir\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        # Benzerlik skorunu hesapla (MSE ile)\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)\n",
        "\n",
        "        # Beklenen giriş şeklini belirle\n",
        "        expected_input_shape = (loaded_model.input.shape[1:] if layer_index == 0 else\n",
        "                               loaded_model.layers[layer_index - 1].output.shape[1:] if layer_index else\n",
        "                               \"Tam model\")\n",
        "\n",
        "        # Sonuçları hazırla\n",
        "        output_str = f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok (Tam Model)'}\\n\"\n",
        "        output_str += f\"Mod: {mode}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape if layer_index else input_data.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Kağan'a Gönderilen Veri Boyutu: {data_sent_size} bayt\\n\"\n",
        "        output_str += f\"{weights_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        # Animasyonlu HTML çıktısı\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        # Hata durumunda açıklayıcı mesaj döndür\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok'}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Katman seçim dropdown'unu güncelleme fonksiyonu\n",
        "def update_layer_dropdown(model_selection):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    loaded_model = tf.keras.models.load_model(model_path)  # Modeli yükle\n",
        "    layer_names = [\"None\"] + [f\"Katman {i}: {layer.name} - Çıkış Şekli: {layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'}\"\n",
        "                              for i, layer in enumerate(loaded_model.layers)]  # Katman adlarını ve şekillerini listele\n",
        "    return gr.Dropdown(choices=layer_names, value=\"None\")  # Dropdown nesnesi döndür\n",
        "\n",
        "# Gradio arayüzünü oluştur\n",
        "with gr.Blocks(title=\"LeNet CNN Model Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# LeNet CNN Model Hızlandırıcı\")  # Başlık\n",
        "    gr.Markdown(\"Modelinizi seçin, katman ve giriş verisi tipini belirleyin. Simülasyon veya donanım modunda FPGA çıktısının gerçek çıktı ile uyumunu görün!\")  # Açıklama\n",
        "\n",
        "    # Model ve mod seçimi\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(choices=list(MODELS.keys()), label=\"Model Seçimi\", value=\"LeNet1\")  # Model seçimi dropdown\n",
        "        mode_input = gr.Radio(choices=[\"Simülasyon\", \"Donanım\"], label=\"Çalışma Modu\", value=\"Simülasyon\")  # Simülasyon/Donanım radyo düğmesi\n",
        "\n",
        "    # Katman seçimi ve simülasyon\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin (None = Hızlandırma Yok)\")  # Katman seçimi dropdown\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")  # Veri seçimi radyo düğmesi\n",
        "            submit_btn = gr.Button(\"Modeli Çalıştır\", variant=\"primary\")  # Çalıştırma düğmesi\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)  # Sonuçları gösteren metin kutusu\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")  # Animasyonlu çıktı\n",
        "\n",
        "    # Model seçildiğinde katman dropdown'unu güncelle\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=model_input, outputs=layer_input)\n",
        "\n",
        "    # Modeli çalıştır\n",
        "    submit_btn.click(fn=run_model, inputs=[model_input, layer_input, data_input, mode_input], outputs=[output_text, output_animation])\n",
        "\n",
        "# Arayüzü başlat\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oMwx_G8ioVRs",
        "outputId": "e5fcae35-ee75-4db5-c045-54133c4d7ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyserial in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.32.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://09df503d8095f222a6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://09df503d8095f222a6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerekli kütüphaneleri içe aktar  #LAST CODE2\n",
        "!pip install pyserial\n",
        "!pip install gradio\n",
        "import tensorflow as tf  # Sinir ağı modeli için\n",
        "import numpy as np  # Sayısal işlemler için\n",
        "from tensorflow.keras import layers  # Keras katmanları için\n",
        "import gradio as gr  # Kullanıcı arayüzü için\n",
        "import os  # Dosya işlemleri için\n",
        "import threading  # Çoklu iş parçacığı için\n",
        "import queue  # İş parçacıkları arası veri aktarımı için\n",
        "import time  # Simülasyon gecikmesi için\n",
        "import serial  # UART iletişimi için\n",
        "import struct  # Binary veri paketleme için\n",
        "import serial.tools.list_ports  # Mevcut seri portları listelemek için\n",
        "import platform  # İşletim sistemi bilgisi için\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Resim yükleme ve işleme için\n",
        "import uuid  # Benzersiz dosya adları için\n",
        "\n",
        "# Model ve veri yollarını tanımla\n",
        "MODELS = {\n",
        "    \"MobilNet1\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet1/saved_model/mobilenet_model.keras\",  # Model dosya yolu\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",  # Test veri yolu\n",
        "        \"flow_from_directory\": True  # Alt klasörlerden veri yükleme\n",
        "    },\n",
        "    \"MobilNet2\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet2/saved_model/mobilenet_model.keras\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "        \"flow_from_directory\": False\n",
        "    },\n",
        "    \"MobilNet3\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet3/saved_model/mobilenet_model.keras\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "        \"flow_from_directory\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Veri yükleme fonksiyonu: Alt klasörsüz dizinlerden resimleri yükler\n",
        "def load_images_from_directory(directory, target_size=(224, 224), batch_size=8):\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)  # Resmi belirtilen boyutta yükle\n",
        "            img_array = img_to_array(img) / 255.0  # Resmi diziye çevir ve normalize et\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)  # Veriyi toplu işleme uygun hale getir\n",
        "\n",
        "# Veri yükleme fonksiyonu: Alt klasörlü dizinlerden resimleri yükler\n",
        "def load_images_with_flow_from_directory(directory, target_size=(224, 224), batch_size=8):\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)  # Normalizasyon için veri üreteci\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data  # ImageDataGenerator nesnesi döndür\n",
        "\n",
        "# Ağırlık ve pencere parametrelerini çıkarma fonksiyonu\n",
        "def extract_weights_and_window(layer):\n",
        "    weights = layer.get_weights()  # Katmanın ağırlıklarını al\n",
        "    window_params = {}  # Pencere parametrelerini saklamak için sözlük\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        window_params[\"kernel_size\"] = list(layer.kernel_size)  # Çekirdek boyutu\n",
        "        window_params[\"stride\"] = list(layer.strides)  # Adım boyutu\n",
        "        window_params[\"padding\"] = layer.padding  # Dolgu tipi\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        window_params[\"units\"] = layer.units  # Birim sayısı\n",
        "    return weights, window_params  # Ağırlıklar ve parametreler döndür\n",
        "\n",
        "# Mevcut seri portları listeleyen fonksiyon\n",
        "def get_available_ports():\n",
        "    ports = serial.tools.list_ports.comports()  # Sistemdeki tüm seri portları al\n",
        "    return [port.device for port in ports]  # Port adlarını listele\n",
        "\n",
        "# FPGA ile iletişim fonksiyonu (Nexys4DDR için UART)\n",
        "def communicate_with_fpga(input_data, output_file, result_queue, mode):\n",
        "    if mode == \"Simülasyon\":\n",
        "        # Simülasyon modu: FPGA yerine gürültü eklenmiş veri döndür\n",
        "        time.sleep(1)  # İletişim gecikmesini taklit et\n",
        "        with open(output_file, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), dtype=np.float32)  # Dosyadan veriyi oku\n",
        "        fpga_output = data.reshape(input_data.shape) + np.random.normal(0, 0.05, input_data.shape)  # Gürültü ekle\n",
        "        result_queue.put((fpga_output, len(data)))  # Sonucu kuyruğa ekle\n",
        "    else:\n",
        "        # Donanım modu: Nexys4DDR ile UART üzerinden gerçek iletişim\n",
        "        try:\n",
        "            # Platforma göre varsayılan port seç\n",
        "            default_port = \"COM3\" if platform.system() == \"Windows\" else \"/dev/ttyUSB0\"\n",
        "            available_ports = get_available_ports()\n",
        "            if default_port not in available_ports:\n",
        "                raise Exception(f\"Port {default_port} bulunamadı. Mevcut portlar: {available_ports or 'Yok'}\")\n",
        "\n",
        "            # Seri portu yapılandır\n",
        "            ser = serial.Serial(\n",
        "                port=default_port,\n",
        "                baudrate=115200,\n",
        "                stopbits=serial.STOPBITS_TWO,\n",
        "                bytesize=serial.EIGHTBITS,\n",
        "                parity=serial.PARITY_NONE,\n",
        "                timeout=5\n",
        "            )\n",
        "\n",
        "            # Dosyadan veriyi oku\n",
        "            with open(output_file, 'rb') as f:\n",
        "                data = f.read()\n",
        "\n",
        "            # Veriyi FPGA'ya gönder\n",
        "            ser.write(data)\n",
        "            ser.flush()\n",
        "\n",
        "            # FPGA'dan yanıtı al\n",
        "            response_size = len(data)\n",
        "            response = ser.read(response_size)\n",
        "\n",
        "            # Seri portu kapat\n",
        "            ser.close()\n",
        "\n",
        "            # Yanıtın doğruluğunu kontrol et\n",
        "            if len(response) != response_size:\n",
        "                raise Exception(f\"FPGA'dan eksik veri alındı: {len(response)}/{response_size} bayt\")\n",
        "\n",
        "            # Yanıtı NumPy dizisine çevir\n",
        "            fpga_output = np.frombuffer(response, dtype=np.float32).reshape(input_data.shape)\n",
        "            result_queue.put((fpga_output, len(data)))\n",
        "\n",
        "        except Exception as e:\n",
        "            # Hata durumunda açıklayıcı mesaj döndür\n",
        "            available_ports = get_available_ports()\n",
        "            error_msg = f\"FPGA iletişimi hatası: {str(e)}\\nMevcut portlar: {available_ports or 'Yok'}\\nLütfen doğru portu kontrol edin veya FPGA'nın bağlı olduğundan emin olun.\"\n",
        "            result_queue.put((None, 0, error_msg))\n",
        "\n",
        "# Katman çıktısını hesaplama fonksiyonu\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# Kağan için veriyi binary formatta kaydetme fonksiyonu\n",
        "def save_data_for_kagan(weights, window_params, data_size, output_data):\n",
        "    bin_file = f\"data_for_kagan_{uuid.uuid4()}.bin\"\n",
        "    with open(bin_file, 'wb') as f:\n",
        "        for w in weights:\n",
        "            f.write(w.flatten().astype(np.float32).tobytes())\n",
        "        if window_params:\n",
        "            if \"kernel_size\" in window_params:\n",
        "                f.write(struct.pack('ii', *window_params[\"kernel_size\"]))\n",
        "                f.write(struct.pack('ii', *window_params[\"stride\"]))\n",
        "                padding_val = 1 if window_params[\"padding\"] == \"valid\" else 0\n",
        "                f.write(struct.pack('i', padding_val))\n",
        "            elif \"units\" in window_params:\n",
        "                f.write(struct.pack('i', window_params[\"units\"]))\n",
        "        f.write(struct.pack('Q', data_size))\n",
        "        f.write(output_data.flatten().astype(np.float32).tobytes())\n",
        "    return bin_file\n",
        "\n",
        "# Ana simülasyon ve çalıştırma fonksiyonu\n",
        "def run_model(model_selection, layer_selection, data_choice, mode):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "\n",
        "    # Modeli yükle\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Test verisini yükle\n",
        "    if flow_from_directory:\n",
        "        test_data = load_images_with_flow_from_directory(test_path, target_size=(224, 224), batch_size=8)\n",
        "    else:\n",
        "        test_data = load_images_from_directory(test_path, target_size=(224, 224), batch_size=8)\n",
        "\n",
        "    # Katman seçimini işle\n",
        "    layer_index = None\n",
        "    current_layer = None\n",
        "    if layer_selection and layer_selection != \"None\":\n",
        "        layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "        current_layer = loaded_model.layers[layer_index]\n",
        "\n",
        "    # Veri seçimini yap\n",
        "    if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "        if flow_from_directory:\n",
        "            input_data = next(test_data)\n",
        "        else:\n",
        "            input_data = next(iter(test_data))\n",
        "        data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "    else:\n",
        "        expected_shape = loaded_model.input.shape[1:]\n",
        "        input_data = np.random.random((8, *expected_shape))\n",
        "        data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "\n",
        "    try:\n",
        "        if layer_index is None or layer_selection == \"None\":\n",
        "            real_output = loaded_model.predict(input_data, verbose=0)\n",
        "            fpga_output = real_output\n",
        "            serialized_output = real_output.flatten().tobytes()\n",
        "            data_sent_size = len(serialized_output)\n",
        "            weights_info = \"Hızlandırma yapılmadı, ağırlıklar kullanılmadı.\"\n",
        "            bin_file = None\n",
        "        else:\n",
        "            weights, window_params = extract_weights_and_window(current_layer)\n",
        "            real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "            output_file_x = f\"file_{uuid.uuid4()}.x\"\n",
        "            output_file_y = f\"file_{uuid.uuid4()}.y\"\n",
        "            with open(output_file_x, 'wb') as f:\n",
        "                f.write(real_output.flatten().tobytes())\n",
        "            with open(output_file_y, 'wb') as f:\n",
        "                for w in weights:\n",
        "                    f.write(w.flatten().tobytes())\n",
        "\n",
        "            bin_file = save_data_for_kagan(weights, window_params, len(real_output.flatten().tobytes()), real_output)\n",
        "\n",
        "            result_queue = queue.Queue()\n",
        "            comm_thread = threading.Thread(\n",
        "                target=communicate_with_fpga,\n",
        "                args=(real_output, output_file_x, result_queue, mode)\n",
        "            )\n",
        "            comm_thread.start()\n",
        "            comm_thread.join()\n",
        "\n",
        "            fpga_result = result_queue.get()\n",
        "            if len(fpga_result) == 3:\n",
        "                raise Exception(fpga_result[2])\n",
        "            fpga_output, data_sent_size = fpga_result\n",
        "            weights_info = f\"Ağırlıklar ve pencere parametreleri: {window_params}, Ağırlık boyutu: {sum(w.size for w in weights)} eleman\"\n",
        "\n",
        "            os.remove(output_file_x)\n",
        "            os.remove(output_file_y)\n",
        "            if bin_file:\n",
        "                os.remove(bin_file)\n",
        "\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)\n",
        "\n",
        "        expected_input_shape = (loaded_model.input.shape[1:] if layer_index == 0 else\n",
        "                               loaded_model.layers[layer_index - 1].output.shape[1:] if layer_index else\n",
        "                               \"Tam model\")\n",
        "\n",
        "        output_str = f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok (Tam Model)'}\\n\"\n",
        "        output_str += f\"Mod: {mode}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape if layer_index else input_data.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Kağan'a Gönderilen Veri Boyutu: {data_sent_size} bayt\\n\"\n",
        "        output_str += f\"{weights_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok'}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Katman seçim dropdown'unu güncelleme fonksiyonu\n",
        "def update_layer_dropdown(model_selection):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "    layer_names = [\"None\"] + [f\"Katman {i}: {layer.name} - Çıkış Şekli: {layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'}\"\n",
        "                              for i, layer in enumerate(loaded_model.layers)]\n",
        "    return gr.Dropdown(choices=layer_names, value=\"None\")\n",
        "\n",
        "# Gradio arayüzünü oluştur\n",
        "with gr.Blocks(title=\"MobileNet CNN Model Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# MobileNet CNN Model Hızlandırıcı\")  # Başlık\n",
        "    gr.Markdown(\"Modelinizi seçin, katman ve giriş verisi tipini belirleyin. Simülasyon veya donanım modunda FPGA çıktısının gerçek çıktı ile uyumunu görün!\")  # Açıklama\n",
        "\n",
        "    # Model ve mod seçimi\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(choices=list(MODELS.keys()), label=\"Model Seçimi\", value=\"MobilNet1\")\n",
        "        mode_input = gr.Radio(choices=[\"Simülasyon\", \"Donanım\"], label=\"Çalışma Modu\", value=\"Simülasyon\")\n",
        "\n",
        "    # Katman seçimi ve simülasyon\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin (None = Hızlandırma Yok)\")\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "            submit_btn = gr.Button(\"Modeli Çalıştır\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Model seçildiğinde katman dropdown'unu güncelle\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=model_input, outputs=layer_input)\n",
        "\n",
        "    # Modeli çalıştır\n",
        "    submit_btn.click(fn=run_model, inputs=[model_input, layer_input, data_input, mode_input], outputs=[output_text, output_animation])\n",
        "\n",
        "# Arayüzü başlat\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-jTJDg-uQp4Q",
        "outputId": "f578a826-0afe-4f1a-cf87-0310f38a0311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyserial in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.32.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://27a99f745e2494cbd7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://27a99f745e2494cbd7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LAST CODE3\n",
        "\n",
        "# Gerekli kütüphaneleri içe aktar\n",
        "!pip install pyserial\n",
        "!pip install gradio\n",
        "import tensorflow as tf  # Sinir ağı modeli için\n",
        "import numpy as np  # Sayısal işlemler için\n",
        "from tensorflow.keras import layers  # Keras katmanları için\n",
        "import gradio as gr  # Kullanıcı arayüzü için\n",
        "import os  # Dosya işlemleri için\n",
        "import threading  # Çoklu iş parçacığı için\n",
        "import queue  # İş parçacıkları arası veri aktarımı için\n",
        "import time  # Simülasyon gecikmesi için\n",
        "import serial  # UART iletişimi için\n",
        "import struct  # Binary veri paketleme için\n",
        "import serial.tools.list_ports  # Mevcut seri portları listelemek için\n",
        "import platform  # İşletim sistemi bilgisi için\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Resim yükleme ve işleme için\n",
        "import uuid  # Benzersiz dosya adları için\n",
        "from google.colab import drive  # Google Drive bağlantısı için\n",
        "\n",
        "# Google Drive'ı bağla\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Model ve veri yollarını tanımla\n",
        "MODELS = {\n",
        "    \"VGG16-1\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-lenetsets/saved_model/vgg16_model.keras\",  # Model dosya yolu\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",  # Test veri yolu\n",
        "        \"flow_from_directory\": True  # Alt klasörlerden veri yükleme\n",
        "    },\n",
        "    \"VGG16-2\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-vgg16sets/saved_model/vgg16_model.keras\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "        \"flow_from_directory\": False\n",
        "    },\n",
        "    \"VGG16-3\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-mobilnetsets/saved_model/vgg16_model.keras\",\n",
        "        \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "        \"flow_from_directory\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Veri yükleme fonksiyonu: Alt klasörsüz dizinlerden resimleri yükler\n",
        "def load_images_from_directory(directory, target_size=(224, 224), batch_size=8):\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)  # Resmi belirtilen boyutta yükle\n",
        "            img_array = img_to_array(img) / 255.0  # Resmi diziye çevir ve normalize et\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)  # Veriyi toplu işleme uygun hale getir\n",
        "\n",
        "# Veri yükleme fonksiyonu: Alt klasörlü dizinlerden resimleri yükler\n",
        "def load_images_with_flow_from_directory(directory, target_size=(224, 224), batch_size=8):\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)  # Normalizasyon için veri üreteci\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data  # ImageDataGenerator nesnesi döndür\n",
        "\n",
        "# Ağırlık ve pencere parametrelerini çıkarma fonksiyonu\n",
        "def extract_weights_and_window(layer):\n",
        "    weights = layer.get_weights()  # Katmanın ağırlıklarını al\n",
        "    window_params = {}  # Pencere parametrelerini saklamak için sözlük\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        window_params[\"kernel_size\"] = list(layer.kernel_size)  # Çekirdek boyutu\n",
        "        window_params[\"stride\"] = list(layer.strides)  # Adım boyutu\n",
        "        window_params[\"padding\"] = layer.padding  # Dolgu tipi\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        window_params[\"units\"] = layer.units  # Birim sayısı\n",
        "    return weights, window_params  # Ağırlıklar ve parametreler döndür\n",
        "\n",
        "# Mevcut seri portları listeleyen fonksiyon\n",
        "def get_available_ports():\n",
        "    ports = serial.tools.list_ports.comports()  # Sistemdeki tüm seri portları al\n",
        "    return [port.device for port in ports]  # Port adlarını listele\n",
        "\n",
        "# FPGA ile iletişim fonksiyonu (Nexys4DDR için UART)\n",
        "def communicate_with_fpga(input_data, output_file, result_queue, mode):\n",
        "    if mode == \"Simülasyon\":\n",
        "        # Simülasyon modu: FPGA yerine gürültü eklenmiş veri döndür\n",
        "        time.sleep(1)  # İletişim gecikmesini taklit et\n",
        "        with open(output_file, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), dtype=np.float32)  # Dosyadan veriyi oku\n",
        "        fpga_output = data.reshape(input_data.shape) + np.random.normal(0, 0.05, input_data.shape)  # Gürültü ekle\n",
        "        result_queue.put((fpga_output, len(data)))  # Sonucu kuyruğa ekle\n",
        "    else:\n",
        "        # Donanım modu: Nexys4DDR ile UART üzerinden gerçek iletişim\n",
        "        try:\n",
        "            # Platforma göre varsayılan port seç\n",
        "            default_port = \"COM3\" if platform.system() == \"Windows\" else \"/dev/ttyUSB0\"\n",
        "            available_ports = get_available_ports()\n",
        "            if default_port not in available_ports:\n",
        "                raise Exception(f\"Port {default_port} bulunamadı. Mevcut portlar: {available_ports or 'Yok'}\")\n",
        "\n",
        "            # Seri portu yapılandır\n",
        "            ser = serial.Serial(\n",
        "                port=default_port,\n",
        "                baudrate=115200,\n",
        "                stopbits=serial.STOPBITS_TWO,\n",
        "                bytesize=serial.EIGHTBITS,\n",
        "                parity=serial.PARITY_NONE,\n",
        "                timeout=5\n",
        "            )\n",
        "\n",
        "            # Dosyadan veriyi oku\n",
        "            with open(output_file, 'rb') as f:\n",
        "                data = f.read()\n",
        "\n",
        "            # Veriyi FPGA'ya gönder\n",
        "            ser.write(data)\n",
        "            ser.flush()\n",
        "\n",
        "            # FPGA'dan yanıtı al\n",
        "            response_size = len(data)\n",
        "            response = ser.read(response_size)\n",
        "\n",
        "            # Seri portu kapat\n",
        "            ser.close()\n",
        "\n",
        "            # Yanıtın doğruluğunu kontrol et\n",
        "            if len(response) != response_size:\n",
        "                raise Exception(f\"FPGA'dan eksik veri alındı: {len(response)}/{response_size} bayt\")\n",
        "\n",
        "            # Yanıtı NumPy dizisine çevir\n",
        "            fpga_output = np.frombuffer(response, dtype=np.float32).reshape(input_data.shape)\n",
        "            result_queue.put((fpga_output, len(data)))\n",
        "\n",
        "        except Exception as e:\n",
        "            # Hata durumunda açıklayıcı mesaj döndür\n",
        "            available_ports = get_available_ports()\n",
        "            error_msg = f\"FPGA iletişimi hatası: {str(e)}\\nMevcut portlar: {available_ports or 'Yok'}\\nLütfen doğru portu kontrol edin veya FPGA'nın bağlı olduğundan emin olun.\"\n",
        "            result_queue.put((None, 0, error_msg))\n",
        "\n",
        "# Katman çıktısını hesaplama fonksiyonu\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# Kağan için veriyi binary formatta kaydetme fonksiyonu\n",
        "def save_data_for_kagan(weights, window_params, data_size, output_data):\n",
        "    bin_file = f\"data_for_kagan_{uuid.uuid4()}.bin\"\n",
        "    with open(bin_file, 'wb') as f:\n",
        "        for w in weights:\n",
        "            f.write(w.flatten().astype(np.float32).tobytes())\n",
        "        if window_params:\n",
        "            if \"kernel_size\" in window_params:\n",
        "                f.write(struct.pack('ii', *window_params[\"kernel_size\"]))\n",
        "                f.write(struct.pack('ii', *window_params[\"stride\"]))\n",
        "                padding_val = 1 if window_params[\"padding\"] == \"valid\" else 0\n",
        "                f.write(struct.pack('i', padding_val))\n",
        "            elif \"units\" in window_params:\n",
        "                f.write(struct.pack('i', window_params[\"units\"]))\n",
        "        f.write(struct.pack('Q', data_size))\n",
        "        f.write(output_data.flatten().astype(np.float32).tobytes())\n",
        "    return bin_file\n",
        "\n",
        "# Ana simülasyon ve çalıştırma fonksiyonu\n",
        "def run_model(model_selection, layer_selection, data_choice, mode):\n",
        "    model_info = MODELS[model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "\n",
        "    # Modeli yükle\n",
        "    try:\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "    except Exception as e:\n",
        "        return f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Test verisini yükle\n",
        "    try:\n",
        "        if flow_from_directory:\n",
        "            test_data = load_images_with_flow_from_directory(test_path, target_size=(224, 224), batch_size=8)\n",
        "        else:\n",
        "            test_data = load_images_from_directory(test_path, target_size=(224, 224), batch_size=8)\n",
        "    except Exception as e:\n",
        "        return f\"Test verisi yükleme hatası: {str(e)}\\nTest yolu: {test_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Katman seçimini işle\n",
        "    layer_index = None\n",
        "    current_layer = None\n",
        "    if layer_selection and layer_selection != \"None\":\n",
        "        try:\n",
        "            layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "            current_layer = loaded_model.layers[layer_index]\n",
        "        except (ValueError, IndexError) as e:\n",
        "            return f\"Katman seçimi hatası: {str(e)}\\nSeçilen katman: {layer_selection}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Veri seçimini yap\n",
        "    try:\n",
        "        if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "            if flow_from_directory:\n",
        "                input_data = next(test_data)\n",
        "            else:\n",
        "                input_data = next(iter(test_data))\n",
        "            data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "        else:\n",
        "            expected_shape = loaded_model.input.shape[1:]\n",
        "            input_data = np.random.random((8, *expected_shape))\n",
        "            data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "    except Exception as e:\n",
        "        return f\"Veri seçimi hatası: {str(e)}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    try:\n",
        "        if layer_index is None or layer_selection == \"None\":\n",
        "            real_output = loaded_model.predict(input_data, verbose=0)\n",
        "            fpga_output = real_output\n",
        "            serialized_output = real_output.flatten().tobytes()\n",
        "            data_sent_size = len(serialized_output)\n",
        "            weights_info = \"Hızlandırma yapılmadı, ağırlıklar kullanılmadı.\"\n",
        "            bin_file = None\n",
        "        else:\n",
        "            weights, window_params = extract_weights_and_window(current_layer)\n",
        "            real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "            output_file_x = f\"file_{uuid.uuid4()}.x\"\n",
        "            output_file_y = f\"file_{uuid.uuid4()}.y\"\n",
        "            with open(output_file_x, 'wb') as f:\n",
        "                f.write(real_output.flatten().tobytes())\n",
        "            with open(output_file_y, 'wb') as f:\n",
        "                for w in weights:\n",
        "                    f.write(w.flatten().tobytes())\n",
        "\n",
        "            bin_file = save_data_for_kagan(weights, window_params, len(real_output.flatten().tobytes()), real_output)\n",
        "\n",
        "            result_queue = queue.Queue()\n",
        "            comm_thread = threading.Thread(\n",
        "                target=communicate_with_fpga,\n",
        "                args=(real_output, output_file_x, result_queue, mode)\n",
        "            )\n",
        "            comm_thread.start()\n",
        "            comm_thread.join()\n",
        "\n",
        "            fpga_result = result_queue.get()\n",
        "            if len(fpga_result) == 3:\n",
        "                raise Exception(fpga_result[2])\n",
        "            fpga_output, data_sent_size = fpga_result\n",
        "            weights_info = f\"Ağırlıklar ve pencere parametreleri: {window_params}, Ağırlık boyutu: {sum(w.size for w in weights)} eleman\"\n",
        "\n",
        "            os.remove(output_file_x)\n",
        "            os.remove(output_file_y)\n",
        "            if bin_file:\n",
        "                os.remove(bin_file)\n",
        "\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)\n",
        "\n",
        "        expected_input_shape = (loaded_model.input.shape[1:] if layer_index == 0 else\n",
        "                               loaded_model.layers[layer_index - 1].output.shape[1:] if layer_index else\n",
        "                               \"Tam model\")\n",
        "\n",
        "        output_str = f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok (Tam Model)'}\\n\"\n",
        "        output_str += f\"Mod: {mode}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape if layer_index else input_data.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Kağan'a Gönderilen Veri Boyutu: {data_sent_size} bayt\\n\"\n",
        "        output_str += f\"{weights_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok'}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Katman seçim dropdown'unu güncelleme fonksiyonu\n",
        "def update_layer_dropdown(model_selection):\n",
        "    try:\n",
        "        model_info = MODELS[model_selection]\n",
        "        model_path = model_info[\"model_path\"]\n",
        "        if not os.path.exists(model_path):\n",
        "            return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                               info=f\"Model dosyası bulunamadı: {model_path}\")\n",
        "\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "        layer_names = [\"None\"]\n",
        "        for i, layer in enumerate(loaded_model.layers):\n",
        "            try:\n",
        "                output_shape = layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: {output_shape}\")\n",
        "            except Exception as e:\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: Hata ({str(e)})\")\n",
        "        return gr.Dropdown(choices=layer_names, value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\")\n",
        "    except Exception as e:\n",
        "        return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                           info=f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\")\n",
        "\n",
        "# Gradio arayüzünü oluştur\n",
        "with gr.Blocks(title=\"VGG-16 CNN Model Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# VGG-16 CNN Model Hızlandırıcı\")  # Başlık\n",
        "    gr.Markdown(\"Modelinizi seçin, katman ve giriş verisi tipini belirleyin. Simülasyon veya donanım modunda FPGA çıktısının gerçek çıktı ile uyumunu görün!\")  # Açıklama\n",
        "\n",
        "    # Model ve mod seçimi\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(choices=list(MODELS.keys()), label=\"Model Seçimi\", value=\"VGG16-1\")\n",
        "        mode_input = gr.Radio(choices=[\"Simülasyon\", \"Donanım\"], label=\"Çalışma Modu\", value=\"Simülasyon\")\n",
        "\n",
        "    # Katman seçimi ve simülasyon\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin (None = Hızlandırma Yok)\")\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "            submit_btn = gr.Button(\"Modeli Çalıştır\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Model seçildiğinde katman dropdown'unu güncelle\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=model_input, outputs=layer_input)\n",
        "\n",
        "    # Modeli çalıştır\n",
        "    submit_btn.click(fn=run_model, inputs=[model_input, layer_input, data_input, mode_input], outputs=[output_text, output_animation])\n",
        "\n",
        "# Arayüzü başlat\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o1HpgDqRcs0R",
        "outputId": "ccd71315-3ef8-4f19-c5b0-a7967c9889bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyserial in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.32.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a7a22db07931a2f2e5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a7a22db07931a2f2e5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 model birleşimi\n",
        "\n",
        "# Gerekli kütüphaneleri içe aktar\n",
        "!pip install pyserial\n",
        "!pip install gradio\n",
        "import tensorflow as tf  # Sinir ağı modeli için\n",
        "import numpy as np  # Sayısal işlemler için\n",
        "from tensorflow.keras import layers  # Keras katmanları için\n",
        "import gradio as gr  # Kullanıcı arayüzü için\n",
        "import os  # Dosya işlemleri için\n",
        "import threading  # Çoklu iş parçacığı için\n",
        "import queue  # İş parçacıkları arası veri aktarımı için\n",
        "import time  # Simülasyon gecikmesi için\n",
        "import serial  # UART iletişimi için\n",
        "import struct  # Binary veri paketleme için\n",
        "import serial.tools.list_ports  # Mevcut seri portları listelemek için\n",
        "import platform  # İşletim sistemi bilgisi için\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Resim yükleme ve işleme için\n",
        "import uuid  # Benzersiz dosya adları için\n",
        "from google.colab import drive  # Google Drive bağlantısı için\n",
        "\n",
        "# Google Drive'ı bağla\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Model ve veri yollarını tanımla\n",
        "MODEL_TYPES = {\n",
        "    \"LeNet\": {\n",
        "        \"models\": {\n",
        "            \"LeNet1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (32, 32)\n",
        "            },\n",
        "            \"LeNet2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (32, 32)\n",
        "            },\n",
        "            \"LeNet3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (32, 32)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"h5\"\n",
        "    },\n",
        "    \"MobileNet\": {\n",
        "        \"models\": {\n",
        "            \"MobilNet1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet1/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"MobilNet2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet2/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"MobilNet3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet3/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"keras\"\n",
        "    },\n",
        "    \"VGG-16\": {\n",
        "        \"models\": {\n",
        "            \"VGG16-1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-lenetsets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"VGG16-2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-vgg16sets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"VGG16-3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-mobilnetsets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"keras\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Veri yükleme fonksiyonu: Alt klasörsüz dizinlerden resimleri yükler\n",
        "def load_images_from_directory(directory, target_size, batch_size=8):\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)\n",
        "\n",
        "# Veri yükleme fonksiyonu: Alt klasörlü dizinlerden resimleri yükler\n",
        "def load_images_with_flow_from_directory(directory, target_size, batch_size=8):\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data\n",
        "\n",
        "# Ağırlık ve pencere parametrelerini çıkarma fonksiyonu\n",
        "def extract_weights_and_window(layer):\n",
        "    weights = layer.get_weights()\n",
        "    window_params = {}\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        window_params[\"kernel_size\"] = list(layer.kernel_size)\n",
        "        window_params[\"stride\"] = list(layer.strides)\n",
        "        window_params[\"padding\"] = layer.padding\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        window_params[\"units\"] = layer.units\n",
        "    return weights, window_params\n",
        "\n",
        "# Mevcut seri portları listeleyen fonksiyon\n",
        "def get_available_ports():\n",
        "    ports = serial.tools.list_ports.comports()\n",
        "    return [port.device for port in ports]\n",
        "\n",
        "# FPGA ile iletişim fonksiyonu\n",
        "def communicate_with_fpga(input_data, output_file, result_queue, mode):\n",
        "    if mode == \"Simülasyon\":\n",
        "        time.sleep(1)\n",
        "        with open(output_file, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), dtype=np.float32)\n",
        "        fpga_output = data.reshape(input_data.shape) + np.random.normal(0, 0.05, input_data.shape)\n",
        "        result_queue.put((fpga_output, len(data)))\n",
        "    else:\n",
        "        try:\n",
        "            default_port = \"COM3\" if platform.system() == \"Windows\" else \"/dev/ttyUSB0\"\n",
        "            available_ports = get_available_ports()\n",
        "            if default_port not in available_ports:\n",
        "                raise Exception(f\"Port {default_port} bulunamadı. Mevcut portlar: {available_ports or 'Yok'}\")\n",
        "\n",
        "            ser = serial.Serial(\n",
        "                port=default_port,\n",
        "                baudrate=115200,\n",
        "                stopbits=serial.STOPBITS_TWO,\n",
        "                bytesize=serial.EIGHTBITS,\n",
        "                parity=serial.PARITY_NONE,\n",
        "                timeout=5\n",
        "            )\n",
        "\n",
        "            with open(output_file, 'rb') as f:\n",
        "                data = f.read()\n",
        "\n",
        "            ser.write(data)\n",
        "            ser.flush()\n",
        "\n",
        "            response_size = len(data)\n",
        "            response = ser.read(response_size)\n",
        "\n",
        "            ser.close()\n",
        "\n",
        "            if len(response) != response_size:\n",
        "                raise Exception(f\"FPGA'dan eksik veri alındı: {len(response)}/{response_size} bayt\")\n",
        "\n",
        "            fpga_output = np.frombuffer(response, dtype=np.float32).reshape(input_data.shape)\n",
        "            result_queue.put((fpga_output, len(data)))\n",
        "\n",
        "        except Exception as e:\n",
        "            available_ports = get_available_ports()\n",
        "            error_msg = f\"FPGA iletişimi hatası: {str(e)}\\nMevcut portlar: {available_ports or 'Yok'}\\nLütfen doğru portu kontrol edin veya FPGA'nın bağlı olduğundan emin olun.\"\n",
        "            result_queue.put((None, 0, error_msg))\n",
        "\n",
        "# Katman çıktısını hesaplama fonksiyonu\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# Kağan için veriyi binary formatta kaydetme fonksiyonu\n",
        "def save_data_for_kagan(weights, window_params, data_size, output_data):\n",
        "    bin_file = f\"data_for_kagan_{uuid.uuid4()}.bin\"\n",
        "    with open(bin_file, 'wb') as f:\n",
        "        for w in weights:\n",
        "            f.write(w.flatten().astype(np.float32).tobytes())\n",
        "        if window_params:\n",
        "            if \"kernel_size\" in window_params:\n",
        "                f.write(struct.pack('ii', *window_params[\"kernel_size\"]))\n",
        "                f.write(struct.pack('ii', *window_params[\"stride\"]))\n",
        "                padding_val = 1 if window_params[\"padding\"] == \"valid\" else 0\n",
        "                f.write(struct.pack('i', padding_val))\n",
        "            elif \"units\" in window_params:\n",
        "                f.write(struct.pack('i', window_params[\"units\"]))\n",
        "        f.write(struct.pack('Q', data_size))\n",
        "        f.write(output_data.flatten().astype(np.float32).tobytes())\n",
        "    return bin_file\n",
        "\n",
        "# Ana simülasyon ve çalıştırma fonksiyonu\n",
        "def run_model(model_type, model_selection, layer_selection, data_choice, mode):\n",
        "    model_info = MODEL_TYPES[model_type][\"models\"][model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "    target_size = model_info[\"target_size\"]\n",
        "    file_format = MODEL_TYPES[model_type][\"file_format\"]\n",
        "\n",
        "    # Modeli yükle\n",
        "    try:\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "    except Exception as e:\n",
        "        return f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Test verisini yükle\n",
        "    try:\n",
        "        if flow_from_directory:\n",
        "            test_data = load_images_with_flow_from_directory(test_path, target_size=target_size, batch_size=8)\n",
        "        else:\n",
        "            test_data = load_images_from_directory(test_path, target_size=target_size, batch_size=8)\n",
        "    except Exception as e:\n",
        "        return f\"Test verisi yükleme hatası: {str(e)}\\nTest yolu: {test_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Katman seçimini işle\n",
        "    layer_index = None\n",
        "    current_layer = None\n",
        "    if layer_selection and layer_selection != \"None\":\n",
        "        try:\n",
        "            layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "            current_layer = loaded_model.layers[layer_index]\n",
        "        except (ValueError, IndexError) as e:\n",
        "            return f\"Katman seçimi hatası: {str(e)}\\nSeçilen katman: {layer_selection}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Veri seçimini yap\n",
        "    try:\n",
        "        if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "            if flow_from_directory:\n",
        "                input_data = next(test_data)\n",
        "            else:\n",
        "                input_data = next(iter(test_data))\n",
        "            data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "        else:\n",
        "            expected_shape = loaded_model.input.shape[1:]\n",
        "            input_data = np.random.random((8, *expected_shape))\n",
        "            data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "    except Exception as e:\n",
        "        return f\"Veri seçimi hatası: {str(e)}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    try:\n",
        "        if layer_index is None or layer_selection == \"None\":\n",
        "            real_output = loaded_model.predict(input_data, verbose=0)\n",
        "            fpga_output = real_output\n",
        "            serialized_output = real_output.flatten().tobytes()\n",
        "            data_sent_size = len(serialized_output)\n",
        "            weights_info = \"Hızlandırma yapılmadı, ağırlıklar kullanılmadı.\"\n",
        "            bin_file = None\n",
        "        else:\n",
        "            weights, window_params = extract_weights_and_window(current_layer)\n",
        "            real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "            output_file_x = f\"file_{uuid.uuid4()}.x\"\n",
        "            output_file_y = f\"file_{uuid.uuid4()}.y\"\n",
        "            with open(output_file_x, 'wb') as f:\n",
        "                f.write(real_output.flatten().tobytes())\n",
        "            with open(output_file_y, 'wb') as f:\n",
        "                for w in weights:\n",
        "                    f.write(w.flatten().tobytes())\n",
        "\n",
        "            bin_file = save_data_for_kagan(weights, window_params, len(real_output.flatten().tobytes()), real_output)\n",
        "\n",
        "            result_queue = queue.Queue()\n",
        "            comm_thread = threading.Thread(\n",
        "                target=communicate_with_fpga,\n",
        "                args=(real_output, output_file_x, result_queue, mode)\n",
        "            )\n",
        "            comm_thread.start()\n",
        "            comm_thread.join()\n",
        "\n",
        "            fpga_result = result_queue.get()\n",
        "            if len(fpga_result) == 3:\n",
        "                raise Exception(fpga_result[2])\n",
        "            fpga_output, data_sent_size = fpga_result\n",
        "            weights_info = f\"Ağırlıklar ve pencere parametreleri: {window_params}, Ağırlık boyutu: {sum(w.size for w in weights)} eleman\"\n",
        "\n",
        "            os.remove(output_file_x)\n",
        "            os.remove(output_file_y)\n",
        "            if bin_file:\n",
        "                os.remove(bin_file)\n",
        "\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)\n",
        "\n",
        "        expected_input_shape = (loaded_model.input.shape[1:] if layer_index == 0 else\n",
        "                               loaded_model.layers[layer_index - 1].output.shape[1:] if layer_index else\n",
        "                               \"Tam model\")\n",
        "\n",
        "        output_str = f\"Seçilen Model Türü: {model_type}\\n\"\n",
        "        output_str += f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok (Tam Model)'}\\n\"\n",
        "        output_str += f\"Mod: {mode}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape if layer_index else input_data.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Kağan'a Gönderilen Veri Boyutu: {data_sent_size} bayt\\n\"\n",
        "        output_str += f\"{weights_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok'}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Model alt seçim dropdown'unu güncelleme fonksiyonu\n",
        "def update_model_dropdown(model_type):\n",
        "    try:\n",
        "        models = list(MODEL_TYPES[model_type][\"models\"].keys())\n",
        "        return gr.Dropdown(choices=models, value=models[0], label=\"Model Seçimi\")\n",
        "    except Exception as e:\n",
        "        return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Model Seçimi\", info=f\"Hata: {str(e)}\")\n",
        "\n",
        "# Katman seçim dropdown'unu güncelleme fonksiyonu\n",
        "def update_layer_dropdown(model_type, model_selection):\n",
        "    try:\n",
        "        model_info = MODEL_TYPES[model_type][\"models\"][model_selection]\n",
        "        model_path = model_info[\"model_path\"]\n",
        "        if not os.path.exists(model_path):\n",
        "            return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                               info=f\"Model dosyası bulunamadı: {model_path}\")\n",
        "\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "        layer_names = [\"None\"]\n",
        "        for i, layer in enumerate(loaded_model.layers):\n",
        "            try:\n",
        "                output_shape = layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: {output_shape}\")\n",
        "            except Exception as e:\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: Hata ({str(e)})\")\n",
        "        return gr.Dropdown(choices=layer_names, value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\")\n",
        "    except Exception as e:\n",
        "        return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                           info=f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\")\n",
        "\n",
        "# Gradio arayüzünü oluştur\n",
        "with gr.Blocks(title=\"CNN Model Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# CNN Model Hızlandırıcı\")\n",
        "    gr.Markdown(\"Model türünüzü ve modelinizi seçin, ardından katman ve giriş verisi tipini belirleyin. Simülasyon veya donanım modunda FPGA çıktısının gerçek çıktı ile uyumunu görün!\")\n",
        "\n",
        "    # Model türü seçimi\n",
        "    model_type_input = gr.Dropdown(choices=list(MODEL_TYPES.keys()), label=\"Model Türü Seçimi\", value=\"LeNet\")\n",
        "\n",
        "    # Model ve mod seçimi\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(label=\"Model Seçimi\")\n",
        "        mode_input = gr.Radio(choices=[\"Simülasyon\", \"Donanım\"], label=\"Çalışma Modu\", value=\"Simülasyon\")\n",
        "\n",
        "    # Katman seçimi ve simülasyon\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin (None = Hızlandırma Yok)\")\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "            submit_btn = gr.Button(\"Modeli Çalıştır\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Model türü değiştiğinde model dropdown'unu güncelle\n",
        "    model_type_input.change(fn=update_model_dropdown, inputs=model_type_input, outputs=model_input)\n",
        "\n",
        "    # Model veya model türü değiştiğinde katman dropdown'unu güncelle\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=[model_type_input, model_input], outputs=layer_input)\n",
        "    model_type_input.change(fn=update_layer_dropdown, inputs=[model_type_input, model_input], outputs=layer_input)\n",
        "\n",
        "    # Modeli çalıştır\n",
        "    submit_btn.click(fn=run_model, inputs=[model_type_input, model_input, layer_input, data_input, mode_input], outputs=[output_text, output_animation])\n",
        "\n",
        "# Arayüzü başlat\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WCB9fl5aiH2r",
        "outputId": "aaeaccc8-e993-46f5-d155-cbfe501796b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyserial\n",
            "  Downloading pyserial-3.5-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/90.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyserial\n",
            "Successfully installed pyserial-3.5\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.13)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://39d4f853385d5a0d1b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://39d4f853385d5a0d1b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# revize kod\n",
        "\n",
        "# 3 model birleşimi\n",
        "\n",
        "# Gerekli kütüphaneleri içe aktar\n",
        "!pip install pyserial\n",
        "!pip install gradio\n",
        "import tensorflow as tf  # Sinir ağı modeli için\n",
        "import numpy as np  # Sayısal işlemler için\n",
        "from tensorflow.keras import layers  # Keras katmanları için\n",
        "import gradio as gr  # Kullanıcı arayüzü için\n",
        "import os  # Dosya işlemleri için\n",
        "import threading  # Çoklu iş parçacığı için\n",
        "import queue  # İş parçacıkları arası veri aktarımı için\n",
        "import time  # Simülasyon gecikmesi için\n",
        "import serial  # UART iletişimi için\n",
        "import struct  # Binary veri paketleme için\n",
        "import serial.tools.list_ports  # Mevcut seri portları listelemek için\n",
        "import platform  # İşletim sistemi bilgisi için\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Resim yükleme ve işleme için\n",
        "import uuid  # Benzersiz dosya adları için\n",
        "from google.colab import drive  # Google Drive bağlantısı için\n",
        "\n",
        "# Google Drive'ı bağla\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Model ve veri yollarını tanımla\n",
        "MODEL_TYPES = {\n",
        "    \"LeNet\": {\n",
        "        \"models\": {\n",
        "            \"LeNet1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (32, 32)\n",
        "            },\n",
        "            \"LeNet2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (32, 32)\n",
        "            },\n",
        "            \"LeNet3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (32, 32)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"h5\"\n",
        "    },\n",
        "    \"MobileNet\": {\n",
        "        \"models\": {\n",
        "            \"MobilNet1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet1/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"MobilNet2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet2/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"MobilNet3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet3/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"keras\"\n",
        "    },\n",
        "    \"VGG-16\": {\n",
        "        \"models\": {\n",
        "            \"VGG16-1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-lenetsets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"VGG16-2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-vgg16sets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"VGG16-3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-mobilnetsets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"keras\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Veri yükleme fonksiyonu: Alt klasörsüz dizinlerden resimleri yükler\n",
        "def load_images_from_directory(directory, target_size, batch_size=8):\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)\n",
        "\n",
        "# Veri yükleme fonksiyonu: Alt klasörlü dizinlerden resimleri yükler\n",
        "def load_images_with_flow_from_directory(directory, target_size, batch_size=8):\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data\n",
        "\n",
        "# Ağırlık ve pencere parametrelerini çıkarma fonksiyonu\n",
        "def extract_weights_and_window(layer):\n",
        "    weights = layer.get_weights()\n",
        "    window_params = {}\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        window_params[\"kernel_size\"] = list(layer.kernel_size)\n",
        "        window_params[\"stride\"] = list(layer.strides)\n",
        "        window_params[\"padding\"] = layer.padding\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        window_params[\"units\"] = layer.units\n",
        "    return weights, window_params\n",
        "\n",
        "# Mevcut seri portları listeleyen fonksiyon\n",
        "def get_available_ports():\n",
        "    ports = serial.tools.list_ports.comports()\n",
        "    return [port.device for port in ports]\n",
        "\n",
        "# FPGA ile iletişim fonksiyonu\n",
        "def communicate_with_fpga(input_data, output_file, result_queue, mode):\n",
        "    if mode == \"Simülasyon\":\n",
        "        time.sleep(1)\n",
        "        with open(output_file, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), dtype=np.float32)\n",
        "        fpga_output = data.reshape(input_data.shape) + np.random.normal(0, 0.05, input_data.shape)\n",
        "        result_queue.put((fpga_output, len(data)))\n",
        "    else:\n",
        "        try:\n",
        "            default_port = \"COM3\" if platform.system() == \"Windows\" else \"/dev/ttyUSB0\"\n",
        "            available_ports = get_available_ports()\n",
        "            if default_port not in available_ports:\n",
        "                raise Exception(f\"Port {default_port} bulunamadı. Mevcut portlar: {available_ports or 'Yok'}\")\n",
        "\n",
        "            ser = serial.Serial(\n",
        "                port=default_port,\n",
        "                baudrate=115200,\n",
        "                stopbits=serial.STOPBITS_TWO,\n",
        "                bytesize=serial.EIGHTBITS,\n",
        "                parity=serial.PARITY_NONE,\n",
        "                timeout=5\n",
        "            )\n",
        "\n",
        "            with open(output_file, 'rb') as f:\n",
        "                data = f.read()\n",
        "\n",
        "            ser.write(data)\n",
        "            ser.flush()\n",
        "\n",
        "            response_size = len(data)\n",
        "            response = ser.read(response_size)\n",
        "\n",
        "            ser.close()\n",
        "\n",
        "            if len(response) != response_size:\n",
        "                raise Exception(f\"FPGA'dan eksik veri alındı: {len(response)}/{response_size} bayt\")\n",
        "\n",
        "            fpga_output = np.frombuffer(response, dtype=np.float32).reshape(input_data.shape)\n",
        "            result_queue.put((fpga_output, len(data)))\n",
        "\n",
        "        except Exception as e:\n",
        "            available_ports = get_available_ports()\n",
        "            error_msg = f\"FPGA iletişimi hatası: {str(e)}\\nMevcut portlar: {available_ports or 'Yok'}\\nLütfen doğru portu kontrol edin veya FPGA'nın bağlı olduğundan emin olun.\"\n",
        "            result_queue.put((None, 0, error_msg))\n",
        "\n",
        "# Katman çıktısını hesaplama fonksiyonu\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# Kağan için veriyi binary formatta kaydetme fonksiyonu\n",
        "def save_data_for_kagan(weights, window_params, data_size, output_data):\n",
        "    bin_file = f\"data_for_kagan_{uuid.uuid4()}.bin\"\n",
        "    with open(bin_file, 'wb') as f:\n",
        "        for w in weights:\n",
        "            f.write(w.flatten().astype(np.float32).tobytes())\n",
        "        if window_params:\n",
        "            if \"kernel_size\" in window_params:\n",
        "                f.write(struct.pack('ii', *window_params[\"kernel_size\"]))\n",
        "                f.write(struct.pack('ii', *window_params[\"stride\"]))\n",
        "                padding_val = 1 if window_params[\"padding\"] == \"valid\" else 0\n",
        "                f.write(struct.pack('i', padding_val))\n",
        "            elif \"units\" in window_params:\n",
        "                f.write(struct.pack('i', window_params[\"units\"]))\n",
        "        f.write(struct.pack('Q', data_size))\n",
        "        f.write(output_data.flatten().astype(np.float32).tobytes())\n",
        "    return bin_file\n",
        "\n",
        "# Ana simülasyon ve çalıştırma fonksiyonu\n",
        "def run_model(model_type, model_selection, layer_selection, data_choice, mode):\n",
        "    model_info = MODEL_TYPES[model_type][\"models\"][model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "    target_size = model_info[\"target_size\"]\n",
        "    file_format = MODEL_TYPES[model_type][\"file_format\"]\n",
        "\n",
        "    # Modeli yükle\n",
        "    try:\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "    except Exception as e:\n",
        "        return f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Test verisini yükle\n",
        "    try:\n",
        "        if flow_from_directory:\n",
        "            test_data = load_images_with_flow_from_directory(test_path, target_size=target_size, batch_size=8)\n",
        "        else:\n",
        "            test_data = load_images_from_directory(test_path, target_size=target_size, batch_size=8)\n",
        "    except Exception as e:\n",
        "        return f\"Test verisi yükleme hatası: {str(e)}\\nTest yolu: {test_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Katman seçimini işle\n",
        "    layer_index = None\n",
        "    current_layer = None\n",
        "    if mode == \"Donanım\" and layer_selection and layer_selection != \"None\":\n",
        "        try:\n",
        "            layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "            current_layer = loaded_model.layers[layer_index]\n",
        "        except (ValueError, IndexError) as e:\n",
        "            return f\"Katman seçimi hatası: {str(e)}\\nSeçilen katman: {layer_selection}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Veri seçimini yap\n",
        "    try:\n",
        "        if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "            if flow_from_directory:\n",
        "                input_data = next(test_data)\n",
        "            else:\n",
        "                input_data = next(iter(test_data))\n",
        "            data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "        else:\n",
        "            expected_shape = loaded_model.input.shape[1:]\n",
        "            input_data = np.random.random((8, *expected_shape))\n",
        "            data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "    except Exception as e:\n",
        "        return f\"Veri seçimi hatası: {str(e)}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    try:\n",
        "        if mode == \"Simülasyon\" or layer_selection == \"None\" or not layer_selection:\n",
        "            real_output = loaded_model.predict(input_data, verbose=0)\n",
        "            fpga_output = real_output\n",
        "            serialized_output = real_output.flatten().tobytes()\n",
        "            data_sent_size = len(serialized_output)\n",
        "            weights_info = \"Hızlandırma yapılmadı, ağırlıklar kullanılmadı.\"\n",
        "            bin_file = None\n",
        "        else:\n",
        "            weights, window_params = extract_weights_and_window(current_layer)\n",
        "            real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "            output_file_x = f\"file_{uuid.uuid4()}.x\"\n",
        "            output_file_y = f\"file_{uuid.uuid4()}.y\"\n",
        "            with open(output_file_x, 'wb') as f:\n",
        "                f.write(real_output.flatten().tobytes())\n",
        "            with open(output_file_y, 'wb') as f:\n",
        "                for w in weights:\n",
        "                    f.write(w.flatten().tobytes())\n",
        "\n",
        "            bin_file = save_data_for_kagan(weights, window_params, len(real_output.flatten().tobytes()), real_output)\n",
        "\n",
        "            result_queue = queue.Queue()\n",
        "            comm_thread = threading.Thread(\n",
        "                target=communicate_with_fpga,\n",
        "                args=(real_output, output_file_x, result_queue, mode)\n",
        "            )\n",
        "            comm_thread.start()\n",
        "            comm_thread.join()\n",
        "\n",
        "            fpga_result = result_queue.get()\n",
        "            if len(fpga_result) == 3:\n",
        "                raise Exception(fpga_result[2])\n",
        "            fpga_output, data_sent_size = fpga_result\n",
        "            weights_info = f\"Ağırlıklar ve pencere parametreleri: {window_params}, Ağırlık boyutu: {sum(w.size for w in weights)} eleman\"\n",
        "\n",
        "            os.remove(output_file_x)\n",
        "            os.remove(output_file_y)\n",
        "            if bin_file:\n",
        "                os.remove(bin_file)\n",
        "\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)\n",
        "\n",
        "        expected_input_shape = (loaded_model.input.shape[1:] if layer_index == 0 else\n",
        "                               loaded_model.layers[layer_index - 1].output.shape[1:] if layer_index else\n",
        "                               \"Tam model\")\n",
        "\n",
        "        output_str = f\"Seçilen Model Türü: {model_type}\\n\"\n",
        "        output_str += f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok (Tam Model)'}\\n\"\n",
        "        output_str += f\"Mod: {mode}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape if layer_index else input_data.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Kağan'a Gönderilen Veri Boyutu: {data_sent_size} bayt\\n\"\n",
        "        output_str += f\"{weights_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok'}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Model alt seçim dropdown'unu güncelleme fonksiyonu\n",
        "def update_model_dropdown(model_type):\n",
        "    try:\n",
        "        models = list(MODEL_TYPES[model_type][\"models\"].keys())\n",
        "        return gr.Dropdown(choices=models, value=models[0], label=\"Model Seçimi\")\n",
        "    except Exception as e:\n",
        "        return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Model Seçimi\", info=f\"Hata: {str(e)}\")\n",
        "\n",
        "# Katman seçim dropdown'unu güncelleme fonksiyonu\n",
        "def update_layer_dropdown(model_type, model_selection):\n",
        "    try:\n",
        "        model_info = MODEL_TYPES[model_type][\"models\"][model_selection]\n",
        "        model_path = model_info[\"model_path\"]\n",
        "        if not os.path.exists(model_path):\n",
        "            return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                               info=f\"Model dosyası bulunamadı: {model_path}\")\n",
        "\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "        layer_names = [\"None\"]\n",
        "        for i, layer in enumerate(loaded_model.layers):\n",
        "            try:\n",
        "                output_shape = layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: {output_shape}\")\n",
        "            except Exception as e:\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: Hata ({str(e)})\")\n",
        "        return gr.Dropdown(choices=layer_names, value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\")\n",
        "    except Exception as e:\n",
        "        return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                           info=f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\")\n",
        "\n",
        "# Çalışma modu değiştiğinde katman dropdown'unun görünürlüğünü güncelleme\n",
        "def update_layer_visibility(mode):\n",
        "    return gr.update(visible=(mode == \"Donanım\"))\n",
        "\n",
        "# Gradio arayüzünü oluştur\n",
        "with gr.Blocks(title=\"CNN Model Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# CNN Model Hızlandırıcı\")\n",
        "    gr.Markdown(\"Model türünüzü ve modelinizi seçin, ardından katman ve giriş verisi tipini belirleyin. Simülasyon veya donanım modunda FPGA çıktısının gerçek çıktı ile uyumunu görün!\")\n",
        "\n",
        "    # Model türü seçimi\n",
        "    model_type_input = gr.Dropdown(choices=list(MODEL_TYPES.keys()), label=\"Model Türü Seçimi\", value=\"LeNet\")\n",
        "\n",
        "    # Model ve mod seçimi\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(label=\"Model Seçimi\")\n",
        "        mode_input = gr.Radio(choices=[\"Simülasyon\", \"Donanım\"], label=\"Çalışma Modu\", value=\"Simülasyon\")\n",
        "\n",
        "    # Katman seçimi ve simülasyon\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin\", visible=False)\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "            submit_btn = gr.Button(\"Modeli Çalıştır\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Model türü değiştiğinde model dropdown'unu güncelle\n",
        "    model_type_input.change(fn=update_model_dropdown, inputs=model_type_input, outputs=model_input)\n",
        "\n",
        "    # Model veya model türü değiştiğinde katman dropdown'unu güncelle\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=[model_type_input, model_input], outputs=layer_input)\n",
        "    model_type_input.change(fn=update_layer_dropdown, inputs=[model_type_input, model_input], outputs=layer_input)\n",
        "\n",
        "    # Çalışma modu değiştiğinde katman dropdown'unun görünürlüğünü güncelle\n",
        "    mode_input.change(fn=update_layer_visibility, inputs=mode_input, outputs=layer_input)\n",
        "\n",
        "    # Modeli çalıştır\n",
        "    submit_btn.click(fn=run_model, inputs=[model_type_input, model_input, layer_input, data_input, mode_input], outputs=[output_text, output_animation])\n",
        "\n",
        "# Arayüzü başlat\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SCy4CfWSKlcg",
        "outputId": "b269d70c-15ba-4474-f0d6-eb3a12841069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyserial\n",
            "  Downloading pyserial-3.5-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/90.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyserial\n",
            "Successfully installed pyserial-3.5\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.13)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a7591dfec41c5f74bd.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a7591dfec41c5f74bd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kod Açıklaması Part Part\n",
        "\n",
        "# Bölüm 1: Kütüphane İçe Aktarmaları ve Kurulum\n",
        "# Bu bölümde, projede kullanılan tüm kütüphaneler içe aktarılır ve Google Drive bağlantısı kurulur.\n",
        "# Gerekli kütüphaneler: TensorFlow (sinir ağı), NumPy (sayısal işlemler), Gradio (kullanıcı arayüzü), PySerial (FPGA iletişimi) vb.\n",
        "\n",
        "!pip install pyserial\n",
        "!pip install gradio\n",
        "import tensorflow as tf  # Sinir ağı modellerini oluşturmak ve çalıştırmak için\n",
        "import numpy as np  # Sayısal işlemler ve dizi manipülasyonları için\n",
        "from tensorflow.keras import layers  # Sinir ağı katmanlarını tanımlamak için\n",
        "import gradio as gr  # İnteraktif kullanıcı arayüzü oluşturmak için\n",
        "import os  # Dosya ve dizin işlemleri için\n",
        "import threading  # FPGA ile paralel iletişim için çoklu iş parçacığı\n",
        "import queue  # İş parçacıkları arasında veri aktarımı için kuyruk\n",
        "import time  # Simülasyon modunda gecikme simülasyonu için\n",
        "import serial  # FPGA ile seri port üzerinden iletişim için\n",
        "import struct  # Binary veri paketleme ve açma için\n",
        "import serial.tools.list_ports  # Mevcut seri portları listelemek için\n",
        "import platform  # İşletim sistemi bilgisini almak için\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Resim yükleme ve ön işleme için\n",
        "import uuid  # Benzersiz dosya adları oluşturmak için\n",
        "from google.colab import drive  # Google Drive bağlantısı için\n",
        "\n",
        "# Google Drive'ı bağla: Modeller ve veri setleri Google Drive'da saklanıyor\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Bölüm 2: Model ve Veri Yolu Tanımlamaları\n",
        "# Bu bölümde, LeNet, MobileNet ve VGG-16 modellerinin yolları ve veri seti bilgileri tanımlanır.\n",
        "# Her model türü için farklı varyantlar ve test veri yolları belirtilir.\n",
        "\n",
        "MODEL_TYPES = {\n",
        "    \"LeNet\": {\n",
        "        \"models\": {\n",
        "            \"LeNet1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (32, 32)\n",
        "            },\n",
        "            \"LeNet2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (32, 32)\n",
        "            },\n",
        "            \"LeNet3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (32, 32)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"h5\"\n",
        "    },\n",
        "    \"MobileNet\": {\n",
        "        \"models\": {\n",
        "            \"MobilNet1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet1/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"MobilNet2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet2/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"MobilNet3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet3/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"keras\"\n",
        "    },\n",
        "    \"VGG-16\": {\n",
        "        \"models\": {\n",
        "            \"VGG16-1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-lenetsets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"VGG16-2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-vgg16sets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"VGG16-3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-mobilnetsets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"keras\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Bölüm 3: Veri Yükleme Fonksiyonları\n",
        "# Bu bölümde, test verilerini yüklemek için iki fonksiyon tanımlanır:\n",
        "# - load_images_from_directory: Alt klasörsüz dizinlerden resimleri yükler\n",
        "# - load_images_with_flow_from_directory: Alt klasörlü dizinlerden resimleri yükler\n",
        "\n",
        "def load_images_from_directory(directory, target_size, batch_size=8):\n",
        "    # Alt klasörsüz dizinlerden resimleri yükler ve ön işleme yapar\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0  # Normalizasyon\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)\n",
        "\n",
        "def load_images_with_flow_from_directory(directory, target_size, batch_size=8):\n",
        "    # Alt klasörlü dizinlerden resimleri yükler ve veri artırma uygular\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data\n",
        "\n",
        "# Bölüm 4: Ağırlık ve Pencere Parametreleri Çıkarma\n",
        "# Bu bölümde, seçilen katmanın ağırlıklarını ve pencere parametrelerini (ör. kernel boyutu, adım) çıkaran bir fonksiyon tanımlanır.\n",
        "\n",
        "def extract_weights_and_window(layer):\n",
        "    # Katmanın ağırlıklarını ve pencere parametrelerini (Conv2D veya Dense katmanları için) çıkarır\n",
        "    weights = layer.get_weights()\n",
        "    window_params = {}\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        window_params[\"kernel_size\"] = list(layer.kernel_size)\n",
        "        window_params[\"stride\"] = list(layer.strides)\n",
        "        window_params[\"padding\"] = layer.padding\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        window_params[\"units\"] = layer.units\n",
        "    return weights, window_params\n",
        "\n",
        "# Bölüm 5: Seri Port ve FPGA İletişimi\n",
        "# Bu bölümde, seri portları listelemek ve FPGA ile iletişim kurmak için fonksiyonlar tanımlanır.\n",
        "\n",
        "def get_available_ports():\n",
        "    # Mevcut seri portları listeler\n",
        "    ports = serial.tools.list_ports.comports()\n",
        "    return [port.device for port in ports]\n",
        "\n",
        "def communicate_with_fpga(input_data, output_file, result_queue, mode):\n",
        "    # FPGA ile iletişim kurar: Simülasyon modunda simüle veri üretir, Donanım modunda seri port üzerinden veri gönderir\n",
        "    if mode == \"Simülasyon\":\n",
        "        time.sleep(1)  # Simülasyon için gecikme\n",
        "        with open(output_file, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), dtype=np.float32)\n",
        "        fpga_output = data.reshape(input_data.shape) + np.random.normal(0, 0.05, input_data.shape)  # Gürültü ekler\n",
        "        result_queue.put((fpga_output, len(data)))\n",
        "    else:\n",
        "        try:\n",
        "            default_port = \"COM3\" if platform.system() == \"Windows\" else \"/dev/ttyUSB0\"\n",
        "            available_ports = get_available_ports()\n",
        "            if default_port not in available_ports:\n",
        "                raise Exception(f\"Port {default_port} bulunamadı. Mevcut portlar: {available_ports or 'Yok'}\")\n",
        "\n",
        "            ser = serial.Serial(\n",
        "                port=default_port,\n",
        "                baudrate=115200,\n",
        "                stopbits=serial.STOPBITS_TWO,\n",
        "                bytesize=serial.EIGHTBITS,\n",
        "                parity=serial.PARITY_NONE,\n",
        "                timeout=5\n",
        "            )\n",
        "\n",
        "            with open(output_file, 'rb') as f:\n",
        "                data = f.read()\n",
        "\n",
        "            ser.write(data)\n",
        "            ser.flush()\n",
        "\n",
        "            response_size = len(data)\n",
        "            response = ser.read(response_size)\n",
        "\n",
        "            ser.close()\n",
        "\n",
        "            if len(response) != response_size:\n",
        "                raise Exception(f\"FPGA'dan eksik veri alındı: {len(response)}/{response_size} bayt\")\n",
        "\n",
        "            fpga_output = np.frombuffer(response, dtype=np.float32).reshape(input_data.shape)\n",
        "            result_queue.put((fpga_output, len(data)))\n",
        "\n",
        "        except Exception as e:\n",
        "            available_ports = get_available_ports()\n",
        "            error_msg = f\"FPGA iletişimi hatası: {str(e)}\\nMevcut portlar: {available_ports or 'Yok'}\\nLütfen doğru portu kontrol edin veya FPGA'nın bağlı olduğundan emin olun.\"\n",
        "            result_queue.put((None, 0, error_msg))\n",
        "\n",
        "# Bölüm 6: Katman Çıktısı Hesaplama\n",
        "# Bu bölümde, seçilen katmanın çıktısını hesaplayan bir fonksiyon tanımlanır.\n",
        "\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    # Belirtilen katmanın çıktısını hesaplar\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# Bölüm 7: Kağan için Veri Hazırlama\n",
        "# Bu bölümde, ağırlıklar ve çıktılar binary formatta kaydedilir (FPGA için veri hazırlığı).\n",
        "\n",
        "def save_data_for_kagan(weights, window_params, data_size, output_data):\n",
        "    # Ağırlıkları, pencere parametrelerini ve çıktıları binary dosyaya kaydeder\n",
        "    bin_file = f\"data_for_kagan_{uuid.uuid4()}.bin\"\n",
        "    with open(bin_file, 'wb') as f:\n",
        "        for w in weights:\n",
        "            f.write(w.flatten().astype(np.float32).tobytes())\n",
        "        if window_params:\n",
        "            if \"kernel_size\" in window_params:\n",
        "                f.write(struct.pack('ii', *window_params[\"kernel_size\"]))\n",
        "                f.write(struct.pack('ii', *window_params[\"stride\"]))\n",
        "                padding_val = 1 if window_params[\"padding\"] == \"valid\" else 0\n",
        "                f.write(struct.pack('i', padding_val))\n",
        "            elif \"units\" in window_params:\n",
        "                f.write(struct.pack('i', window_params[\"units\"]))\n",
        "        f.write(struct.pack('Q', data_size))\n",
        "        f.write(output_data.flatten().astype(np.float32).tobytes())\n",
        "    return bin_file\n",
        "\n",
        "# Bölüm 8: Ana Simülasyon ve Çalıştırma Fonksiyonu\n",
        "# Bu bölümde, modelin çalıştırılması, FPGA ile iletişim ve sonuçların karşılaştırılması gerçekleştirilir.\n",
        "\n",
        "def run_model(model_type, model_selection, layer_selection, data_choice, mode):\n",
        "    # Seçilen model, katman ve mod ile modeli çalıştırır ve FPGA çıktısını gerçek çıktı ile karşılaştırır\n",
        "    model_info = MODEL_TYPES[model_type][\"models\"][model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "    target_size = model_info[\"target_size\"]\n",
        "    file_format = MODEL_TYPES[model_type][\"file_format\"]\n",
        "\n",
        "    # Modeli yükle\n",
        "    try:\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "    except Exception as e:\n",
        "        return f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Test verisini yükle\n",
        "    try:\n",
        "        if flow_from_directory:\n",
        "            test_data = load_images_with_flow_from_directory(test_path, target_size=target_size, batch_size=8)\n",
        "        else:\n",
        "            test_data = load_images_from_directory(test_path, target_size=target_size, batch_size=8)\n",
        "    except Exception as e:\n",
        "        return f\"Test verisi yükleme hatası: {str(e)}\\nTest yolu: {test_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Katman seçimini işle (sadece Donanım modunda)\n",
        "    layer_index = None\n",
        "    current_layer = None\n",
        "    if mode == \"Donanım\" and layer_selection and layer_selection != \"None\":\n",
        "        try:\n",
        "            layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "            current_layer = loaded_model.layers[layer_index]\n",
        "        except (ValueError, IndexError) as e:\n",
        "            return f\"Katman seçimi hatası: {str(e)}\\nSeçilen katman: {layer_selection}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Veri seçimini yap\n",
        "    try:\n",
        "        if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "            if flow_from_directory:\n",
        "                input_data = next(test_data)\n",
        "            else:\n",
        "                input_data = next(iter(test_data))\n",
        "            data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "        else:\n",
        "            expected_shape = loaded_model.input.shape[1:]\n",
        "            input_data = np.random.random((8, *expected_shape))\n",
        "            data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "    except Exception as e:\n",
        "        return f\"Veri seçimi hatası: {str(e)}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    try:\n",
        "        if mode == \"Simülasyon\" or layer_selection == \"None\" or not layer_selection:\n",
        "            # Simülasyon modunda veya katman seçilmediğinde tam modeli çalıştır\n",
        "            real_output = loaded_model.predict(input_data, verbose=0)\n",
        "            fpga_output = real_output\n",
        "            serialized_output = real_output.flatten().tobytes()\n",
        "            data_sent_size = len(serialized_output)\n",
        "            weights_info = \"Hızlandırma yapılmadı, ağırlıklar kullanılmadı.\"\n",
        "            bin_file = None\n",
        "        else:\n",
        "            # Donanım modunda seçilen katmanın çıktısını hesapla ve FPGA ile iletişim kur\n",
        "            weights, window_params = extract_weights_and_window(current_layer)\n",
        "            real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "            output_file_x = f\"file_{uuid.uuid4()}.x\"\n",
        "            output_file_y = f\"file_{uuid.uuid4()}.y\"\n",
        "            with open(output_file_x, 'wb') as f:\n",
        "                f.write(real_output.flatten().tobytes())\n",
        "            with open(output_file_y, 'wb') as f:\n",
        "                for w in weights:\n",
        "                    f.write(w.flatten().tobytes())\n",
        "\n",
        "            bin_file = save_data_for_kagan(weights, window_params, len(real_output.flatten().tobytes()), real_output)\n",
        "\n",
        "            result_queue = queue.Queue()\n",
        "            comm_thread = threading.Thread(\n",
        "                target=communicate_with_fpga,\n",
        "                args=(real_output, output_file_x, result_queue, mode)\n",
        "            )\n",
        "            comm_thread.start()\n",
        "            comm_thread.join()\n",
        "\n",
        "            fpga_result = result_queue.get()\n",
        "            if len(fpga_result) == 3:\n",
        "                raise Exception(fpga_result[2])\n",
        "            fpga_output, data_sent_size = fpga_result\n",
        "            weights_info = f\"Ağırlıklar ve pencere parametreleri: {window_params}, Ağırlık boyutu: {sum(w.size for w in weights)} eleman\"\n",
        "\n",
        "            os.remove(output_file_x)\n",
        "            os.remove(output_file_y)\n",
        "            if bin_file:\n",
        "                os.remove(bin_file)\n",
        "\n",
        "        # Çıktıları karşılaştır ve benzerlik skorunu hesapla\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)\n",
        "\n",
        "        expected_input_shape = (loaded_model.input.shape[1:] if layer_index == 0 else\n",
        "                               loaded_model.layers[layer_index - 1].output.shape[1:] if layer_index else\n",
        "                               \"Tam model\")\n",
        "\n",
        "        # Sonuçları formatla\n",
        "        output_str = f\"Seçilen Model Türü: {model_type}\\n\"\n",
        "        output_str += f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok (Tam Model)'}\\n\"\n",
        "        output_str += f\"Mod: {mode}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape if layer_index else input_data.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Kağan'a Gönderilen Veri Boyutu: {data_sent_size} bayt\\n\"\n",
        "        output_str += f\"{weights_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        # Benzerlik skorunu görselleştir\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok'}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Bölüm 9: Gradio Arayüz Yardımcı Fonksiyonları\n",
        "# Bu bölümde, Gradio arayüzünün dinamik bileşenlerini güncelleyen fonksiyonlar tanımlanır.\n",
        "\n",
        "def update_model_dropdown(model_type):\n",
        "    # Model türü seçildiğinde model seçim dropdown'unu günceller\n",
        "    try:\n",
        "        models = list(MODEL_TYPES[model_type][\"models\"].keys())\n",
        "        return gr.Dropdown(choices=models, value=models[0], label=\"Model Seçimi\")\n",
        "    except Exception as e:\n",
        "        return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Model Seçimi\", info=f\"Hata: {str(e)}\")\n",
        "\n",
        "def update_layer_dropdown(model_type, model_selection):\n",
        "    # Model veya model türü değiştiğinde katman seçim dropdown'unu günceller\n",
        "    try:\n",
        "        model_info = MODEL_TYPES[model_type][\"models\"][model_selection]\n",
        "        model_path = model_info[\"model_path\"]\n",
        "        if not os.path.exists(model_path):\n",
        "            return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                               info=f\"Model dosyası bulunamadı: {model_path}\")\n",
        "\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "        layer_names = [\"None\"]\n",
        "        for i, layer in enumerate(loaded_model.layers):\n",
        "            try:\n",
        "                output_shape = layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: {output_shape}\")\n",
        "            except Exception as e:\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: Hata ({str(e)})\")\n",
        "        return gr.Dropdown(choices=layer_names, value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\")\n",
        "    except Exception as e:\n",
        "        return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                           info=f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\")\n",
        "\n",
        "def update_layer_visibility(mode):\n",
        "    # Çalışma modu değiştiğinde katman seçim dropdown'unun görünürlüğünü kontrol eder\n",
        "    return gr.update(visible=(mode == \"Donanım\"))\n",
        "\n",
        "# Bölüm 10: Gradio Kullanıcı Arayüzü\n",
        "# Bu bölümde, interaktif Gradio arayüzü oluşturulur ve kullanıcı girişleri alınır.\n",
        "\n",
        "with gr.Blocks(title=\"CNN Model Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# CNN Model Hızlandırıcı\")\n",
        "    gr.Markdown(\"Model türünüzü ve modelinizi seçin, ardından katman ve giriş verisi tipini belirleyin. Simülasyon veya donanım modunda FPGA çıktısının gerçek çıktı ile uyumunu görün!\")\n",
        "\n",
        "    # Model türü seçimi\n",
        "    model_type_input = gr.Dropdown(choices=list(MODEL_TYPES.keys()), label=\"Model Türü Seçimi\", value=\"LeNet\")\n",
        "\n",
        "    # Model ve mod seçimi\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(label=\"Model Seçimi\")\n",
        "        mode_input = gr.Radio(choices=[\"Simülasyon\", \"Donanım\"], label=\"Çalışma Modu\", value=\"Simülasyon\")\n",
        "\n",
        "    # Katman seçimi ve simülasyon\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin\", visible=False)\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "            submit_btn = gr.Button(\"Modeli Çalıştır\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Model türü değiştiğinde model dropdown'unu güncelle\n",
        "    model_type_input.change(fn=update_model_dropdown, inputs=model_type_input, outputs=model_input)\n",
        "\n",
        "    # Model veya model türü değiştiğinde katman dropdown'unu güncelle\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=[model_type_input, model_input], outputs=layer_input)\n",
        "    model_type_input.change(fn=update_layer_dropdown, inputs=[model_type_input, model_input], outputs=layer_input)\n",
        "\n",
        "    # Çalışma modu değiştiğinde katman dropdown'unun görünürlüğünü güncelle\n",
        "    mode_input.change(fn=update_layer_visibility, inputs=mode_input, outputs=layer_input)\n",
        "\n",
        "    # Modeli çalıştır\n",
        "    submit_btn.click(fn=run_model, inputs=[model_type_input, model_input, layer_input, data_input, mode_input], outputs=[output_text, output_animation])\n",
        "\n",
        "# Arayüzü başlat\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2g7tJz7vsjpR",
        "outputId": "457e516c-ed74-4f4e-c416-ad6098b6b885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyserial\n",
            "  Downloading pyserial-3.5-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/90.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyserial\n",
            "Successfully installed pyserial-3.5\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.42.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.11.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1651567a529ef5338f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1651567a529ef5338f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#26.08.2025 Grubun ortak phyton kodu deneme1\n",
        "\n",
        "\n",
        "# Kod Açıklaması Part Part\n",
        "\n",
        "# Bölüm 1: Kütüphane İçe Aktarmaları ve Kurulum\n",
        "# Bu bölümde, projede kullanılan tüm kütüphaneler içe aktarılır ve Google Drive bağlantısı kurulur.\n",
        "# Gerekli kütüphaneler: TensorFlow (sinir ağı), NumPy (sayısal işlemler), Gradio (kullanıcı arayüzü), PySerial (FPGA iletişimi) vb.\n",
        "\n",
        "!pip install pyserial\n",
        "!pip install gradio\n",
        "import tensorflow as tf  # Sinir ağı modellerini oluşturmak ve çalıştırmak için\n",
        "import numpy as np  # Sayısal işlemler ve dizi manipülasyonları için\n",
        "from tensorflow.keras import layers  # Sinir ağı katmanlarını tanımlamak için\n",
        "import gradio as gr  # İnteraktif kullanıcı arayüzü oluşturmak için\n",
        "import os  # Dosya ve dizin işlemleri için\n",
        "import threading  # FPGA ile paralel iletişim için çoklu iş parçacığı\n",
        "import queue  # İş parçacıkları arasında veri aktarımı için kuyruk\n",
        "import time  # Simülasyon modunda gecikme simülasyonu için\n",
        "import serial  # FPGA ile seri port üzerinden iletişim için\n",
        "import struct  # Binary veri paketleme ve açma için\n",
        "import serial.tools.list_ports  # Mevcut seri portları listelemek için\n",
        "import platform  # İşletim sistemi bilgisini almak için\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Resim yükleme ve ön işleme için\n",
        "import uuid  # Benzersiz dosya adları oluşturmak için\n",
        "from google.colab import drive  # Google Drive bağlantısı için\n",
        "\n",
        "# Google Drive'ı bağla: Modeller ve veri setleri Google Drive'da saklanıyor\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Bölüm 2: Model ve Veri Yolu Tanımlamaları\n",
        "# Bu bölümde, LeNet, MobileNet ve VGG-16 modellerinin yolları ve veri seti bilgileri tanımlanır.\n",
        "# Her model türü için farklı varyantlar ve test veri yolları belirtilir.\n",
        "\n",
        "MODEL_TYPES = {\n",
        "    \"LeNet\": {\n",
        "        \"models\": {\n",
        "            \"LeNet1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (32, 32)\n",
        "            },\n",
        "            \"LeNet2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (32, 32)\n",
        "            },\n",
        "            \"LeNet3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (32, 32)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"h5\"\n",
        "    },\n",
        "    \"MobileNet\": {\n",
        "        \"models\": {\n",
        "            \"MobilNet1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet1/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"MobilNet2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet2/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"MobilNet3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet3/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"keras\"\n",
        "    },\n",
        "    \"VGG-16\": {\n",
        "        \"models\": {\n",
        "            \"VGG16-1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-lenetsets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"VGG16-2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-vgg16sets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"VGG16-3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-mobilnetsets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"keras\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Bölüm 3: Veri Yükleme Fonksiyonları\n",
        "# Bu bölümde, test verilerini yüklemek için iki fonksiyon tanımlanır:\n",
        "# - load_images_from_directory: Alt klasörsüz dizinlerden resimleri yükler\n",
        "# - load_images_with_flow_from_directory: Alt klasörlü dizinlerden resimleri yükler\n",
        "\n",
        "def load_images_from_directory(directory, target_size, batch_size=8):\n",
        "    # Alt klasörsüz dizinlerden resimleri yükler ve ön işleme yapar\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0  # Normalizasyon\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)\n",
        "\n",
        "def load_images_with_flow_from_directory(directory, target_size, batch_size=8):\n",
        "    # Alt klasörlü dizinlerden resimleri yükler ve veri artırma uygular\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data\n",
        "\n",
        "# Bölüm 4: Ağırlık ve Pencere Parametreleri Çıkarma\n",
        "# Bu bölümde, seçilen katmanın ağırlıklarını ve pencere parametrelerini (ör. kernel boyutu, adım) çıkaran bir fonksiyon tanımlanır.\n",
        "\n",
        "def extract_weights_and_window(layer):\n",
        "    # Katmanın ağırlıklarını ve pencere parametrelerini (Conv2D veya Dense katmanları için) çıkarır\n",
        "    weights = layer.get_weights()\n",
        "    window_params = {}\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        window_params[\"kernel_size\"] = list(layer.kernel_size)\n",
        "        window_params[\"stride\"] = list(layer.strides)\n",
        "        window_params[\"padding\"] = layer.padding\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        window_params[\"units\"] = layer.units\n",
        "    return weights, window_params\n",
        "\n",
        "# Bölüm 5: Seri Port ve FPGA İletişimi\n",
        "# Bu bölümde, seri portları listelemek ve FPGA ile iletişim kurmak için fonksiyonlar tanımlanır.\n",
        "\n",
        "def get_available_ports():\n",
        "    # Mevcut seri portları listeler\n",
        "    ports = serial.tools.list_ports.comports()\n",
        "    return [port.device for port in ports]\n",
        "\n",
        "# FPGA kodundan entegre edilen fonksiyonlar\n",
        "def float2hex(data: float) -> int:\n",
        "    ret = int()\n",
        "    ret = struct.unpack('!I', struct.pack('!f', data))[0]\n",
        "    return ret\n",
        "\n",
        "def to_four_bytes_little(data) -> bytearray:\n",
        "    to4 = struct.Struct('<I').pack\n",
        "    dummy = float2hex(data)\n",
        "    ret = bytearray(to4(dummy & 0xFFFFFFFF))\n",
        "    return ret\n",
        "\n",
        "def array2bytearray_little(data: np.ndarray, dim: int) -> bytearray:\n",
        "    ret = bytearray()\n",
        "    if dim == 1 :\n",
        "        for i in range(0, data.shape[0]):\n",
        "            ret.extend(to_four_bytes_little(data[i]))\n",
        "        return ret\n",
        "    elif dim == 2:\n",
        "        for i in range(0, data.shape[0]):\n",
        "            for j in range(0, data.shape[1]):\n",
        "                ret.extend(to_four_bytes_little(data[i,j]))\n",
        "        return ret\n",
        "    else:\n",
        "        return ret\n",
        "\n",
        "def byt_conv(data: int) -> bytes:\n",
        "    ret = data.to_bytes(4,'little')\n",
        "    return ret\n",
        "\n",
        "def intarray2bytearray(data: np.ndarray) -> bytearray:\n",
        "    ret = bytearray()\n",
        "    for i in range(0, len(data)):\n",
        "        ret.extend(byt_conv(data[i]))\n",
        "    return ret\n",
        "\n",
        "def read_float(seri: serial) -> float:\n",
        "    dat = bytes()\n",
        "    dat = seri.read(4)\n",
        "    dum = struct.unpack('<I', dat)[0]\n",
        "    dat = struct.pack('>I', dum)\n",
        "    datflo = struct.unpack('>f', dat)\n",
        "    return datflo[0]\n",
        "\n",
        "def recv_res(seri: serial, row, col):\n",
        "    res = np.zeros((row,col), dtype=float)\n",
        "    for i in range(0,row):\n",
        "        for j in range(0,col):\n",
        "            res[i,j] = read_float(seri)\n",
        "    return res\n",
        "\n",
        "def Conv_HW(seri: serial, data_rows: int, data_cols: int, kernel_size: int, data_matrice, kernel):\n",
        "    result_rows = data_rows - kernel_size + 1\n",
        "    result_cols = data_cols - kernel_size + 1\n",
        "    ram1_size: int = kernel_size * kernel_size * 4\n",
        "    ram2_size: int = data_rows * data_cols * 4\n",
        "    ram3_size: int = result_cols * result_cols * 4\n",
        "    params = [data_rows, data_cols, kernel_size, result_rows, ram1_size, ram2_size, ram3_size, result_cols]\n",
        "    buf1 = bytearray()\n",
        "    for i in range(0, len(params)):\n",
        "        buf1.extend(byt_conv(params[i]))\n",
        "    buf2 = array2bytearray_little(kernel, 2)\n",
        "    buf3 = array2bytearray_little(data_matrice, 2)\n",
        "    seri.write(buf1)\n",
        "    seri.write(buf2)\n",
        "    seri.write(buf3)\n",
        "    result = recv_res(seri, result_rows, result_cols)\n",
        "    return result\n",
        "\n",
        "def communicate_with_fpga(input_data, output_file, result_queue, mode):\n",
        "\n",
        "    if mode == \"Simülasyon\":\n",
        "        time.sleep(1)\n",
        "        with open(output_file, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), dtype=np.float32)\n",
        "        fpga_output = data.reshape(input_data.shape) + np.random.normal(0, 0.05, input_data.shape)\n",
        "        result_queue.put((fpga_output, len(data)))\n",
        "    else:\n",
        "        try:\n",
        "            ser = serial.Serial(\n",
        "                port='COM1',\n",
        "                baudrate=115200,\n",
        "                stopbits=serial.STOPBITS_TWO,\n",
        "                parity=serial.PARITY_NONE,\n",
        "                timeout=2\n",
        "            )\n",
        "\n",
        "            # Conv_HW'yi kullanarak hesaplama yap\n",
        "            # Not: input_data'nın 2D olduğu varsayılıyor (örneğin tek kanal için). Çok kanallı için uyarlama gerekebilir.\n",
        "            # Burada basitlik için input_data'nın (rows, cols) şeklinde olduğunu varsayıyoruz; gerekirse reshape edin.\n",
        "            if len(input_data.shape) > 2:\n",
        "                # Örnek: Tek batch ve kanal için flatten to 2D; gerçekte loop ile kanalları işleyin.\n",
        "                data_matrice = input_data[0, :, :, 0]  # İlk batch, ilk kanal örneği; uyarlayın.\n",
        "            else:\n",
        "                data_matrice = input_data\n",
        "\n",
        "            # Kernel de benzer şekilde; weights[0] kernel (height, width, in_channels, out_channels)\n",
        "            # Basitlik için tek kanal kernel alıyoruz; tam entegrasyon için loop ekleyin.\n",
        "            kernel = weights[0][:, :, 0, 0]  # Örnek: İlk filtre; gerçekte tüm filtreleri işleyin.\n",
        "\n",
        "            data_rows, data_cols = data_matrice.shape\n",
        "            kernel_size = kernel.shape[0]  # Kare kernel varsayarak\n",
        "\n",
        "            fpga_output = Conv_HW(ser, data_rows, data_cols, kernel_size, data_matrice, kernel)\n",
        "\n",
        "            # fpga_output'ı orijinal shape'e uyarla\n",
        "            fpga_output = np.expand_dims(fpga_output, axis=(0, -1))  # Örnek uyarlama; shape'i input_data'ya göre ayarlayın.\n",
        "\n",
        "            data_sent_size = (data_rows * data_cols + kernel_size * kernel_size) * 4  # Yaklaşık boyut\n",
        "\n",
        "            ser.close()\n",
        "\n",
        "            result_queue.put((fpga_output, data_sent_size))\n",
        "\n",
        "        except Exception as e:\n",
        "            available_ports = get_available_ports()\n",
        "            error_msg = f\"FPGA iletişimi hatası: {str(e)}\\nMevcut portlar: {available_ports or 'Yok'}\\nLütfen doğru portu kontrol edin veya FPGA'nın bağlı olduğundan emin olun.\"\n",
        "            result_queue.put((None, 0, error_msg))\n",
        "\n",
        "# Bölüm 6: Katman Çıktısı Hesaplama\n",
        "# Bu bölümde, seçilen katmanın çıktısını hesaplayan bir fonksiyon tanımlanır.\n",
        "\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    # Belirtilen katmanın çıktısını hesaplar\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# Bölüm 7: Kağan için Veri Hazırlama\n",
        "# Bu bölümde, ağırlıklar ve çıktılar binary formatta kaydedilir (FPGA için veri hazırlığı).\n",
        "\n",
        "def save_data_for_kagan(weights, window_params, data_size, output_data):\n",
        "    # Ağırlıkları, pencere parametrelerini ve çıktıları binary dosyaya kaydeder\n",
        "    bin_file = f\"data_for_kagan_{uuid.uuid4()}.bin\"\n",
        "    with open(bin_file, 'wb') as f:\n",
        "        for w in weights:\n",
        "            f.write(w.flatten().astype(np.float32).tobytes())\n",
        "        if window_params:\n",
        "            if \"kernel_size\" in window_params:\n",
        "                f.write(struct.pack('ii', *window_params[\"kernel_size\"]))\n",
        "                f.write(struct.pack('ii', *window_params[\"stride\"]))\n",
        "                padding_val = 1 if window_params[\"padding\"] == \"valid\" else 0\n",
        "                f.write(struct.pack('i', padding_val))\n",
        "            elif \"units\" in window_params:\n",
        "                f.write(struct.pack('i', window_params[\"units\"]))\n",
        "        f.write(struct.pack('Q', data_size))\n",
        "        f.write(output_data.flatten().astype(np.float32).tobytes())\n",
        "    return bin_file\n",
        "\n",
        "# Bölüm 8: Ana Simülasyon ve Çalıştırma Fonksiyonu\n",
        "# Bu bölümde, modelin çalıştırılması, FPGA ile iletişim ve sonuçların karşılaştırılması gerçekleştirilir.\n",
        "\n",
        "def run_model(model_type, model_selection, layer_selection, data_choice, mode):\n",
        "    # Seçilen model, katman ve mod ile modeli çalıştırır ve FPGA çıktısını gerçek çıktı ile karşılaştırır\n",
        "    model_info = MODEL_TYPES[model_type][\"models\"][model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "    target_size = model_info[\"target_size\"]\n",
        "    file_format = MODEL_TYPES[model_type][\"file_format\"]\n",
        "\n",
        "    # Modeli yükle\n",
        "    try:\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "    except Exception as e:\n",
        "        return f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Test verisini yükle\n",
        "    try:\n",
        "        if flow_from_directory:\n",
        "            test_data = load_images_with_flow_from_directory(test_path, target_size=target_size, batch_size=8)\n",
        "        else:\n",
        "            test_data = load_images_from_directory(test_path, target_size=target_size, batch_size=8)\n",
        "    except Exception as e:\n",
        "        return f\"Test verisi yükleme hatası: {str(e)}\\nTest yolu: {test_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Katman seçimini işle (sadece Donanım modunda)\n",
        "    layer_index = None\n",
        "    current_layer = None\n",
        "    if mode == \"Donanım\" and layer_selection and layer_selection != \"None\":\n",
        "        try:\n",
        "            layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "            current_layer = loaded_model.layers[layer_index]\n",
        "        except (ValueError, IndexError) as e:\n",
        "            return f\"Katman seçimi hatası: {str(e)}\\nSeçilen katman: {layer_selection}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Veri seçimini yap\n",
        "    try:\n",
        "        if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "            if flow_from_directory:\n",
        "                input_data = next(test_data)\n",
        "            else:\n",
        "                input_data = next(iter(test_data))\n",
        "            data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "        else:\n",
        "            expected_shape = loaded_model.input.shape[1:]\n",
        "            input_data = np.random.random((8, *expected_shape))\n",
        "            data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "    except Exception as e:\n",
        "        return f\"Veri seçimi hatası: {str(e)}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    try:\n",
        "        if mode == \"Simülasyon\" or layer_selection == \"None\" or not layer_selection:\n",
        "            # Simülasyon modunda veya katman seçilmediğinde tam modeli çalıştır\n",
        "            real_output = loaded_model.predict(input_data, verbose=0)\n",
        "            fpga_output = real_output\n",
        "            serialized_output = real_output.flatten().tobytes()\n",
        "            data_sent_size = len(serialized_output)\n",
        "            weights_info = \"Hızlandırma yapılmadı, ağırlıklar kullanılmadı.\"\n",
        "            bin_file = None\n",
        "        else:\n",
        "            # Donanım modunda seçilen katmanın çıktısını hesapla ve FPGA ile iletişim kur\n",
        "            global weights  # Conv_HW için weights'i global yap (entegre ederken erişim için)\n",
        "            weights, window_params = extract_weights_and_window(current_layer)\n",
        "            real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "            output_file_x = f\"file_{uuid.uuid4()}.x\"\n",
        "            with open(output_file_x, 'wb') as f:\n",
        "                f.write(real_output.flatten().tobytes())  # input_data yerine real_output (katman inputu) kullan; ama Conv_HW için data_matrice katman inputu olmalı.\n",
        "\n",
        "            bin_file = save_data_for_kagan(weights, window_params, len(real_output.flatten().tobytes()), real_output)\n",
        "\n",
        "            result_queue = queue.Queue()\n",
        "            comm_thread = threading.Thread(\n",
        "                target=communicate_with_fpga,\n",
        "                args=(real_output, output_file_x, result_queue, mode)  # input_data yerine katman inputu (real_output öncesi output)\n",
        "            )\n",
        "            comm_thread.start()\n",
        "            comm_thread.join()\n",
        "\n",
        "            fpga_result = result_queue.get()\n",
        "            if len(fpga_result) == 3:\n",
        "                raise Exception(fpga_result[2])\n",
        "            fpga_output, data_sent_size = fpga_result\n",
        "            weights_info = f\"Ağırlıklar ve pencere parametreleri: {window_params}, Ağırlık boyutu: {sum(w.size for w in weights)} eleman\"\n",
        "\n",
        "            os.remove(output_file_x)\n",
        "            if bin_file:\n",
        "                os.remove(bin_file)\n",
        "\n",
        "        # Çıktıları karşılaştır ve benzerlik skorunu hesapla\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)\n",
        "\n",
        "        expected_input_shape = (loaded_model.input.shape[1:] if layer_index == 0 else\n",
        "                               loaded_model.layers[layer_index - 1].output.shape[1:] if layer_index else\n",
        "                               \"Tam model\")\n",
        "\n",
        "        # Sonuçları formatla\n",
        "        output_str = f\"Seçilen Model Türü: {model_type}\\n\"\n",
        "        output_str += f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok (Tam Model)'}\\n\"\n",
        "        output_str += f\"Mod: {mode}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape if layer_index else input_data.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Kağan'a Gönderilen Veri Boyutu: {data_sent_size} bayt\\n\"\n",
        "        output_str += f\"{weights_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        # Benzerlik skorunu görselleştir\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok'}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Bölüm 9: Gradio Arayüz Yardımcı Fonksiyonları\n",
        "# Bu bölümde, Gradio arayüzünün dinamik bileşenlerini güncelleyen fonksiyonlar tanımlanır.\n",
        "\n",
        "def update_model_dropdown(model_type):\n",
        "    # Model türü seçildiğinde model seçim dropdown'unu günceller\n",
        "    try:\n",
        "        models = list(MODEL_TYPES[model_type][\"models\"].keys())\n",
        "        return gr.Dropdown(choices=models, value=models[0], label=\"Model Seçimi\")\n",
        "    except Exception as e:\n",
        "        return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Model Seçimi\", info=f\"Hata: {str(e)}\")\n",
        "\n",
        "def update_layer_dropdown(model_type, model_selection):\n",
        "    # Model veya model türü değiştiğinde katman seçim dropdown'unu günceller\n",
        "    try:\n",
        "        model_info = MODEL_TYPES[model_type][\"models\"][model_selection]\n",
        "        model_path = model_info[\"model_path\"]\n",
        "        if not os.path.exists(model_path):\n",
        "            return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                               info=f\"Model dosyası bulunamadı: {model_path}\")\n",
        "\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "        layer_names = [\"None\"]\n",
        "        for i, layer in enumerate(loaded_model.layers):\n",
        "            try:\n",
        "                output_shape = layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: {output_shape}\")\n",
        "            except Exception as e:\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: Hata ({str(e)})\")\n",
        "        return gr.Dropdown(choices=layer_names, value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\")\n",
        "    except Exception as e:\n",
        "        return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                           info=f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\")\n",
        "\n",
        "def update_layer_visibility(mode):\n",
        "    # Çalışma modu değiştiğinde katman seçim dropdown'unun görünürlüğünü kontrol eder\n",
        "    return gr.update(visible=(mode == \"Donanım\"))\n",
        "\n",
        "# Bölüm 10: Gradio Kullanıcı Arayüzü\n",
        "# Bu bölümde, interaktif Gradio arayüzü oluşturulur ve kullanıcı girişleri alınır.\n",
        "\n",
        "with gr.Blocks(title=\"CNN Model Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# CNN Model Hızlandırıcı\")\n",
        "    gr.Markdown(\"Model türünüzü ve modelinizi seçin, ardından katman ve giriş verisi tipini belirleyin. Simülasyon veya donanım modunda FPGA çıktısının gerçek çıktı ile uyumunu görün!\")\n",
        "\n",
        "    # Model türü seçimi\n",
        "    model_type_input = gr.Dropdown(choices=list(MODEL_TYPES.keys()), label=\"Model Türü Seçimi\", value=\"LeNet\")\n",
        "\n",
        "    # Model ve mod seçimi\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(label=\"Model Seçimi\")\n",
        "        mode_input = gr.Radio(choices=[\"Simülasyon\", \"Donanım\"], label=\"Çalışma Modu\", value=\"Simülasyon\")\n",
        "\n",
        "    # Katman seçimi ve simülasyon\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin\", visible=False)\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "            submit_btn = gr.Button(\"Modeli Çalıştır\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Model türü değiştiğinde model dropdown'unu güncelle\n",
        "    model_type_input.change(fn=update_model_dropdown, inputs=model_type_input, outputs=model_input)\n",
        "\n",
        "    # Model veya model türü değiştiğinde katman dropdown'unu güncelle\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=[model_type_input, model_input], outputs=layer_input)\n",
        "    model_type_input.change(fn=update_layer_dropdown, inputs=[model_type_input, model_input], outputs=layer_input)\n",
        "\n",
        "    # Çalışma modu değiştiğinde katman dropdown'unun görünürlüğünü güncelle\n",
        "    mode_input.change(fn=update_layer_visibility, inputs=mode_input, outputs=layer_input)\n",
        "\n",
        "    # Modeli çalıştır\n",
        "    submit_btn.click(fn=run_model, inputs=[model_type_input, model_input, layer_input, data_input, mode_input], outputs=[output_text, output_animation])\n",
        "\n",
        "# Arayüzü başlat\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u2VOVLZXnsgj",
        "outputId": "341dde5a-f454-4b69-fc90-62fc760b6cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyserial\n",
            "  Downloading pyserial-3.5-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/90.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyserial\n",
            "Successfully installed pyserial-3.5\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.43.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.10)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://40b5f1b9c124330031.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://40b5f1b9c124330031.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#yeni güncel\n",
        "# 26.08.2025 Grubun ortak Python kodu deneme1\n",
        "\n",
        "# Kod Açıklaması Part Part\n",
        "\n",
        "# Bölüm 1: Kütüphane İçe Aktarmaları ve Kurulum\n",
        "# Bu bölümde, projede kullanılan tüm kütüphaneler içe aktarılır ve Google Drive bağlantısı kurulur.\n",
        "# Gerekli kütüphaneler: TensorFlow (sinir ağı), NumPy (sayısal işlemler), Gradio (kullanıcı arayüzü), PySerial (FPGA iletişimi) vb.\n",
        "\n",
        "!pip install pyserial\n",
        "!pip install gradio\n",
        "import tensorflow as tf  # Sinir ağı modellerini oluşturmak ve çalıştırmak için\n",
        "import numpy as np  # Sayısal işlemler ve dizi manipülasyonları için\n",
        "from tensorflow.keras import layers  # Sinir ağı katmanlarını tanımlamak için\n",
        "import gradio as gr  # İnteraktif kullanıcı arayüzü oluşturmak için\n",
        "import os  # Dosya ve dizin işlemleri için\n",
        "import threading  # FPGA ile paralel iletişim için çoklu iş parçacığı\n",
        "import queue  # İş parçacıkları arasında veri aktarımı için kuyruk\n",
        "import time  # Simülasyon modunda gecikme simülasyonu için\n",
        "import serial  # FPGA ile seri port üzerinden iletişim için\n",
        "import struct  # Binary veri paketleme ve açma için\n",
        "import serial.tools.list_ports  # Mevcut seri portları listelemek için\n",
        "import platform  # İşletim sistemi bilgisini almak için\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Resim yükleme ve ön işleme için\n",
        "import uuid  # Benzersiz dosya adları oluşturmak için\n",
        "from google.colab import drive  # Google Drive bağlantısı için\n",
        "\n",
        "# Google Drive'ı bağla: Modeller ve veri setleri Google Drive'da saklanıyor\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Bölüm 2: Model ve Veri Yolu Tanımlamaları\n",
        "# Bu bölümde, LeNet, MobileNet ve VGG-16 modellerinin yolları ve veri seti bilgileri tanımlanır.\n",
        "# Her model türü için farklı varyantlar ve test veri yolları belirtilir.\n",
        "\n",
        "MODEL_TYPES = {\n",
        "    \"LeNet\": {\n",
        "        \"models\": {\n",
        "            \"LeNet1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (32, 32)\n",
        "            },\n",
        "            \"LeNet2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (32, 32)\n",
        "            },\n",
        "            \"LeNet3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (32, 32)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"h5\"\n",
        "    },\n",
        "    \"MobileNet\": {\n",
        "        \"models\": {\n",
        "            \"MobilNet1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet1/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"MobilNet2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet2/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"MobilNet3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet3/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"keras\"\n",
        "    },\n",
        "    \"VGG-16\": {\n",
        "        \"models\": {\n",
        "            \"VGG16-1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-lenetsets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"VGG16-2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-vgg16sets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"VGG16-3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-mobilnetsets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"keras\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Bölüm 3: Veri Yükleme Fonksiyonları\n",
        "# Bu bölümde, test verilerini yüklemek için iki fonksiyon tanımlanır:\n",
        "# - load_images_from_directory: Alt klasörsüz dizinlerden resimleri yükler\n",
        "# - load_images_with_flow_from_directory: Alt klasörlü dizinlerden resimleri yükler\n",
        "\n",
        "def load_images_from_directory(directory, target_size, batch_size=8):\n",
        "    # Alt klasörsüz dizinlerden resimleri yükler ve ön işleme yapar\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0  # Normalizasyon\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)\n",
        "\n",
        "def load_images_with_flow_from_directory(directory, target_size, batch_size=8):\n",
        "    # Alt klasörlü dizinlerden resimleri yükler ve veri artırma uygular\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data\n",
        "\n",
        "# Bölüm 4: Ağırlık ve Pencere Parametreleri Çıkarma\n",
        "# Bu bölümde, seçilen katmanın ağırlıklarını ve pencere parametrelerini (ör. kernel boyutu, adım) çıkaran bir fonksiyon tanımlanır.\n",
        "\n",
        "def extract_weights_and_window(layer):\n",
        "    # Katmanın ağırlıklarını ve pencere parametrelerini (Conv2D veya Dense katmanları için) çıkarır\n",
        "    weights = layer.get_weights()\n",
        "    window_params = {}\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        window_params[\"kernel_size\"] = list(layer.kernel_size)\n",
        "        window_params[\"stride\"] = list(layer.strides)\n",
        "        window_params[\"padding\"] = layer.padding\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        window_params[\"units\"] = layer.units\n",
        "    return weights, window_params\n",
        "\n",
        "# Bölüm 5: Seri Port ve FPGA İletişimi\n",
        "# Bu bölümde, seri portları listelemek ve FPGA ile iletişim kurmak için fonksiyonlar tanımlanır.\n",
        "\n",
        "def get_available_ports():\n",
        "    # Mevcut seri portları listeler\n",
        "    ports = serial.tools.list_ports.comports()\n",
        "    return [port.device for port in ports]\n",
        "\n",
        "# FPGA kodundan entegre edilen fonksiyonlar\n",
        "def float2hex(data: float) -> int:\n",
        "    ret = int()\n",
        "    ret = struct.unpack('!I', struct.pack('!f', data))[0]\n",
        "    return ret\n",
        "\n",
        "def to_four_bytes_little(data) -> bytearray:\n",
        "    to4 = struct.Struct('<I').pack\n",
        "    dummy = float2hex(data)\n",
        "    ret = bytearray(to4(dummy & 0xFFFFFFFF))\n",
        "    return ret\n",
        "\n",
        "def array2bytearray_little(data: np.ndarray, dim: int) -> bytearray:\n",
        "    ret = bytearray()\n",
        "    if dim == 1:\n",
        "        for i in range(0, data.shape[0]):\n",
        "            ret.extend(to_four_bytes_little(data[i]))\n",
        "        return ret\n",
        "    elif dim == 2:\n",
        "        for i in range(0, data.shape[0]):\n",
        "            for j in range(0, data.shape[1]):\n",
        "                ret.extend(to_four_bytes_little(data[i,j]))\n",
        "        return ret\n",
        "    else:\n",
        "        return ret\n",
        "\n",
        "def byt_conv(data: int) -> bytes:\n",
        "    ret = data.to_bytes(4,'little')\n",
        "    return ret\n",
        "\n",
        "def intarray2bytearray(data: np.ndarray) -> bytearray:\n",
        "    ret = bytearray()\n",
        "    for i in range(0, len(data)):\n",
        "        ret.extend(byt_conv(data[i]))\n",
        "    return ret\n",
        "\n",
        "def read_float(seri: serial) -> float:\n",
        "    dat = bytes()\n",
        "    dat = seri.read(4)\n",
        "    dum = struct.unpack('<I', dat)[0]\n",
        "    dat = struct.pack('>I', dum)\n",
        "    datflo = struct.unpack('>f', dat)\n",
        "    return datflo[0]\n",
        "\n",
        "def recv_res(seri: serial, row, col):\n",
        "    res = np.zeros((row,col), dtype=float)\n",
        "    for i in range(0,row):\n",
        "        for j in range(0,col):\n",
        "            res[i,j] = read_float(seri)\n",
        "    return res\n",
        "\n",
        "def Conv_HW(seri: serial, data_rows: int, data_cols: int, kernel_size: int, data_matrice, kernel):\n",
        "    result_rows = data_rows - kernel_size + 1\n",
        "    result_cols = data_cols - kernel_size + 1\n",
        "    ram1_size: int = kernel_size * kernel_size * 4\n",
        "    ram2_size: int = data_rows * data_cols * 4\n",
        "    ram3_size: int = result_cols * result_cols * 4\n",
        "    params = [data_rows, data_cols, kernel_size, result_rows, ram1_size, ram2_size, ram3_size, result_cols]\n",
        "    buf1 = bytearray()\n",
        "    for i in range(0, len(params)):\n",
        "        buf1.extend(byt_conv(params[i]))\n",
        "    buf2 = array2bytearray_little(kernel, 2)\n",
        "    buf3 = array2bytearray_little(data_matrice, 2)\n",
        "    seri.write(buf1)\n",
        "    seri.write(buf2)\n",
        "    seri.write(buf3)\n",
        "    result = recv_res(seri, result_rows, result_cols)\n",
        "    return result\n",
        "\n",
        "def communicate_with_fpga(input_data, output_file, result_queue, mode):\n",
        "    if mode == \"Simülasyon\":\n",
        "        time.sleep(1)\n",
        "        with open(output_file, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), dtype=np.float32)\n",
        "        fpga_output = data.reshape(input_data.shape) + np.random.normal(0, 0.05, input_data.shape)\n",
        "        result_queue.put((fpga_output, len(data)))\n",
        "    else:\n",
        "        try:\n",
        "            ser = serial.Serial(\n",
        "                port='COM1',\n",
        "                baudrate=115200,\n",
        "                stopbits=serial.STOPBITS_TWO,\n",
        "                parity=serial.PARITY_NONE,\n",
        "                timeout=2\n",
        "            )\n",
        "\n",
        "            # Çok kanallı giriş ve çoklu filtreler için işlem\n",
        "            # input_data şekli: (batch_size, height, width, in_channels)\n",
        "            # weights[0] şekli: (kernel_height, kernel_width, in_channels, out_channels)\n",
        "            in_channels = input_data.shape[-1]  # Giriş kanalları\n",
        "            out_channels = weights[0].shape[-1]  # Çıkış kanalları (filtre sayısı)\n",
        "            data_rows, data_cols = input_data.shape[1:3]  # Yükseklik ve genişlik\n",
        "            kernel_size = weights[0].shape[0]  # Kare kernel varsayımı\n",
        "\n",
        "            # Çıktı boyutlarını hesapla\n",
        "            result_rows = data_rows - kernel_size + 1\n",
        "            result_cols = data_cols - kernel_size + 1\n",
        "            # Toplam çıktı şekli: (batch_size, result_rows, result_cols, out_channels)\n",
        "            fpga_output = np.zeros((input_data.shape[0], result_rows, result_cols, out_channels), dtype=np.float32)\n",
        "\n",
        "            # Her giriş kanalı ve çıkış filtresi için döngü\n",
        "            for out_ch in range(out_channels):  # Çıkış filtreleri\n",
        "                for in_ch in range(in_channels):  # Giriş kanalları\n",
        "                    # Giriş verisinden ilgili kanalı seç\n",
        "                    data_matrice = input_data[0, :, :, in_ch]  # İlk batch, belirli kanal\n",
        "                    # Ağırlıklardan ilgili filtreyi seç\n",
        "                    kernel = weights[0][:, :, in_ch, out_ch]  # Belirli giriş/çıkış kanalı için filtre\n",
        "\n",
        "                    # Conv_HW ile evrişim işlemini gerçekleştir\n",
        "                    channel_output = Conv_HW(ser, data_rows, data_cols, kernel_size, data_matrice, kernel)\n",
        "\n",
        "                    # Çıktıyı toplu sonuca ekle (kanallar arasında toplama)\n",
        "                    fpga_output[0, :, :, out_ch] += channel_output  # İlk batch için\n",
        "\n",
        "            # Bias ekleme (varsa)\n",
        "            if len(weights) > 1:  # Bias varsa (weights[1])\n",
        "                for out_ch in range(out_channels):\n",
        "                    fpga_output[0, :, :, out_ch] += weights[1][out_ch]\n",
        "\n",
        "            # Çıktıyı orijinal şekle uygun hale getir\n",
        "            data_sent_size = (data_rows * data_cols * in_channels + kernel_size * kernel_size * in_channels * out_channels) * 4  # Yaklaşık veri boyutu\n",
        "\n",
        "            ser.close()\n",
        "            result_queue.put((fpga_output, data_sent_size))\n",
        "\n",
        "        except Exception as e:\n",
        "            available_ports = get_available_ports()\n",
        "            error_msg = f\"FPGA iletişimi hatası: {str(e)}\\nMevcut portlar: {available_ports or 'Yok'}\\nLütfen doğru portu kontrol edin veya FPGA'nın bağlı olduğundan emin olun.\"\n",
        "            result_queue.put((None, 0, error_msg))\n",
        "\n",
        "# Bölüm 6: Katman Çıktısı Hesaplama\n",
        "# Bu bölümde, seçilen katmanın çıktısını hesaplayan bir fonksiyon tanımlanır.\n",
        "\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    # Belirtilen katmanın çıktısını hesaplar\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# Bölüm 7: Kağan için Veri Hazırlama\n",
        "# Bu bölümde, ağırlıklar ve çıktılar binary formatta kaydedilir (FPGA için veri hazırlığı).\n",
        "\n",
        "def save_data_for_kagan(weights, window_params, data_size, output_data):\n",
        "    # Ağırlıkları, pencere parametrelerini ve çıktıları binary dosyaya kaydeder\n",
        "    bin_file = f\"data_for_kagan_{uuid.uuid4()}.bin\"\n",
        "    with open(bin_file, 'wb') as f:\n",
        "        for w in weights:\n",
        "            f.write(w.flatten().astype(np.float32).tobytes())\n",
        "        if window_params:\n",
        "            if \"kernel_size\" in window_params:\n",
        "                f.write(struct.pack('ii', *window_params[\"kernel_size\"]))\n",
        "                f.write(struct.pack('ii', *window_params[\"stride\"]))\n",
        "                padding_val = 1 if window_params[\"padding\"] == \"valid\" else 0\n",
        "                f.write(struct.pack('i', padding_val))\n",
        "            elif \"units\" in window_params:\n",
        "                f.write(struct.pack('i', window_params[\"units\"]))\n",
        "        f.write(struct.pack('Q', data_size))\n",
        "        f.write(output_data.flatten().astype(np.float32).tobytes())\n",
        "    return bin_file\n",
        "\n",
        "# Bölüm 8: Ana Simülasyon ve Çalıştırma Fonksiyonu\n",
        "# Bu bölümde, modelin çalıştırılması, FPGA ile iletişim ve sonuçların karşılaştırılması gerçekleştirilir.\n",
        "\n",
        "def run_model(model_type, model_selection, layer_selection, data_choice, mode):\n",
        "    # Seçilen model, katman ve mod ile modeli çalıştırır ve FPGA çıktısını gerçek çıktı ile karşılaştırır\n",
        "    model_info = MODEL_TYPES[model_type][\"models\"][model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "    target_size = model_info[\"target_size\"]\n",
        "    file_format = MODEL_TYPES[model_type][\"file_format\"]\n",
        "\n",
        "    # Modeli yükle\n",
        "    try:\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "    except Exception as e:\n",
        "        return f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Test verisini yükle\n",
        "    try:\n",
        "        if flow_from_directory:\n",
        "            test_data = load_images_with_flow_from_directory(test_path, target_size=target_size, batch_size=8)\n",
        "        else:\n",
        "            test_data = load_images_from_directory(test_path, target_size=target_size, batch_size=8)\n",
        "    except Exception as e:\n",
        "        return f\"Test verisi yükleme hatası: {str(e)}\\nTest yolu: {test_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Katman seçimini işle (sadece Donanım modunda)\n",
        "    layer_index = None\n",
        "    current_layer = None\n",
        "    if mode == \"Donanım\" and layer_selection and layer_selection != \"None\":\n",
        "        try:\n",
        "            layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "            current_layer = loaded_model.layers[layer_index]\n",
        "        except (ValueError, IndexError) as e:\n",
        "            return f\"Katman seçimi hatası: {str(e)}\\nSeçilen katman: {layer_selection}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Veri seçimini yap\n",
        "    try:\n",
        "        if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "            if flow_from_directory:\n",
        "                input_data = next(test_data)\n",
        "            else:\n",
        "                input_data = next(iter(test_data))\n",
        "            data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "        else:\n",
        "            expected_shape = loaded_model.input.shape[1:]\n",
        "            input_data = np.random.random((8, *expected_shape))\n",
        "            data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "    except Exception as e:\n",
        "        return f\"Veri seçimi hatası: {str(e)}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    try:\n",
        "        if mode == \"Simülasyon\" or layer_selection == \"None\" or not layer_selection:\n",
        "            # Simülasyon modunda veya katman seçilmediğinde tam modeli çalıştır\n",
        "            real_output = loaded_model.predict(input_data, verbose=0)\n",
        "            fpga_output = real_output\n",
        "            serialized_output = real_output.flatten().tobytes()\n",
        "            data_sent_size = len(serialized_output)\n",
        "            weights_info = \"Hızlandırma yapılmadı, ağırlıklar kullanılmadı.\"\n",
        "            bin_file = None\n",
        "        else:\n",
        "            # Donanım modunda seçilen katmanın çıktısını hesapla ve FPGA ile iletişim kur\n",
        "            global weights  # Conv_HW için weights'i global yap (entegre ederken erişim için)\n",
        "            weights, window_params = extract_weights_and_window(current_layer)\n",
        "            real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "            output_file_x = f\"file_{uuid.uuid4()}.x\"\n",
        "            with open(output_file_x, 'wb') as f:\n",
        "                f.write(real_output.flatten().tobytes())  # input_data yerine real_output (katman inputu) kullan; ama Conv_HW için data_matrice katman inputu olmalı.\n",
        "\n",
        "            bin_file = save_data_for_kagan(weights, window_params, len(real_output.flatten().tobytes()), real_output)\n",
        "\n",
        "            result_queue = queue.Queue()\n",
        "            comm_thread = threading.Thread(\n",
        "                target=communicate_with_fpga,\n",
        "                args=(real_output, output_file_x, result_queue, mode)  # input_data yerine katman inputu (real_output öncesi output)\n",
        "            )\n",
        "            comm_thread.start()\n",
        "            comm_thread.join()\n",
        "\n",
        "            fpga_result = result_queue.get()\n",
        "            if len(fpga_result) == 3:\n",
        "                raise Exception(fpga_result[2])\n",
        "            fpga_output, data_sent_size = fpga_result\n",
        "            weights_info = f\"Ağırlıklar ve pencere parametreleri: {window_params}, Ağırlık boyutu: {sum(w.size for w in weights)} eleman\"\n",
        "\n",
        "            os.remove(output_file_x)\n",
        "            if bin_file:\n",
        "                os.remove(bin_file)\n",
        "\n",
        "        # Çıktıları karşılaştır ve benzerlik skorunu hesapla\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)\n",
        "\n",
        "        expected_input_shape = (loaded_model.input.shape[1:] if layer_index == 0 else\n",
        "                               loaded_model.layers[layer_index - 1].output.shape[1:] if layer_index else\n",
        "                               \"Tam model\")\n",
        "\n",
        "        # Sonuçları formatla\n",
        "        output_str = f\"Seçilen Model Türü: {model_type}\\n\"\n",
        "        output_str += f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok (Tam Model)'}\\n\"\n",
        "        output_str += f\"Mod: {mode}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape if layer_index else input_data.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Kağan'a Gönderilen Veri Boyutu: {data_sent_size} bayt\\n\"\n",
        "        output_str += f\"{weights_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        # Benzerlik skorunu görselleştir\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok'}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Bölüm 9: Gradio Arayüz Yardımcı Fonksiyonları\n",
        "# Bu bölümde, Gradio arayüzünün dinamik bileşenlerini güncelleyen fonksiyonlar tanımlanır.\n",
        "\n",
        "def update_model_dropdown(model_type):\n",
        "    # Model türü seçildiğinde model seçim dropdown'unu günceller\n",
        "    try:\n",
        "        models = list(MODEL_TYPES[model_type][\"models\"].keys())\n",
        "        return gr.Dropdown(choices=models, value=models[0], label=\"Model Seçimi\")\n",
        "    except Exception as e:\n",
        "        return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Model Seçimi\", info=f\"Hata: {str(e)}\")\n",
        "\n",
        "def update_layer_dropdown(model_type, model_selection):\n",
        "    # Model veya model türü değiştiğinde katman seçim dropdown'unu günceller\n",
        "    try:\n",
        "        model_info = MODEL_TYPES[model_type][\"models\"][model_selection]\n",
        "        model_path = model_info[\"model_path\"]\n",
        "        if not os.path.exists(model_path):\n",
        "            return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                               info=f\"Model dosyası bulunamadı: {model_path}\")\n",
        "\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "        layer_names = [\"None\"]\n",
        "        for i, layer in enumerate(loaded_model.layers):\n",
        "            try:\n",
        "                output_shape = layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: {output_shape}\")\n",
        "            except Exception as e:\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: Hata ({str(e)})\")\n",
        "        return gr.Dropdown(choices=layer_names, value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\")\n",
        "    except Exception as e:\n",
        "        return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                           info=f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\")\n",
        "\n",
        "def update_layer_visibility(mode):\n",
        "    # Çalışma modu değiştiğinde katman seçim dropdown'unun görünürlüğünü kontrol eder\n",
        "    return gr.update(visible=(mode == \"Donanım\"))\n",
        "\n",
        "# Bölüm 10: Gradio Kullanıcı Arayüzü\n",
        "# Bu bölümde, interaktif Gradio arayüzü oluşturulur ve kullanıcı girişleri alınır.\n",
        "\n",
        "with gr.Blocks(title=\"CNN Model Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# CNN Model Hızlandırıcı\")\n",
        "    gr.Markdown(\"Model türünüzü ve modelinizi seçin, ardından katman ve giriş verisi tipini belirleyin. Simülasyon veya donanım modunda FPGA çıktısının gerçek çıktı ile uyumunu görün!\")\n",
        "\n",
        "    # Model türü seçimi\n",
        "    model_type_input = gr.Dropdown(choices=list(MODEL_TYPES.keys()), label=\"Model Türü Seçimi\", value=\"LeNet\")\n",
        "\n",
        "    # Model ve mod seçimi\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(label=\"Model Seçimi\")\n",
        "        mode_input = gr.Radio(choices=[\"Simülasyon\", \"Donanım\"], label=\"Çalışma Modu\", value=\"Simülasyon\")\n",
        "\n",
        "    # Katman seçimi ve simülasyon\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin\", visible=False)\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "            submit_btn = gr.Button(\"Modeli Çalıştır\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Model türü değiştiğinde model dropdown'unu güncelle\n",
        "    model_type_input.change(fn=update_model_dropdown, inputs=model_type_input, outputs=model_input)\n",
        "\n",
        "    # Model veya model türü değiştiğinde katman dropdown'unu güncelle\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=[model_type_input, model_input], outputs=layer_input)\n",
        "    model_type_input.change(fn=update_layer_dropdown, inputs=[model_type_input, model_input], outputs=layer_input)\n",
        "\n",
        "    # Çalışma modu değiştiğinde katman dropdown'unun görünürlüğünü güncelle\n",
        "    mode_input.change(fn=update_layer_visibility, inputs=mode_input, outputs=layer_input)\n",
        "\n",
        "    # Modeli çalıştır\n",
        "    submit_btn.click(fn=run_model, inputs=[model_type_input, model_input, layer_input, data_input, mode_input], outputs=[output_text, output_animation])\n",
        "\n",
        "# Arayüzü başlat\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P_qyZCTqe6Ys",
        "outputId": "720871f3-f31d-4be9-ec02-4b2f400e95f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyserial in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.43.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.10)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6f5036ede4692634dc.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6f5036ede4692634dc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#yeniyeni\n",
        "\n",
        "# 26.08.2025 Grubun ortak Python kodu deneme1\n",
        "\n",
        "# Kod Açıklaması Part Part\n",
        "\n",
        "# Bölüm 1: Kütüphane İçe Aktarmaları ve Kurulum\n",
        "# Bu bölümde, projede kullanılan tüm kütüphaneler içe aktarılır ve Google Drive bağlantısı kurulur.\n",
        "# Gerekli kütüphaneler: TensorFlow (sinir ağı), NumPy (sayısal işlemler), Gradio (kullanıcı arayüzü), PySerial (FPGA iletişimi) vb.\n",
        "\n",
        "!pip install pyserial\n",
        "!pip install gradio==3.50.2\n",
        "import tensorflow as tf  # Sinir ağı modellerini oluşturmak ve çalıştırmak için\n",
        "import numpy as np  # Sayısal işlemler ve dizi manipülasyonları için\n",
        "from tensorflow.keras import layers  # Sinir ağı katmanlarını tanımlamak için\n",
        "import gradio as gr  # İnteraktif kullanıcı arayüzü oluşturmak için\n",
        "import os  # Dosya ve dizin işlemleri için\n",
        "import threading  # FPGA ile paralel iletişim için çoklu iş parçacığı\n",
        "import queue  # İş parçacıkları arasında veri aktarımı için kuyruk\n",
        "import time  # Simülasyon modunda gecikme simülasyonu için\n",
        "import serial  # FPGA ile seri port üzerinden iletişim için\n",
        "import struct  # Binary veri paketleme ve açma için\n",
        "import serial.tools.list_ports  # Mevcut seri portları listelemek için\n",
        "import platform  # İşletim sistemi bilgisini almak için\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Resim yükleme ve ön işleme için\n",
        "import uuid  # Benzersiz dosya adları oluşturmak için\n",
        "from google.colab import drive  # Google Drive bağlantısı için\n",
        "\n",
        "# Google Drive'ı bağla: Modeller ve veri setleri Google Drive'da saklanıyor\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Bölüm 2: Model ve Veri Yolu Tanımlamaları\n",
        "# Bu bölümde, LeNet, MobileNet ve VGG-16 modellerinin yolları ve veri seti bilgileri tanımlanır.\n",
        "# Her model türü için farklı varyantlar ve test veri yolları belirtilir.\n",
        "\n",
        "MODEL_TYPES = {\n",
        "    \"LeNet\": {\n",
        "        \"models\": {\n",
        "            \"LeNet1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model1/lenet_model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (32, 32)\n",
        "            },\n",
        "            \"LeNet2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Model2/lenet_model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (32, 32)\n",
        "            },\n",
        "            \"LeNet3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/models/model.h5\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (32, 32)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"h5\"\n",
        "    },\n",
        "    \"MobileNet\": {\n",
        "        \"models\": {\n",
        "            \"MobilNet1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet1/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"MobilNet2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet2/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"MobilNet3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Datasetsets/MobilNet3/saved_model/mobilenet_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"keras\"\n",
        "    },\n",
        "    \"VGG-16\": {\n",
        "        \"models\": {\n",
        "            \"VGG16-1\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-lenetsets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Lenets/Lenetsetleri/test\",\n",
        "                \"flow_from_directory\": True,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"VGG16-2\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-vgg16sets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/VGG-16/test\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            },\n",
        "            \"VGG16-3\": {\n",
        "                \"model_path\": \"/content/drive/MyDrive/Modeller/vgg16model-mobilnetsets/saved_model/vgg16_model.keras\",\n",
        "                \"test_path\": \"/content/drive/MyDrive/Datasetsets/Mobilnets/seg_pred\",\n",
        "                \"flow_from_directory\": False,\n",
        "                \"target_size\": (224, 224)\n",
        "            }\n",
        "        },\n",
        "        \"file_format\": \"keras\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Bölüm 3: Veri Yükleme Fonksiyonları\n",
        "# Bu bölümde, test verilerini yüklemek için iki fonksiyon tanımlanır:\n",
        "# - load_images_from_directory: Alt klasörsüz dizinlerden resimleri yükler\n",
        "# - load_images_with_flow_from_directory: Alt klasörlü dizinlerden resimleri yükler\n",
        "\n",
        "def load_images_from_directory(directory, target_size, batch_size=8):\n",
        "    # Alt klasörsüz dizinlerden resimleri yükler ve ön işleme yapar\n",
        "    images = []\n",
        "    if not os.path.exists(directory):\n",
        "        raise ValueError(f\"{directory} klasörü bulunamadı!\")\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0  # Normalizasyon\n",
        "            images.append(img_array)\n",
        "    if not images:\n",
        "        raise ValueError(f\"{directory} dizininde geçerli resim dosyası bulunamadı!\")\n",
        "    images = np.array(images)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(batch_size)\n",
        "\n",
        "def load_images_with_flow_from_directory(directory, target_size, batch_size=8):\n",
        "    # Alt klasörlü dizinlerden resimleri yükler ve veri artırma uygular\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_data\n",
        "\n",
        "# Bölüm 4: Ağırlık ve Pencere Parametreleri Çıkarma\n",
        "# Bu bölümde, seçilen katmanın ağırlıklarını ve pencere parametrelerini (ör. kernel boyutu, adım) çıkaran bir fonksiyon tanımlanır.\n",
        "\n",
        "def extract_weights_and_window(layer):\n",
        "    # Katmanın ağırlıklarını ve pencere parametrelerini (Conv2D veya Dense katmanları için) çıkarır\n",
        "    weights = layer.get_weights()\n",
        "    window_params = {}\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        window_params[\"kernel_size\"] = list(layer.kernel_size)\n",
        "        window_params[\"stride\"] = list(layer.strides)\n",
        "        window_params[\"padding\"] = layer.padding\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        window_params[\"units\"] = layer.units\n",
        "    return weights, window_params\n",
        "\n",
        "# Bölüm 5: Seri Port ve FPGA İletişimi\n",
        "# Bu bölümde, seri portları listelemek ve FPGA ile iletişim kurmak için fonksiyonlar tanımlanır.\n",
        "\n",
        "def get_available_ports():\n",
        "    # Mevcut seri portları listeler\n",
        "    ports = serial.tools.list_ports.comports()\n",
        "    return [port.device for port in ports]\n",
        "\n",
        "# FPGA kodundan entegre edilen fonksiyonlar\n",
        "def float2hex(data: float) -> int:\n",
        "    ret = int()\n",
        "    ret = struct.unpack('!I', struct.pack('!f', data))[0]\n",
        "    return ret\n",
        "\n",
        "def to_four_bytes_little(data) -> bytearray:\n",
        "    to4 = struct.Struct('<I').pack\n",
        "    dummy = float2hex(data)\n",
        "    ret = bytearray(to4(dummy & 0xFFFFFFFF))\n",
        "    return ret\n",
        "\n",
        "def array2bytearray_little(data: np.ndarray, dim: int) -> bytearray:\n",
        "    ret = bytearray()\n",
        "    if dim == 1:\n",
        "        for i in range(0, data.shape[0]):\n",
        "            ret.extend(to_four_bytes_little(data[i]))\n",
        "        return ret\n",
        "    elif dim == 2:\n",
        "        for i in range(0, data.shape[0]):\n",
        "            for j in range(0, data.shape[1]):\n",
        "                ret.extend(to_four_bytes_little(data[i,j]))\n",
        "        return ret\n",
        "    else:\n",
        "        return ret\n",
        "\n",
        "def byt_conv(data: int) -> bytes:\n",
        "    ret = data.to_bytes(4,'little')\n",
        "    return ret\n",
        "\n",
        "def intarray2bytearray(data: np.ndarray) -> bytearray:\n",
        "    ret = bytearray()\n",
        "    for i in range(0, len(data)):\n",
        "        ret.extend(byt_conv(data[i]))\n",
        "    return ret\n",
        "\n",
        "def read_float(seri: serial) -> float:\n",
        "    dat = bytes()\n",
        "    dat = seri.read(4)\n",
        "    dum = struct.unpack('<I', dat)[0]\n",
        "    dat = struct.pack('>I', dum)\n",
        "    datflo = struct.unpack('>f', dat)\n",
        "    return datflo[0]\n",
        "\n",
        "def recv_res(seri: serial, row, col):\n",
        "    res = np.zeros((row,col), dtype=float)\n",
        "    for i in range(0,row):\n",
        "        for j in range(0,col):\n",
        "            res[i,j] = read_float(seri)\n",
        "    return res\n",
        "\n",
        "def Conv_HW(seri: serial, data_rows: int, data_cols: int, kernel_size: int, data_matrice, kernel):\n",
        "    result_rows = data_rows - kernel_size + 1\n",
        "    result_cols = data_cols - kernel_size + 1\n",
        "    ram1_size: int = kernel_size * kernel_size * 4\n",
        "    ram2_size: int = data_rows * data_cols * 4\n",
        "    ram3_size: int = result_cols * result_cols * 4\n",
        "    params = [data_rows, data_cols, kernel_size, result_rows, ram1_size, ram2_size, ram3_size, result_cols]\n",
        "    buf1 = bytearray()\n",
        "    for i in range(0, len(params)):\n",
        "        buf1.extend(byt_conv(params[i]))\n",
        "    buf2 = array2bytearray_little(kernel, 2)\n",
        "    buf3 = array2bytearray_little(data_matrice, 2)\n",
        "    seri.write(buf1)\n",
        "    seri.write(buf2)\n",
        "    seri.write(buf3)\n",
        "    result = recv_res(seri, result_rows, result_cols)\n",
        "    return result\n",
        "\n",
        "def communicate_with_fpga(input_data, output_file, result_queue, mode):\n",
        "    if mode == \"Simülasyon\":\n",
        "        time.sleep(1)\n",
        "        with open(output_file, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), dtype=np.float32)\n",
        "        fpga_output = data.reshape(input_data.shape) + np.random.normal(0, 0.05, input_data.shape)\n",
        "        result_queue.put((fpga_output, len(data)))\n",
        "    else:\n",
        "        try:\n",
        "            ser = serial.Serial(\n",
        "                port='COM1',\n",
        "                baudrate=115200,\n",
        "                stopbits=serial.STOPBITS_TWO,\n",
        "                parity=serial.PARITY_NONE,\n",
        "                timeout=2\n",
        "            )\n",
        "\n",
        "            # Çok kanallı giriş ve çoklu filtreler için işlem\n",
        "            # input_data şekli: (batch_size, height, width, in_channels)\n",
        "            # weights[0] şekli: (kernel_height, kernel_width, in_channels, out_channels)\n",
        "            in_channels = input_data.shape[-1]  # Giriş kanalları\n",
        "            out_channels = weights[0].shape[-1]  # Çıkış kanalları (filtre sayısı)\n",
        "            data_rows, data_cols = input_data.shape[1:3]  # Yükseklik ve genişlik\n",
        "            kernel_size = weights[0].shape[0]  # Kare kernel varsayımı\n",
        "\n",
        "            # Çıktı boyutlarını hesapla\n",
        "            result_rows = data_rows - kernel_size + 1\n",
        "            result_cols = data_cols - kernel_size + 1\n",
        "            # Toplam çıktı şekli: (batch_size, result_rows, result_cols, out_channels)\n",
        "            fpga_output = np.zeros((input_data.shape[0], result_rows, result_cols, out_channels), dtype=np.float32)\n",
        "\n",
        "            # Her giriş kanalı ve çıkış filtresi için döngü\n",
        "            for out_ch in range(out_channels):  # Çıkış filtreleri\n",
        "                for in_ch in range(in_channels):  # Giriş kanalları\n",
        "                    # Giriş verisinden ilgili kanalı seç\n",
        "                    data_matrice = input_data[0, :, :, in_ch]  # İlk batch, belirli kanal\n",
        "                    # Ağırlıklardan ilgili filtreyi seç\n",
        "                    kernel = weights[0][:, :, in_ch, out_ch]  # Belirli giriş/çıkış kanalı için filtre\n",
        "\n",
        "                    # Conv_HW ile evrişim işlemini gerçekleştir\n",
        "                    channel_output = Conv_HW(ser, data_rows, data_cols, kernel_size, data_matrice, kernel)\n",
        "\n",
        "                    # Çıktıyı toplu sonuca ekle (kanallar arasında toplama)\n",
        "                    fpga_output[0, :, :, out_ch] += channel_output  # İlk batch için\n",
        "\n",
        "            # Bias ekleme (varsa)\n",
        "            if len(weights) > 1:  # Bias varsa (weights[1])\n",
        "                for out_ch in range(out_channels):\n",
        "                    fpga_output[0, :, :, out_ch] += weights[1][out_ch]\n",
        "\n",
        "            # Çıktıyı orijinal şekle uygun hale getir\n",
        "            data_sent_size = (data_rows * data_cols * in_channels + kernel_size * kernel_size * in_channels * out_channels) * 4  # Yaklaşık veri boyutu\n",
        "\n",
        "            ser.close()\n",
        "            result_queue.put((fpga_output, data_sent_size))\n",
        "\n",
        "        except Exception as e:\n",
        "            available_ports = get_available_ports()\n",
        "            error_msg = f\"FPGA iletişimi hatası: {str(e)}\\nMevcut portlar: {available_ports or 'Yok'}\\nLütfen doğru portu kontrol edin veya FPGA'nın bağlı olduğundan emin olun.\"\n",
        "            result_queue.put((None, 0, error_msg))\n",
        "\n",
        "# Bölüm 6: Katman Çıktısı Hesaplama\n",
        "# Bu bölümde, seçilen katmanın çıktısını hesaplayan bir fonksiyon tanımlanır.\n",
        "\n",
        "def get_layer_output(model, layer_index, input_data):\n",
        "    # Belirtilen katmanın çıktısını hesaplar\n",
        "    if layer_index == 0:\n",
        "        intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "    else:\n",
        "        prev_output = input_data\n",
        "        for i in range(layer_index):\n",
        "            intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[i].output)\n",
        "            prev_output = intermediate_model.predict(input_data, verbose=0)\n",
        "        intermediate_model = tf.keras.Sequential()\n",
        "        for i in range(layer_index + 1):\n",
        "            intermediate_model.add(model.layers[i])\n",
        "        return intermediate_model.predict(input_data, verbose=0)\n",
        "\n",
        "# Bölüm 7: Kağan için Veri Hazırlama\n",
        "# Bu bölümde, ağırlıklar ve çıktılar binary formatta kaydedilir (FPGA için veri hazırlığı).\n",
        "\n",
        "def save_data_for_kagan(weights, window_params, data_size, output_data):\n",
        "    # Ağırlıkları, pencere parametrelerini ve çıktıları binary dosyaya kaydeder\n",
        "    bin_file = f\"data_for_kagan_{uuid.uuid4()}.bin\"\n",
        "    with open(bin_file, 'wb') as f:\n",
        "        for w in weights:\n",
        "            f.write(w.flatten().astype(np.float32).tobytes())\n",
        "        if window_params:\n",
        "            if \"kernel_size\" in window_params:\n",
        "                f.write(struct.pack('ii', *window_params[\"kernel_size\"]))\n",
        "                f.write(struct.pack('ii', *window_params[\"stride\"]))\n",
        "                padding_val = 1 if window_params[\"padding\"] == \"valid\" else 0\n",
        "                f.write(struct.pack('i', padding_val))\n",
        "            elif \"units\" in window_params:\n",
        "                f.write(struct.pack('i', window_params[\"units\"]))\n",
        "        f.write(struct.pack('Q', data_size))\n",
        "        f.write(output_data.flatten().astype(np.float32).tobytes())\n",
        "    return bin_file\n",
        "\n",
        "# Bölüm 8: Ana Simülasyon ve Çalıştırma Fonksiyonu\n",
        "# Bu bölümde, modelin çalıştırılması, FPGA ile iletişim ve sonuçların karşılaştırılması gerçekleştirilir.\n",
        "\n",
        "def run_model(model_type, model_selection, layer_selection, data_choice, mode):\n",
        "    # Seçilen model, katman ve mod ile modeli çalıştırır ve FPGA çıktısını gerçek çıktı ile karşılaştırır\n",
        "    model_info = MODEL_TYPES[model_type][\"models\"][model_selection]\n",
        "    model_path = model_info[\"model_path\"]\n",
        "    test_path = model_info[\"test_path\"]\n",
        "    flow_from_directory = model_info[\"flow_from_directory\"]\n",
        "    target_size = model_info[\"target_size\"]\n",
        "    file_format = MODEL_TYPES[model_type][\"file_format\"]\n",
        "\n",
        "    # Modeli yükle\n",
        "    try:\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "    except Exception as e:\n",
        "        return f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Test verisini yükle\n",
        "    try:\n",
        "        if flow_from_directory:\n",
        "            test_data = load_images_with_flow_from_directory(test_path, target_size=target_size, batch_size=8)\n",
        "        else:\n",
        "            test_data = load_images_from_directory(test_path, target_size=target_size, batch_size=8)\n",
        "    except Exception as e:\n",
        "        return f\"Test verisi yükleme hatası: {str(e)}\\nTest yolu: {test_path}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Katman seçimini işle (sadece Donanım modunda)\n",
        "    layer_index = None\n",
        "    current_layer = None\n",
        "    if mode == \"Donanım\" and layer_selection and layer_selection != \"None\":\n",
        "        try:\n",
        "            layer_index = int(layer_selection.split(\":\")[0].replace(\"Katman \", \"\"))\n",
        "            current_layer = loaded_model.layers[layer_index]\n",
        "        except (ValueError, IndexError) as e:\n",
        "            return f\"Katman seçimi hatası: {str(e)}\\nSeçilen katman: {layer_selection}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    # Veri seçimini yap\n",
        "    try:\n",
        "        if data_choice == \"Test Verisinden Örnek Kullan\":\n",
        "            if flow_from_directory:\n",
        "                input_data = next(test_data)\n",
        "            else:\n",
        "                input_data = next(iter(test_data))\n",
        "            data_info = f\"Örnek veri kullanıldı. Şekil: {input_data.shape}\"\n",
        "        else:\n",
        "            expected_shape = loaded_model.input.shape[1:]\n",
        "            input_data = np.random.random((8, *expected_shape))\n",
        "            data_info = f\"Rastgele veri oluşturuldu. Şekil: {input_data.shape}\"\n",
        "    except Exception as e:\n",
        "        return f\"Veri seçimi hatası: {str(e)}\", \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "    try:\n",
        "        if mode == \"Simülasyon\" or layer_selection == \"None\" or not layer_selection:\n",
        "            # Simülasyon modunda veya katman seçilmediğinde tam modeli çalıştır\n",
        "            real_output = loaded_model.predict(input_data, verbose=0)\n",
        "            fpga_output = real_output\n",
        "            serialized_output = real_output.flatten().tobytes()\n",
        "            data_sent_size = len(serialized_output)\n",
        "            weights_info = \"Hızlandırma yapılmadı, ağırlıklar kullanılmadı.\"\n",
        "            bin_file = None\n",
        "        else:\n",
        "            # Donanım modunda seçilen katmanın çıktısını hesapla ve FPGA ile iletişim kur\n",
        "            global weights  # Conv_HW için weights'i global yap (entegre ederken erişim için)\n",
        "            weights, window_params = extract_weights_and_window(current_layer)\n",
        "            real_output = get_layer_output(loaded_model, layer_index, input_data)\n",
        "\n",
        "            output_file_x = f\"file_{uuid.uuid4()}.x\"\n",
        "            with open(output_file_x, 'wb') as f:\n",
        "                f.write(real_output.flatten().tobytes())  # input_data yerine real_output (katman inputu) kullan; ama Conv_HW için data_matrice katman inputu olmalı.\n",
        "\n",
        "            bin_file = save_data_for_kagan(weights, window_params, len(real_output.flatten().tobytes()), real_output)\n",
        "\n",
        "            result_queue = queue.Queue()\n",
        "            comm_thread = threading.Thread(\n",
        "                target=communicate_with_fpga,\n",
        "                args=(real_output, output_file_x, result_queue, mode)  # input_data yerine katman inputu (real_output öncesi output)\n",
        "            )\n",
        "            comm_thread.start()\n",
        "            comm_thread.join()\n",
        "\n",
        "            fpga_result = result_queue.get()\n",
        "            if len(fpga_result) == 3:\n",
        "                raise Exception(fpga_result[2])\n",
        "            fpga_output, data_sent_size = fpga_result\n",
        "            weights_info = f\"Ağırlıklar ve pencere parametreleri: {window_params}, Ağırlık boyutu: {sum(w.size for w in weights)} eleman\"\n",
        "\n",
        "            os.remove(output_file_x)\n",
        "            if bin_file:\n",
        "                os.remove(bin_file)\n",
        "\n",
        "        # Çıktıları karşılaştır ve benzerlik skorunu hesapla\n",
        "        real_output_np = real_output if isinstance(real_output, np.ndarray) else real_output.numpy()\n",
        "        fpga_output_np = fpga_output if isinstance(fpga_output, np.ndarray) else fpga_output.numpy()\n",
        "        serialized_output = real_output_np.flatten().tobytes()\n",
        "\n",
        "        mse = np.mean((real_output_np - fpga_output_np) ** 2)\n",
        "        similarity = max(0, 1 - mse)\n",
        "\n",
        "        expected_input_shape = (loaded_model.input.shape[1:] if layer_index == 0 else\n",
        "                               loaded_model.layers[layer_index - 1].output.shape[1:] if layer_index else\n",
        "                               \"Tam model\")\n",
        "\n",
        "        # Sonuçları formatla\n",
        "        output_str = f\"Seçilen Model Türü: {model_type}\\n\"\n",
        "        output_str += f\"Seçilen Model: {model_selection}\\n\"\n",
        "        output_str += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok (Tam Model)'}\\n\"\n",
        "        output_str += f\"Mod: {mode}\\n\"\n",
        "        output_str += f\"Beklenen Giriş Şekli: {expected_input_shape}\\n\"\n",
        "        output_str += f\"Gerçek Giriş Şekli: {input_data.shape if layer_index == 0 else loaded_model.layers[layer_index - 1].output.shape if layer_index else input_data.shape}\\n\"\n",
        "        output_str += f\"{data_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Şekli: {real_output.shape}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Şekli: {fpga_output.shape}\\n\"\n",
        "        output_str += f\"Kağan'a Gönderilen Veri Boyutu: {data_sent_size} bayt\\n\"\n",
        "        output_str += f\"{weights_info}\\n\"\n",
        "        output_str += f\"Gerçek Çıktı Örnek Veri: {real_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"FPGA Çıktı Örnek Veri: {fpga_output_np.flatten()[:5]}\\n\"\n",
        "        output_str += f\"Benzerlik Skoru: {similarity:.4f} (1’e yakınsa daha uyumlu)\\n\"\n",
        "\n",
        "        # Benzerlik skorunu görselleştir\n",
        "        animation_html = f\"\"\"\n",
        "        <div style='width: 100%; background: #f0f0f0; border-radius: 5px;'>\n",
        "            <div style='width: {similarity * 100}%; background: #4CAF50; height: 20px; border-radius: 5px;\n",
        "                        transition: width 1s ease-in-out; text-align: center; color: white;'>\n",
        "                {similarity * 100:.1f}%\n",
        "            </div>\n",
        "        </div>\n",
        "        <p style='text-align: center;'>FPGA Çıktısının Gerçek Çıktıyla Uyumu</p>\n",
        "        \"\"\"\n",
        "\n",
        "        return output_str, animation_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Hata oluştu: {str(e)}\\n\"\n",
        "        error_msg += f\"Seçilen Katman: {current_layer.name if current_layer else 'Hızlandırma Yok'}\\n\"\n",
        "        error_msg += f\"Giriş Verisi Şekli: {input_data.shape}\\n\"\n",
        "        error_msg += f\"Geçerli Katman Çıkış Şekli: {real_output.shape if 'real_output' in locals() else 'Hesaplanamadı'}\\n\"\n",
        "        return error_msg, \"<p>Hata nedeniyle animasyon oluşturulamadı.</p>\"\n",
        "\n",
        "# Bölüm 9: Gradio Arayüz Yardımcı Fonksiyonları\n",
        "# Bu bölümde, Gradio arayüzünün dinamik bileşenlerini güncelleyen fonksiyonlar tanımlanır.\n",
        "\n",
        "def update_model_dropdown(model_type):\n",
        "    # Model türü seçildiğinde model seçim dropdown'unu günceller\n",
        "    try:\n",
        "        models = list(MODEL_TYPES[model_type][\"models\"].keys())\n",
        "        return gr.Dropdown(choices=models, value=models[0], label=\"Model Seçimi\")\n",
        "    except Exception as e:\n",
        "        return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Model Seçimi\", info=f\"Hata: {str(e)}\")\n",
        "\n",
        "def update_layer_dropdown(model_type, model_selection):\n",
        "    # Model veya model türü değiştiğinde katman seçim dropdown'unu günceller\n",
        "    try:\n",
        "        if model_type not in MODEL_TYPES or model_selection not in MODEL_TYPES[model_type][\"models\"]:\n",
        "            return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                               info=f\"Geçersiz model türü ({model_type}) veya model seçimi ({model_selection})\")\n",
        "\n",
        "        model_info = MODEL_TYPES[model_type][\"models\"][model_selection]\n",
        "        model_path = model_info[\"model_path\"]\n",
        "        if not os.path.exists(model_path):\n",
        "            return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                               info=f\"Model dosyası bulunamadı: {model_path}\")\n",
        "\n",
        "        loaded_model = tf.keras.models.load_model(model_path)\n",
        "        layer_names = [\"None\"]\n",
        "        for i, layer in enumerate(loaded_model.layers):\n",
        "            try:\n",
        "                output_shape = layer.output.shape if hasattr(layer, 'output') else 'Giriş Katmanı'\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: {output_shape}\")\n",
        "            except Exception as e:\n",
        "                layer_names.append(f\"Katman {i}: {layer.name} - Çıkış Şekli: Hata ({str(e)})\")\n",
        "        return gr.Dropdown(choices=layer_names, value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\")\n",
        "    except Exception as e:\n",
        "        return gr.Dropdown(choices=[\"None\"], value=\"None\", label=\"Hızlandırmak İstediğiniz Katmanı Seçin\",\n",
        "                           info=f\"Model yükleme hatası: {str(e)}\\nModel yolu: {model_path}\")\n",
        "\n",
        "def update_layer_visibility(mode):\n",
        "    # Çalışma modu değiştiğinde katman seçim dropdown'unun görünürlüğünü kontrol eder\n",
        "    return gr.update(visible=(mode == \"Donanım\"))\n",
        "\n",
        "# Bölüm 10: Gradio Kullanıcı Arayüzü\n",
        "# Bu bölümde, interaktif Gradio arayüzü oluşturulur ve kullanıcı girişleri alınır.\n",
        "\n",
        "with gr.Blocks(title=\"CNN Model Hızlandırıcı\") as interface:\n",
        "    gr.Markdown(\"# CNN Model Hızlandırıcı\")\n",
        "    gr.Markdown(\"Model türünüzü ve modelinizi seçin, ardından katman ve giriş verisi tipini belirleyin. Simülasyon veya donanım modunda FPGA çıktısının gerçek çıktı ile uyumunu görün!\")\n",
        "\n",
        "    # Model türü seçimi\n",
        "    model_type_input = gr.Dropdown(choices=list(MODEL_TYPES.keys()), label=\"Model Türü Seçimi\", value=\"LeNet\")\n",
        "\n",
        "    # Model ve mod seçimi\n",
        "    with gr.Row():\n",
        "        model_input = gr.Dropdown(label=\"Model Seçimi\", value=\"LeNet1\")\n",
        "        mode_input = gr.Radio(choices=[\"Simülasyon\", \"Donanım\"], label=\"Çalışma Modu\", value=\"Simülasyon\")\n",
        "\n",
        "    # Katman seçimi ve simülasyon\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            layer_input = gr.Dropdown(label=\"Hızlandırmak İstediğiniz Katmanı Seçin\", visible=False)\n",
        "            data_input = gr.Radio(choices=[\"Test Verisinden Örnek Kullan\", \"Rastgele Veri Kullan\"],\n",
        "                                 label=\"Giriş Verisi Seçimi\", value=\"Test Verisinden Örnek Kullan\")\n",
        "            submit_btn = gr.Button(\"Modeli Çalıştır\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Sonuçlar\", lines=15)\n",
        "            output_animation = gr.HTML(label=\"FPGA Çıktı Uyumu\")\n",
        "\n",
        "    # Model türü değiştiğinde model dropdown'unu güncelle\n",
        "    model_type_input.change(fn=update_model_dropdown, inputs=model_type_input, outputs=model_input)\n",
        "\n",
        "    # Model değiştiğinde katman dropdown'unu güncelle\n",
        "    model_input.change(fn=update_layer_dropdown, inputs=[model_type_input, model_input], outputs=layer_input)\n",
        "\n",
        "    # Çalışma modu değiştiğinde katman dropdown'unun görünürlüğünü güncelle\n",
        "    mode_input.change(fn=update_layer_visibility, inputs=mode_input, outputs=layer_input)\n",
        "\n",
        "    # Modeli çalıştır\n",
        "    submit_btn.click(fn=run_model, inputs=[model_type_input, model_input, layer_input, data_input, mode_input], outputs=[output_text, output_animation])\n",
        "\n",
        "# Arayüzü başlat\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-wKm8dL9hpeU",
        "outputId": "790a23b5-51a3-4ba4-bffb-e3cac3e30e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyserial in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: gradio==3.50.2 in /usr/local/lib/python3.12/dist-packages (3.50.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==0.6.1 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.34.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (3.1.6)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (3.10.0)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (10.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (6.0.2)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.32.4)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.35.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (11.0.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==0.6.1->gradio==3.50.2) (2025.3.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (3.19.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (1.1.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.0->gradio==3.50.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests~=2.0->gradio==3.50.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.0->gradio==3.50.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.0->gradio==3.50.2) (2025.8.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (0.16.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi->gradio==3.50.2) (0.47.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->gradio==3.50.2) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->gradio==3.50.2) (1.0.9)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.50.2) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->gradio==3.50.2) (1.3.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/components/dropdown.py:231: UserWarning: The value passed into gr.Dropdown() is not in the list of choices. Please update the list of choices to include: LeNet1 or set allow_custom_value=True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://453ba769dae372624a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://453ba769dae372624a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}